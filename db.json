{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/images/anchr_1.jpg","path":"images/anchr_1.jpg","modified":1,"renderable":0},{"_id":"source/images/Webserver_memory_graph.jpg","path":"images/Webserver_memory_graph.jpg","modified":1,"renderable":0},{"_id":"source/images/anchr_2.jpg","path":"images/anchr_2.jpg","modified":1,"renderable":0},{"_id":"source/images/angular2_logo.png","path":"images/angular2_logo.png","modified":1,"renderable":0},{"_id":"source/images/apple-touch-icon.png","path":"images/apple-touch-icon.png","modified":1,"renderable":0},{"_id":"source/images/benchmarks.svg","path":"images/benchmarks.svg","modified":1,"renderable":0},{"_id":"source/images/benchmarks2.svg","path":"images/benchmarks2.svg","modified":1,"renderable":0},{"_id":"source/images/cartpole1.jpg","path":"images/cartpole1.jpg","modified":1,"renderable":0},{"_id":"source/images/cartpole2.png","path":"images/cartpole2.png","modified":1,"renderable":0},{"_id":"source/images/cartpole3.png","path":"images/cartpole3.png","modified":1,"renderable":0},{"_id":"source/images/cartpole4.png","path":"images/cartpole4.png","modified":1,"renderable":0},{"_id":"source/images/doodlerbot_icon.png","path":"images/doodlerbot_icon.png","modified":1,"renderable":0},{"_id":"source/images/dqn1.png","path":"images/dqn1.png","modified":1,"renderable":0},{"_id":"source/images/dqn2.png","path":"images/dqn2.png","modified":1,"renderable":0},{"_id":"source/images/dqn3.png","path":"images/dqn3.png","modified":1,"renderable":0},{"_id":"source/images/dqn4.png","path":"images/dqn4.png","modified":1,"renderable":0},{"_id":"source/images/expensebot_icon.png","path":"images/expensebot_icon.png","modified":1,"renderable":0},{"_id":"source/images/halite_langs.png","path":"images/halite_langs.png","modified":1,"renderable":0},{"_id":"source/images/middleman.png","path":"images/middleman.png","modified":1,"renderable":0},{"_id":"source/images/middleman2.png","path":"images/middleman2.png","modified":1,"renderable":0},{"_id":"source/images/push_screenshot1.png","path":"images/push_screenshot1.png","modified":1,"renderable":0},{"_id":"source/images/push_screenshot2.png","path":"images/push_screenshot2.png","modified":1,"renderable":0},{"_id":"source/images/raid01.png","path":"images/raid01.png","modified":1,"renderable":0},{"_id":"source/images/statista.png","path":"images/statista.png","modified":1,"renderable":0},{"_id":"source/images/raid10.png","path":"images/raid10.png","modified":1,"renderable":0},{"_id":"source/images/trivia.jpg","path":"images/trivia.jpg","modified":1,"renderable":0},{"_id":"source/images/unhosted.jpg","path":"images/unhosted.jpg","modified":1,"renderable":0},{"_id":"source/images/webdev_techstack.png","path":"images/webdev_techstack.png","modified":1,"renderable":0},{"_id":"source/images/webdevlist.jpg","path":"images/webdevlist.jpg","modified":1,"renderable":0},{"_id":"source/images/webserver_performance.png","path":"images/webserver_performance.png","modified":1,"renderable":0},{"_id":"source/images/whatsapp_logo.png","path":"images/whatsapp_logo.png","modified":1,"renderable":0},{"_id":"source/images/do.png","path":"images/do.png","modified":1,"renderable":0},{"_id":"source/images/thesis_mockup.png","path":"images/thesis_mockup.png","modified":1,"renderable":0},{"_id":"source/images/thesis_stack.png","path":"images/thesis_stack.png","modified":1,"renderable":0},{"_id":"source/images/webdev_techstack_large.png","path":"images/webdev_techstack_large.png","modified":1,"renderable":0},{"_id":"source/images/webservers.png","path":"images/webservers.png","modified":1,"renderable":0},{"_id":"source/images/scorecard.jpg","path":"images/scorecard.jpg","modified":1,"renderable":0},{"_id":"themes/cactus-dark/source/css/style.styl","path":"css/style.styl","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/images/favicon-192x192.png","path":"images/favicon-192x192.png","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/images/favicon.ico","path":"images/favicon.ico","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/js/main.js","path":"js/main.js","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/lib/justified-gallery/jquery.justifiedGallery.min.js","path":"lib/justified-gallery/jquery.justifiedGallery.min.js","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/lib/justified-gallery/justifiedGallery.min.css","path":"lib/justified-gallery/justifiedGallery.min.css","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/styles.css","path":"lib/meslo-LG/styles.css","modified":1,"renderable":1},{"_id":"source/images/halite_game.png","path":"images/halite_game.png","modified":1,"renderable":0},{"_id":"themes/cactus-dark/source/lib/jquery/jquery.min.js","path":"lib/jquery/jquery.min.js","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGL-Italic.ttf","path":"lib/meslo-LG/fonts/MesloLGL-Italic.ttf","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGM-Italic.ttf","path":"lib/meslo-LG/fonts/MesloLGM-Italic.ttf","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGS-Italic.ttf","path":"lib/meslo-LG/fonts/MesloLGS-Italic.ttf","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGL-Bold.ttf","path":"lib/meslo-LG/fonts/MesloLGL-Bold.ttf","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGL-BoldItalic.ttf","path":"lib/meslo-LG/fonts/MesloLGL-BoldItalic.ttf","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGL-Regular.ttf","path":"lib/meslo-LG/fonts/MesloLGL-Regular.ttf","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGM-BoldItalic.ttf","path":"lib/meslo-LG/fonts/MesloLGM-BoldItalic.ttf","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGM-Bold.ttf","path":"lib/meslo-LG/fonts/MesloLGM-Bold.ttf","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGS-Bold.ttf","path":"lib/meslo-LG/fonts/MesloLGS-Bold.ttf","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGM-Regular.ttf","path":"lib/meslo-LG/fonts/MesloLGM-Regular.ttf","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGS-BoldItalic.ttf","path":"lib/meslo-LG/fonts/MesloLGS-BoldItalic.ttf","modified":1,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGS-Regular.ttf","path":"lib/meslo-LG/fonts/MesloLGS-Regular.ttf","modified":1,"renderable":1}],"Cache":[{"_id":"themes/cactus-dark/LICENSE","hash":"4d5f5f360a18c68f0fd1897bdb1eb1210c2893e3","modified":1521451810000},{"_id":"themes/cactus-dark/README.md","hash":"f38b2f4771eeccc0ae0959ac3e3c485a9d159d4a","modified":1521451810000},{"_id":"themes/cactus-dark/_config.yml","hash":"decff06348dd0d6913b3562a55efe01b2ead3077","modified":1521451810000},{"_id":"source/_data/projects.json","hash":"5ce62d53267ecf79a2372fbbdee3d5f03f9e16db","modified":1521451808000},{"_id":"source/articles/index.md","hash":"c78343a2d767f7662ebaf281eb4f6ad8d0bdebb3","modified":1521451808000},{"_id":"source/_posts/anchr-io-image-uploads-bookmarks-and-shortlink-service.md","hash":"789d49d89b31f482f80e792ffdc627d7c245fe3c","modified":1521451807000},{"_id":"source/_posts/caddy-a-modern-web-server-vs-nginx.md","hash":"9a9c355ed3ddcbef9ff79deef95f88751212450f","modified":1521451808000},{"_id":"source/_posts/cartpole-with-a-deep-q-network.md","hash":"c8eacbd536e751bf7d864bcbde685169a762944b","modified":1521451807000},{"_id":"source/_posts/cartpole-with-qlearning-first-experiences-with-openai-gym.md","hash":"59cf103abe185845dc2e96178d0a136c468b6604","modified":1521451808000},{"_id":"source/_posts/design-of-a-linked-dataenabled-microservice-platform-for-the-industrial-internet-of-things.md","hash":"c1c3aab0d95a2987e58fe9189598f9c36a18ccc9","modified":1521451807000},{"_id":"source/_posts/digitalocean-my-preferred-cloud-hosting-provider.md","hash":"7d6b7e6bed189f180fb58f52f0ea971dae96ab45","modified":1521451808000},{"_id":"source/_posts/halite-a-rule-based-ai-bot.md","hash":"64a6e8bd46d4b23f30c429642da6905892172e89","modified":1521451808000},{"_id":"source/_posts/how-do-whatsapps-end-to-end-encrypted-group-chats-work.md","hash":"1209b6df611783a249ba29a1dbaedc94e3079ff0","modified":1521451807000},{"_id":"source/_posts/how-to-load-yago-into-apache-jena-fuseki.md","hash":"47a6356bc8cfce54d352a58373a76ac38f3009ea","modified":1521451807000},{"_id":"source/_posts/how-to-make-telegram-bots.md","hash":"ad41a23a8ef8683745fa102e406708f2b8fa2a5b","modified":1521451807000},{"_id":"source/_posts/http-performance-java-jersey-vs-go-vs-nodejs.md","hash":"cbb3c4ef84caaf4456120b02e7efe53062607303","modified":1521451807000},{"_id":"source/_posts/http20-server-push-proxy.md","hash":"ec535d2a2ef2f10ab1f207fa664c7a2763b27f3a","modified":1521451807000},{"_id":"source/_posts/innovation-in-germany-not.md","hash":"31d27dc67d2c57fac4a28ac15ca1ebdbaca57fef","modified":1521451807000},{"_id":"source/_posts/instant-messenger-security-encryption-overview.md","hash":"eefec3bcbd6bd4f6e9241ac168ccea422b01a4c3","modified":1521451807000},{"_id":"source/_posts/learning-angular2-what-is-new.md","hash":"942d033405f0192315d26efedbe8b8bbce20631a","modified":1521451807000},{"_id":"source/_posts/linkeddata-trivia-game.md","hash":"5f8d798558af3716b59c271c4c07050d66b3293d","modified":1521451807000},{"_id":"source/_posts/linux-cache-information-bash-script.md","hash":"9b5526414d08dc4102119d7c31996c9961288fbb","modified":1521451807000},{"_id":"source/_posts/migrate-maildir-to-new-server-using-imapsync.md","hash":"15ae57c2734c5e3514532806234212184f340166","modified":1521451807000},{"_id":"source/_posts/ml-telegram-chat-message-classification.md","hash":"58ddc07e88e9917646c60d0ded5ddca7e310cbe6","modified":1521451807000},{"_id":"source/_posts/my-teck-stack-if-i-had-to-build-an-app-today.md","hash":"173cd62d9eccceda4387127935c58d132aff6774","modified":1521451807000},{"_id":"source/_posts/telegram-bot-example-code-in-nodejs.md","hash":"10a1212093688aa9589c882fafe0297fd999e2b6","modified":1521451807000},{"_id":"source/_posts/telegram-expensebot-doodlerbot.md","hash":"30f5598d3774028f543c17dc63a4e32ae9d3cbdc","modified":1521451807000},{"_id":"source/_posts/telegram-middleman-bot-push-notifications-as-easy-as-post.md","hash":"1444fdb87c854abb4cd2b011d1f4bf7d0f970ab0","modified":1521451807000},{"_id":"source/_posts/unhostedorg-applications-with-remotestorageio-and-webfingernet.md","hash":"213eca3c8df289c14d237fbcec4038bfe6994c04","modified":1521451807000},{"_id":"source/_posts/web-development-technology-stack.md","hash":"3196d6ac39cf01f233d0919f4d4405e768dfa565","modified":1521451807000},{"_id":"source/_posts/webdevlistnet-the-developers-resource-collection.md","hash":"b0f879ca1c4c00993c5e088bb1439356d9cdccc2","modified":1521451807000},{"_id":"source/_posts/why-raid-10-is-better-than-raid-01.md","hash":"a6eafba6baa3e10da17b3d93281bd3860cd0893d","modified":1521451807000},{"_id":"source/about/index.md","hash":"07f6fabca84b961ddcfad583e56fa173447140e6","modified":1526073090235},{"_id":"source/images/anchr_1.jpg","hash":"0d50b24329bdcddea234f0c3ade3f2846daae148","modified":1521451808000},{"_id":"source/images/Webserver_memory_graph.jpg","hash":"aeaf52174560a2d3a7ff32fda21a26b96c907cc9","modified":1521451808000},{"_id":"source/images/anchr_2.jpg","hash":"d07dfedb2fc549983f63bf7251f3d011b96188aa","modified":1521451808000},{"_id":"source/images/angular2_logo.png","hash":"189713e0c0de88477c6726fc59b4cd1cfb16b05e","modified":1521451808000},{"_id":"source/images/apple-touch-icon.png","hash":"07059d8fe92f685176d96045edb70c01deb8c4d0","modified":1521451808000},{"_id":"source/images/benchmarks.svg","hash":"e9fbfdf69d7ac1c9890d541fb07d69f844fbb99a","modified":1521451808000},{"_id":"source/images/benchmarks2.svg","hash":"c4bd56f99f3a8810fd50a3caf7a99213b407a0d5","modified":1521451808000},{"_id":"source/images/cartpole1.jpg","hash":"3e237ad7b3bb78ada0d507c8f644a791797b194e","modified":1521451808000},{"_id":"source/images/cartpole2.png","hash":"bb292c589bd25b8b59c75989377163232d29b1c8","modified":1521451808000},{"_id":"source/images/cartpole3.png","hash":"03883366ab1f16b607653ef239b99ede1ac56efc","modified":1521451808000},{"_id":"source/images/cartpole4.png","hash":"d92a7e37c8e88986a51e9a7e6b0124093b5a7425","modified":1521451808000},{"_id":"source/images/doodlerbot_icon.png","hash":"7e548feeabd180f1e5af390365ce88fe70fe619e","modified":1521451808000},{"_id":"source/images/dqn1.png","hash":"500531da445ad95337e7d60b0834ce15ed235b41","modified":1521451808000},{"_id":"source/images/dqn2.png","hash":"07d2f6e25d0328c8986d173efab87bc59e63f944","modified":1521451808000},{"_id":"source/images/dqn3.png","hash":"664f10963a00e2d66fe7dde7e78848d26dbf78cd","modified":1521451808000},{"_id":"source/images/dqn4.png","hash":"e564dd5d0e8258145f93d65eb1a600a9d5489826","modified":1521451808000},{"_id":"source/images/expensebot_icon.png","hash":"479cb80aa0620db49e0a353ac7f550f7cc9f205d","modified":1521451808000},{"_id":"source/images/halite_langs.png","hash":"68561eee10ca68ffafaadcbe07056dc039d3be23","modified":1521451808000},{"_id":"source/images/middleman.png","hash":"f09ddfd0c8c0973d16567a1122981e6b14db615b","modified":1521451808000},{"_id":"source/images/middleman2.png","hash":"456e72dd3824a95589cc264627b81596eb589f96","modified":1521451808000},{"_id":"source/images/push_screenshot1.png","hash":"91d5fa3e4c5a3a3d0f369a8d90055d029e8ef28e","modified":1521451808000},{"_id":"source/images/push_screenshot2.png","hash":"144ca3caed3e5b9285f7f8edeba41917266ed529","modified":1521451808000},{"_id":"source/images/raid01.png","hash":"15da9f10e5a4d3f452287daf4420da8582d3ad31","modified":1521451808000},{"_id":"source/images/statista.png","hash":"4385242cac93067b8ca8dd02c01a1778bf1c6102","modified":1521451808000},{"_id":"source/images/raid10.png","hash":"ae8cb17a2ae2eba7d238a8d56136f60823172242","modified":1521451808000},{"_id":"source/images/trivia.jpg","hash":"8e7715fa940d79f43fd1e2a9ff8c2149cf0b11a8","modified":1521451808000},{"_id":"source/images/unhosted.jpg","hash":"6e0bde1ad7bfb3ba8d9b634f6518299e2d9d1f1b","modified":1521451808000},{"_id":"source/images/webdev_techstack.png","hash":"e3f4b8cdac4233ebcb5d7e20ee42703c9ffad6ba","modified":1521451808000},{"_id":"source/images/webdevlist.jpg","hash":"cfa9e038e301cdcd577c7833fc8b220f6c0d6a98","modified":1521451808000},{"_id":"source/images/webserver_performance.png","hash":"737f74276f3832a342464110566fdab49593de94","modified":1521451808000},{"_id":"source/images/whatsapp_logo.png","hash":"197552fa1ec1aefb1c912e52272d6d2d032e76f6","modified":1521451808000},{"_id":"source/imprint/index.md","hash":"685dd4a60c968b55fbc84e1a9f05a2867dabf67a","modified":1525786441169},{"_id":"themes/cactus-dark/layout/archive.ejs","hash":"ab9798bf534485a4fed4d3089011421858afdd26","modified":1521451810000},{"_id":"themes/cactus-dark/layout/index.ejs","hash":"3091e16a565d7ce2bd49935f7036d86cee2bd53e","modified":1521451810000},{"_id":"themes/cactus-dark/layout/layout.ejs","hash":"8484532ad7c4da22f46fc1394bb2fd9ded34be1f","modified":1521451810000},{"_id":"themes/cactus-dark/layout/page.ejs","hash":"b6b7b1e6dc856a0e62f35da0151f67ba41143e04","modified":1521451810000},{"_id":"themes/cactus-dark/layout/post.ejs","hash":"f870a765e89f5f1a4eaeae49f4f6f00736b0f3ee","modified":1521451810000},{"_id":"themes/cactus-dark/scripts/meta.js","hash":"fa6055a39851c9953d033e70c1614547b94dce60","modified":1521451810000},{"_id":"themes/cactus-dark/scripts/thumbnail.js","hash":"df8829fd8c3119650037eba5ec11bdce06acff9d","modified":1521451810000},{"_id":"source/images/do.png","hash":"dd43ce0ffde6885ad251e6e4edff64b36ddecd02","modified":1521451808000},{"_id":"source/images/thesis_mockup.png","hash":"a5ec4a8949edd6a168c866c675ab6c4e2bc00d33","modified":1521451808000},{"_id":"source/images/thesis_stack.png","hash":"5a410fcb932c552dbc0096f59fda594be334e9cd","modified":1521451808000},{"_id":"source/images/webdev_techstack_large.png","hash":"76169ecb9523c245c6588156fcff24c851b5c43b","modified":1521451808000},{"_id":"source/images/webservers.png","hash":"c1550f9bcb7350c9ebef5090484960877d8dda55","modified":1521451808000},{"_id":"source/images/scorecard.jpg","hash":"e4b56c4f825d42890e6c735c17d6a29a80a7f075","modified":1521451808000},{"_id":"themes/cactus-dark/layout/_partial/comments.ejs","hash":"853a4500da515ef3facc51a055886eaf8efd080d","modified":1521451810000},{"_id":"themes/cactus-dark/layout/_partial/footer.ejs","hash":"7f6b3f126a58e6734b658ab57bc6b41822bc9342","modified":1521451810000},{"_id":"themes/cactus-dark/layout/_partial/head.ejs","hash":"7782e6b1ce72fcf121f0017d383e2fb87e72c539","modified":1525786033759},{"_id":"themes/cactus-dark/layout/_partial/header.ejs","hash":"889fe54bbfd1fb3357e8c0614d57a437a72f782a","modified":1521451810000},{"_id":"themes/cactus-dark/layout/_partial/pagination.ejs","hash":"ca660c59aec56daa4a7b41715b97434d4a24c37e","modified":1521451810000},{"_id":"themes/cactus-dark/layout/_partial/scripts.ejs","hash":"ffdf85e347233b6dc3b12296cd3d25cd1d0bd8e6","modified":1525786110206},{"_id":"themes/cactus-dark/layout/_partial/styles.ejs","hash":"e62b799d8ac369d1f1b36bd2649ecc34aec3384c","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_extend.styl","hash":"faca25132d55e8989d1c1d638e55d1e97de3c561","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_mixins.styl","hash":"c921ceb620deedddd38c9cec28190995e8764bab","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_util.styl","hash":"f8e286a21c7ec3e771d5ddeb2909ac92390af9bd","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_variables.styl","hash":"80345f77f0e601669047cbb3c44491720c3b5c13","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/style.styl","hash":"9a989e414ab2fa12f39791f2ea07c22aec00c670","modified":1521451810000},{"_id":"themes/cactus-dark/source/images/favicon-192x192.png","hash":"07059d8fe92f685176d96045edb70c01deb8c4d0","modified":1521451810000},{"_id":"themes/cactus-dark/source/images/favicon.ico","hash":"164bc240105d72d826efc048442d85dcf90d2cce","modified":1521451810000},{"_id":"themes/cactus-dark/source/js/main.js","hash":"2703a7cb4fc7056d13215b9fde675da426b9cdc4","modified":1521451810000},{"_id":"themes/cactus-dark/layout/_partial/post/actions_desktop.ejs","hash":"2319dea76f205c27dd59c994921f66350df8027a","modified":1521451810000},{"_id":"themes/cactus-dark/layout/_partial/post/actions_mobile.ejs","hash":"e7638a83e5aaa4bf5b24440ca76fec8eb563bed7","modified":1521451810000},{"_id":"themes/cactus-dark/layout/_partial/post/date.ejs","hash":"12a4a7ba6334e3e5c03d9a9601d7779a27c2e082","modified":1521451810000},{"_id":"themes/cactus-dark/layout/_partial/post/gallery.ejs","hash":"9aecd8908e8a684f33dc20c02497c0f1774137c7","modified":1521451810000},{"_id":"themes/cactus-dark/layout/_partial/post/share.ejs","hash":"25a3406f97e976ec13239f0d3f32f9e512511f50","modified":1521451810000},{"_id":"themes/cactus-dark/layout/_partial/post/tag.ejs","hash":"bfab03ef986d35ccad583f2d2b575db4a8d2789e","modified":1521451810000},{"_id":"themes/cactus-dark/layout/_partial/post/title.ejs","hash":"a060f1c6e3718494a6b1d0e1981ea0bf4e549828","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/agate.styl","hash":"601eb70448a16b918df132f6fc41e891ae053653","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/androidstudio.styl","hash":"65d09f1b0e81c6a182f549fd3de51e59823c97ae","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/arta.styl","hash":"1a5accc115f41d1b669ed708ac6a29abac876599","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/atelier-cave-dark.styl","hash":"bc647b2c1d971d7cc947aa1ed66e9fd115261921","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/atelier-dune-dark.styl","hash":"df50a85a4b14c7ca6e825d665594b91229d0e460","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/atelier-estuary-dark.styl","hash":"d84382bc8298f96730757391d3e761b7e640f406","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/atelier-forest-dark.styl","hash":"57c154c6045a038dc7df0a25927853e10bf48c4a","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/atelier-heath-dark.styl","hash":"b0cf13b2233e7bc38342032d2d7296591a4c2bcf","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/atelier-lakeside-dark.styl","hash":"bb0a8c4ad0dd8e3e7de7122ddf268fc42aa94acb","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/atelier-plateau-dark.styl","hash":"09c64f1a7052aec9070c36c0431df25216afaea1","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/atelier-savanna-dark.styl","hash":"a16c919a1ccf2f845488078fb341381bec46b1f3","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/atelier-seaside-dark.styl","hash":"ce233a101daea7124cbfcd34add43ccfe2e1e1c7","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/atelier-sulphurpool-dark.styl","hash":"414b0cfc142f70afe359c16450b651e28bf7325a","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/codepen-embed.styl","hash":"f4dcc84d8e39f9831a5efe80e51923fc3054feb0","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/dark.styl","hash":"71ce56d311cc2f3a605f6e2c495ccd7236878404","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/darkula.styl","hash":"ad0d5728d21645039c9f199e7a56814170ed3bab","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/far.styl","hash":"d9928010ffe71e80b97a5afcba1a4975efdd7372","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/hopscotch.styl","hash":"b374c6550b89b4751aedc8fbc3cf98d95bd70ead","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/hybrid.styl","hash":"ea8d7ddc258b073308746385f5cb85aabb8bfb83","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/ir-black.styl","hash":"693078bbd72a2091ed30f506cc55949600b717af","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/kimbie.styl","hash":"45dbb168f22d739d0109745d2decd66b5f94e786","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/monokai-sublime.styl","hash":"25aa2fc1dbe38593e7c7ebe525438a39574d9935","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/monokai.styl","hash":"5a4fe9f957fd7a368c21b62a818403db4270452f","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/obsidian.styl","hash":"55572bbcfee1de6c31ac54681bb00336f5ae826d","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/paraiso.styl","hash":"f1537bd868579fa018ecdbfd2eb922dcf3ba2cac","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/pojoaque.styl","hash":"77dae9dc41945359d17fe84dbd317f1b40b2ee33","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/railscasts.styl","hash":"acd620f8bb7ff0e3fe5f9a22b4433ceef93a05e6","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/rainbow.styl","hash":"ce73b858fc0aba0e57ef9fb136c083082746bc1d","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/solarized-dark.styl","hash":"702b9299a48c90124e3ac1d45f1591042f2beccc","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/sunburst.styl","hash":"a0b5b5129547a23865d400cfa562ea0ac1ee3958","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/tomorrow-night-blue.styl","hash":"8b3087d4422be6eb800935a22eb11e035341c4ba","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/tomorrow-night-bright.styl","hash":"0ac6af6ecb446b5b60d6226748e4a6532db34f57","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/tomorrow-night-eighties.styl","hash":"fa57b3bb7857a160fc856dbe319b31e30cc5d771","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/tomorrow-night.styl","hash":"19b3080d4b066b40d50d7e7f297472482b5801fd","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_highlight/zenburn.styl","hash":"fc5ec840435dad80964d04519d3f882ddc03746a","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_partial/archive.styl","hash":"18fa7f84a9783c5fb56c9f450ea93bd88408e682","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_partial/article.styl","hash":"3dbf627d9f27ebf0b10cdc4d28341e35786b3cf5","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_partial/comments.styl","hash":"11fb41241a13971d23fc3f7e6d60315c7f248396","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_partial/footer.styl","hash":"344f6877733a488f7f07f87fbaa518295948766f","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_partial/header.styl","hash":"86676f767cfacd9203477de5ed1545bd51b0169c","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_partial/index.styl","hash":"cf43702450ea1e5617541501886982a394cff8ec","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_partial/pagination.styl","hash":"03a1b81d60dae3dd55963b7e74a6fee83470e6bb","modified":1521451810000},{"_id":"themes/cactus-dark/source/lib/justified-gallery/jquery.justifiedGallery.min.js","hash":"b2683e7a872bc109b1756a65188a37cef7d0bd5c","modified":1521451811000},{"_id":"themes/cactus-dark/source/lib/justified-gallery/justifiedGallery.min.css","hash":"13fbcba5e97aa88b748d94d3efc4718475279907","modified":1521451811000},{"_id":"themes/cactus-dark/source/lib/meslo-LG/styles.css","hash":"eb88d0b9f1bbef99070e9627e2c96d892036bf7e","modified":1521451810000},{"_id":"source/images/halite_game.png","hash":"d67ea5a35af5f4cf91808c78eb156e259fbf50bf","modified":1521451808000},{"_id":"themes/cactus-dark/source/lib/jquery/jquery.min.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1521451811000},{"_id":"themes/cactus-dark/source/css/_partial/post/actions_desktop.styl","hash":"a9f9b6382d313f9ef9ff9f53bd0db11e5b36edf4","modified":1521451810000},{"_id":"themes/cactus-dark/source/css/_partial/post/actions_mobile.styl","hash":"e6a802d7ee1023c5fc5fac18bb0ba3dc03ef2ac8","modified":1521451810000},{"_id":"themes/cactus-dark/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1521451811000},{"_id":"themes/cactus-dark/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1521451811000},{"_id":"themes/cactus-dark/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1521451811000},{"_id":"themes/cactus-dark/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1521451811000},{"_id":"themes/cactus-dark/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1521451811000},{"_id":"themes/cactus-dark/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1521451811000},{"_id":"themes/cactus-dark/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1521451811000},{"_id":"themes/cactus-dark/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1521451811000},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGL-Italic.ttf","hash":"96c97a0a098ca40802f948ae56fa37aa6683d034","modified":1521451810000},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGM-Italic.ttf","hash":"68700db02debd4b922304134da83b829cbfddfc9","modified":1521451811000},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGS-Italic.ttf","hash":"7f7cdbdcc26279c04046632e22d872f111bc9399","modified":1521451811000},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGL-Bold.ttf","hash":"bfa1ed9a263ed78462f06d322de13bd5bd0906b2","modified":1521451810000},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGL-BoldItalic.ttf","hash":"a9a431fc7a6c3a67c98021d4035c12a07a4f1070","modified":1521451811000},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGL-Regular.ttf","hash":"2b912dd13f052f645ee19951604610bb350d50af","modified":1521451810000},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGM-BoldItalic.ttf","hash":"65ddb11e75ee93909e845ab912a36717c48f1c94","modified":1521451811000},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGM-Bold.ttf","hash":"a8a8df3393bccc365335fc5eb0a62a6b7ccd32b9","modified":1521451810000},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGS-Bold.ttf","hash":"df202ce09cbdc70bc16b81983a13ef0f94e46f10","modified":1521451811000},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGM-Regular.ttf","hash":"5e220152adefe905b2197f873d7cee99eca50e91","modified":1521451810000},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGS-BoldItalic.ttf","hash":"d895a1bd25e36c58b7f463ebe14de09f186d5ab4","modified":1521451811000},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGS-Regular.ttf","hash":"56fa0e33a390b704afc56af93a31576ccdbbdd9e","modified":1521451811000},{"_id":"public/sitemap.xml","hash":"d3445cc48dffd1792967bcb84b46837104cfbb00","modified":1526073096019},{"_id":"public/articles/index.html","hash":"563c642ae8efaf71eb0b2f4658cf48a02a65d95a","modified":1526073096285},{"_id":"public/about/index.html","hash":"8816915e6d41e673c597b02012b619432351dfad","modified":1526073096285},{"_id":"public/linkeddata-trivia-game.html","hash":"c34b4184775cd3c2618f8140335fd6d21ba0c254","modified":1526073096285},{"_id":"public/http20-server-push-proxy.html","hash":"cbfc75f4c67045555ce5746f8ceccd3cfc69cc28","modified":1526073096285},{"_id":"public/web-development-technology-stack.html","hash":"5a04e47bc696adba2f9ce7209f1b5f73be7e0270","modified":1526073096285},{"_id":"public/instant-messenger-security-encryption-overview.html","hash":"acd4def85c72ac6afca3d41834eb1aa96b0aba14","modified":1526073096285},{"_id":"public/telegram-bot-example-code-in-nodejs.html","hash":"97d00334a270470b546abde660af46bce5e05b6c","modified":1526073096285},{"_id":"public/linux-cache-information-bash-script.html","hash":"7fa0718cbf8d5355d22acaa3eb3b87617c9b6f0b","modified":1526073096286},{"_id":"public/index.html","hash":"a0855f735c7ff96d1554469435efaa6039a04af6","modified":1526073096286},{"_id":"public/page/2/index.html","hash":"9e091bd1ae37b26818708fee9bd20592d13915d2","modified":1526073096286},{"_id":"public/archives/index.html","hash":"8d872028ce79848d1c419226fe90d4916b196d9c","modified":1526073096286},{"_id":"public/archives/page/2/index.html","hash":"0bda16a4c3bd0e72504521016dcdbe90726b84de","modified":1526073096286},{"_id":"public/archives/2015/index.html","hash":"c1b65d14a21048b2024a7987625c8f7311c5f25d","modified":1526073096286},{"_id":"public/archives/2015/02/index.html","hash":"55819dd2af30a248bd5c48b778c228376c9d258e","modified":1526073096286},{"_id":"public/archives/2015/06/index.html","hash":"ffd34360997352bbd2d075a8d5ce68d3d401e2e4","modified":1526073096286},{"_id":"public/archives/2015/11/index.html","hash":"48572047c52ceb7fe443ba9af950ca70ed7d7866","modified":1526073096286},{"_id":"public/archives/2015/12/index.html","hash":"9a13fe63de3294479edf33fbe0eac3e0a472125a","modified":1526073096286},{"_id":"public/archives/2016/index.html","hash":"9f9f45a07d9867db69fd4fbd09fe4061341ac16f","modified":1526073096286},{"_id":"public/archives/2016/02/index.html","hash":"1ecd27ccd9e7e94cf791821b6e7bac54a94987c6","modified":1526073096286},{"_id":"public/archives/2016/03/index.html","hash":"5a33767ad8187a8080c8db2d6bee9fc46f4c0132","modified":1526073096286},{"_id":"public/archives/2016/04/index.html","hash":"282397a8a76ecc1c7e5de9d25d52ffc5c958aff0","modified":1526073096286},{"_id":"public/archives/2016/05/index.html","hash":"feb16f9fbe67441d4f3ccd1676c5362ce7f8e23d","modified":1526073096286},{"_id":"public/archives/2016/07/index.html","hash":"af3e4bb35681c419c5a4b5418374c2d85e09ae63","modified":1526073096286},{"_id":"public/archives/2016/09/index.html","hash":"4bfbf7dccfd1ca4289317fb0b8021aa865f9e081","modified":1526073096287},{"_id":"public/archives/2016/10/index.html","hash":"52d1bd85166e5e4fc8aa71f494fa602aa6ea4d4d","modified":1526073096287},{"_id":"public/archives/2016/11/index.html","hash":"852699af142e6bf6d7628e226d9b3d11e1fa294c","modified":1526073096287},{"_id":"public/archives/2017/index.html","hash":"eaa264cbf6ecbb11deb86e5ebd4baa55fedc5a57","modified":1526073096287},{"_id":"public/archives/2017/01/index.html","hash":"76e8bcc2e2768521dae1ed49797e85a161e77bc3","modified":1526073096287},{"_id":"public/archives/2017/02/index.html","hash":"e6bba8e1300f696e805ab97a9c20654db3c53024","modified":1526073096287},{"_id":"public/archives/2017/07/index.html","hash":"b63765b1ef540c51aa261cd89eef78c3984e4ac7","modified":1526073096287},{"_id":"public/archives/2017/08/index.html","hash":"6b2c9431123279c2778f272f54ac7747c0261aab","modified":1526073096287},{"_id":"public/archives/2017/09/index.html","hash":"11ee8a57e70ed1f3a3936400a664efae5e4c7964","modified":1526073096287},{"_id":"public/archives/2018/index.html","hash":"dd5cfada6fcf2a279b2a2e51a18941df01a15762","modified":1526073096287},{"_id":"public/archives/2018/01/index.html","hash":"d4341b77bd56ae6fd69f0c67991d80061ad2064f","modified":1526073096287},{"_id":"public/imprint/index.html","hash":"db11854f805a64d91f2d72f01e9c72811f1ac8ff","modified":1526073096287},{"_id":"public/halite-a-rule-based-ai-bot.html","hash":"870151e42f07039b6a05f4cde63cbdfc5b863f5f","modified":1526073096287},{"_id":"public/cartpole-with-a-deep-q-network.html","hash":"4a85d282fa595a63623094f019f7b225f8443b33","modified":1526073096288},{"_id":"public/cartpole-with-qlearning-first-experiences-with-openai-gym.html","hash":"48a0d74247ae88d51107cec5eebe8dadf6934a40","modified":1526073096288},{"_id":"public/telegram-middleman-bot-push-notifications-as-easy-as-post.html","hash":"210b14fb437118dee73a560d7fc08226004e04bf","modified":1526073096288},{"_id":"public/ml-telegram-chat-message-classification.html","hash":"9ec86dcd25f6b73f8a51a5f55ca676788f096b41","modified":1526073096288},{"_id":"public/caddy-a-modern-web-server-vs-nginx.html","hash":"660e2773888b3c0f544d750a665a865a0e6884e7","modified":1526073096288},{"_id":"public/http-performance-java-jersey-vs-go-vs-nodejs.html","hash":"5b24f7015025fa447958c2d6875b7413c0f7da4d","modified":1526073096288},{"_id":"public/my-teck-stack-if-i-had-to-build-an-app-today.html","hash":"87e6089fc80ddf339b0a6f45aee0eaf94a648a78","modified":1526073096288},{"_id":"public/how-to-load-yago-into-apache-jena-fuseki.html","hash":"bbf562bb3e35b878b616fb3f254ff4a3848de379","modified":1526073096288},{"_id":"public/design-of-a-linked-dataenabled-microservice-platform-for-the-industrial-internet-of-things.html","hash":"8f722e4e6b979638c3f46c9ede7e995f573f3f09","modified":1526073096288},{"_id":"public/webdevlistnet-the-developers-resource-collection.html","hash":"292858987ff98f9c71aac649e797f6f5d0e840ac","modified":1526073096288},{"_id":"public/migrate-maildir-to-new-server-using-imapsync.html","hash":"b654578316560ffad323f837d2068912e7756bb4","modified":1526073096288},{"_id":"public/innovation-in-germany-not.html","hash":"efaca5ad9b4bf8a79a240a0a95e02739e69b8c23","modified":1526073096288},{"_id":"public/telegram-expensebot-doodlerbot.html","hash":"91f557a4cce9edd7c04d5eb537f9653fcab26701","modified":1526073096288},{"_id":"public/unhostedorg-applications-with-remotestorageio-and-webfingernet.html","hash":"b537267bde054e2af62a7b29067f7357fdacbf89","modified":1526073096288},{"_id":"public/how-do-whatsapps-end-to-end-encrypted-group-chats-work.html","hash":"76a1afd7ecd55f6d2d5edfc602b4c9ebb51f3eca","modified":1526073096289},{"_id":"public/digitalocean-my-preferred-cloud-hosting-provider.html","hash":"4f47c53e4a1bfe50c3c3d140d8bae8eca60cee74","modified":1526073096289},{"_id":"public/learning-angular2-what-is-new.html","hash":"7dcfbed0b5fc1ca9981ec5e6069e09b3050fc88d","modified":1526073096289},{"_id":"public/anchr-io-image-uploads-bookmarks-and-shortlink-service.html","hash":"e7860f8c3767ed8e27e2dfe18e07ca274d260925","modified":1526073096289},{"_id":"public/why-raid-10-is-better-than-raid-01.html","hash":"dac59e12c5b113ddea09f2cc74a59ac3e4454fd8","modified":1526073096289},{"_id":"public/how-to-make-telegram-bots.html","hash":"5553485043897d59a9b222903488464fccab3433","modified":1526073096289},{"_id":"public/images/anchr_2.jpg","hash":"d07dfedb2fc549983f63bf7251f3d011b96188aa","modified":1526073096305},{"_id":"public/images/anchr_1.jpg","hash":"0d50b24329bdcddea234f0c3ade3f2846daae148","modified":1526073096305},{"_id":"public/images/angular2_logo.png","hash":"189713e0c0de88477c6726fc59b4cd1cfb16b05e","modified":1526073096305},{"_id":"public/images/apple-touch-icon.png","hash":"07059d8fe92f685176d96045edb70c01deb8c4d0","modified":1526073096305},{"_id":"public/images/Webserver_memory_graph.jpg","hash":"aeaf52174560a2d3a7ff32fda21a26b96c907cc9","modified":1526073096305},{"_id":"public/images/benchmarks.svg","hash":"e9fbfdf69d7ac1c9890d541fb07d69f844fbb99a","modified":1526073096306},{"_id":"public/images/benchmarks2.svg","hash":"c4bd56f99f3a8810fd50a3caf7a99213b407a0d5","modified":1526073096306},{"_id":"public/images/cartpole1.jpg","hash":"3e237ad7b3bb78ada0d507c8f644a791797b194e","modified":1526073096306},{"_id":"public/images/cartpole2.png","hash":"bb292c589bd25b8b59c75989377163232d29b1c8","modified":1526073096306},{"_id":"public/images/cartpole3.png","hash":"03883366ab1f16b607653ef239b99ede1ac56efc","modified":1526073096306},{"_id":"public/images/cartpole4.png","hash":"d92a7e37c8e88986a51e9a7e6b0124093b5a7425","modified":1526073096306},{"_id":"public/images/doodlerbot_icon.png","hash":"7e548feeabd180f1e5af390365ce88fe70fe619e","modified":1526073096306},{"_id":"public/images/dqn1.png","hash":"500531da445ad95337e7d60b0834ce15ed235b41","modified":1526073096306},{"_id":"public/images/dqn2.png","hash":"07d2f6e25d0328c8986d173efab87bc59e63f944","modified":1526073096306},{"_id":"public/images/dqn3.png","hash":"664f10963a00e2d66fe7dde7e78848d26dbf78cd","modified":1526073096306},{"_id":"public/images/dqn4.png","hash":"e564dd5d0e8258145f93d65eb1a600a9d5489826","modified":1526073096306},{"_id":"public/images/expensebot_icon.png","hash":"479cb80aa0620db49e0a353ac7f550f7cc9f205d","modified":1526073096306},{"_id":"public/images/halite_langs.png","hash":"68561eee10ca68ffafaadcbe07056dc039d3be23","modified":1526073096306},{"_id":"public/images/middleman.png","hash":"f09ddfd0c8c0973d16567a1122981e6b14db615b","modified":1526073096306},{"_id":"public/images/middleman2.png","hash":"456e72dd3824a95589cc264627b81596eb589f96","modified":1526073096306},{"_id":"public/images/push_screenshot1.png","hash":"91d5fa3e4c5a3a3d0f369a8d90055d029e8ef28e","modified":1526073096306},{"_id":"public/images/push_screenshot2.png","hash":"144ca3caed3e5b9285f7f8edeba41917266ed529","modified":1526073096307},{"_id":"public/images/raid01.png","hash":"15da9f10e5a4d3f452287daf4420da8582d3ad31","modified":1526073096307},{"_id":"public/images/statista.png","hash":"4385242cac93067b8ca8dd02c01a1778bf1c6102","modified":1526073096307},{"_id":"public/images/raid10.png","hash":"ae8cb17a2ae2eba7d238a8d56136f60823172242","modified":1526073096307},{"_id":"public/images/trivia.jpg","hash":"8e7715fa940d79f43fd1e2a9ff8c2149cf0b11a8","modified":1526073096307},{"_id":"public/images/unhosted.jpg","hash":"6e0bde1ad7bfb3ba8d9b634f6518299e2d9d1f1b","modified":1526073096307},{"_id":"public/images/webdev_techstack.png","hash":"e3f4b8cdac4233ebcb5d7e20ee42703c9ffad6ba","modified":1526073096307},{"_id":"public/images/webdevlist.jpg","hash":"cfa9e038e301cdcd577c7833fc8b220f6c0d6a98","modified":1526073096307},{"_id":"public/images/webserver_performance.png","hash":"737f74276f3832a342464110566fdab49593de94","modified":1526073096307},{"_id":"public/images/whatsapp_logo.png","hash":"197552fa1ec1aefb1c912e52272d6d2d032e76f6","modified":1526073096307},{"_id":"public/images/favicon-192x192.png","hash":"07059d8fe92f685176d96045edb70c01deb8c4d0","modified":1526073096307},{"_id":"public/images/favicon.ico","hash":"164bc240105d72d826efc048442d85dcf90d2cce","modified":1526073096307},{"_id":"public/images/do.png","hash":"dd43ce0ffde6885ad251e6e4edff64b36ddecd02","modified":1526073096528},{"_id":"public/images/webdev_techstack_large.png","hash":"76169ecb9523c245c6588156fcff24c851b5c43b","modified":1526073096528},{"_id":"public/images/webservers.png","hash":"c1550f9bcb7350c9ebef5090484960877d8dda55","modified":1526073096529},{"_id":"public/images/thesis_mockup.png","hash":"a5ec4a8949edd6a168c866c675ab6c4e2bc00d33","modified":1526073096529},{"_id":"public/images/thesis_stack.png","hash":"5a410fcb932c552dbc0096f59fda594be334e9cd","modified":1526073096529},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1526073096529},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1526073096530},{"_id":"public/js/main.js","hash":"2703a7cb4fc7056d13215b9fde675da426b9cdc4","modified":1526073096571},{"_id":"public/lib/justified-gallery/justifiedGallery.min.css","hash":"13fbcba5e97aa88b748d94d3efc4718475279907","modified":1526073096571},{"_id":"public/lib/meslo-LG/styles.css","hash":"eb88d0b9f1bbef99070e9627e2c96d892036bf7e","modified":1526073096572},{"_id":"public/css/style.css","hash":"c8c2e4e887bc9e64d5e57ddb77c38c15b054991f","modified":1526073096572},{"_id":"public/lib/justified-gallery/jquery.justifiedGallery.min.js","hash":"b2683e7a872bc109b1756a65188a37cef7d0bd5c","modified":1526073096572},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1526073096572},{"_id":"public/lib/jquery/jquery.min.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1526073096572},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1526073096572},{"_id":"public/images/scorecard.jpg","hash":"e4b56c4f825d42890e6c735c17d6a29a80a7f075","modified":1526073096572},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1526073096572},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1526073096572},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1526073096572},{"_id":"public/images/halite_game.png","hash":"d67ea5a35af5f4cf91808c78eb156e259fbf50bf","modified":1526073096579},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1526073096581},{"_id":"public/lib/meslo-LG/fonts/MesloLGM-Italic.ttf","hash":"68700db02debd4b922304134da83b829cbfddfc9","modified":1526073096584},{"_id":"public/lib/meslo-LG/fonts/MesloLGL-Italic.ttf","hash":"96c97a0a098ca40802f948ae56fa37aa6683d034","modified":1526073096584},{"_id":"public/lib/meslo-LG/fonts/MesloLGS-Italic.ttf","hash":"7f7cdbdcc26279c04046632e22d872f111bc9399","modified":1526073096585},{"_id":"public/lib/meslo-LG/fonts/MesloLGL-Bold.ttf","hash":"bfa1ed9a263ed78462f06d322de13bd5bd0906b2","modified":1526073096586},{"_id":"public/lib/meslo-LG/fonts/MesloLGL-BoldItalic.ttf","hash":"a9a431fc7a6c3a67c98021d4035c12a07a4f1070","modified":1526073096586},{"_id":"public/lib/meslo-LG/fonts/MesloLGL-Regular.ttf","hash":"2b912dd13f052f645ee19951604610bb350d50af","modified":1526073096586},{"_id":"public/lib/meslo-LG/fonts/MesloLGM-BoldItalic.ttf","hash":"65ddb11e75ee93909e845ab912a36717c48f1c94","modified":1526073096587},{"_id":"public/lib/meslo-LG/fonts/MesloLGM-Bold.ttf","hash":"a8a8df3393bccc365335fc5eb0a62a6b7ccd32b9","modified":1526073096587},{"_id":"public/lib/meslo-LG/fonts/MesloLGS-Bold.ttf","hash":"df202ce09cbdc70bc16b81983a13ef0f94e46f10","modified":1526073096587},{"_id":"public/lib/meslo-LG/fonts/MesloLGM-Regular.ttf","hash":"5e220152adefe905b2197f873d7cee99eca50e91","modified":1526073096588},{"_id":"public/lib/meslo-LG/fonts/MesloLGS-BoldItalic.ttf","hash":"d895a1bd25e36c58b7f463ebe14de09f186d5ab4","modified":1526073096588},{"_id":"public/lib/meslo-LG/fonts/MesloLGS-Regular.ttf","hash":"56fa0e33a390b704afc56af93a31576ccdbbdd9e","modified":1526073096588}],"Category":[],"Data":[{"_id":"projects","data":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}],"Page":[{"title":"Articles","date":"2017-09-13T20:43:52.000Z","_content":"\n# Articles\n\nThis is a collection of articles, blog posts, scientific papers and other resources I found on the internet, which I consider interesting, helpful, well-written or something to think about. They are not in any particular order.\n\n ## General\n * [Please do learn to code](https://medium.freecodecamp.org/please-do-learn-to-code-233597dd141c)\n * [My Google Internship](http://www.goldsborough.me/google/internship/2016/11/18/01-57-54-my_google_internship_/)\n * [What are 10 things that you should definitely do before turning 30?](https://www.quora.com/What-are-10-things-that-you-should-definitely-do-before-turning-30/answer/K-John-25?srid=uBHCu)\n * [From Coding To Management To Leadership](https://dev.to/lpasqualis/from-coding-to-management-to-leadership)\n\n## Web Development\n * [The State of Developer Ecosystem in 2017](https://www.jetbrains.com/research/devecosystem-2017/)\n * [Stack Overflow Developer Survey 2017](http://stackoverflow.com/insights/survey/2017/#technology-most-loved-dreaded-and-wanted-languages)\n * [Web Developer Security Checklist](https://simplesecurity.sensedeep.com/web-developer-security-checklist-f2e4f43c9c56)\n * [Websocket Shootout: Clojure, C++, Elixir, Go, NodeJS, and Ruby](https://hashrocket.com/blog/posts/websocket-shootout)\n * [Understanding the NodeJS event loop](http://blog.mixu.net/2011/02/01/understanding-the-node-js-event-loop/)\n * [5 Reasons to Use Protocol Buffers Instead of JSON](http://blog.codeclimate.com/blog/2014/06/05/choose-protocol-buffers/)\n * [Understanding Reactive Programming and RxJS](https://auth0.com/blog/understanding-reactive-programming-and-rxjs)\n * [How We Moved Our API From Ruby to Go and Saved Our Sanity](http://blog.parse.com/learn/how-we-moved-our-api-from-ruby-to-go-and-saved-our-sanity/)\n * [10 things I learned making the fastest site in the world](https://hackernoon.com/10-things-i-learned-making-the-fastest-site-in-the-world-18a0e1cdf4a7#.syz3poebn)\n\n## Operations & Other\n * [Why arenâ€™t we using SSH for everything?](https://medium.com/@shazow/ssh-how-does-it-even-9e43586e4ffc)\n * [what-happens-when](https://github.com/alex/what-happens-when/blob/master/README.rst#the-g-key-is-pressed)\n\n## Machine Learning & Data Analytics\n * [Introduction to Deep Learning 2016](https://blog.algorithmia.com/introduction-to-deep-learning-2016/)\n * [Instagram photos reveal predictive markers of depression](https://epjdatascience.springeropen.com/articles/10.1140/epjds/s13688-017-0110-z)\n * [Deep Q-Learning with Keras and Gym](https://keon.io/deep-q-learning/)","source":"articles/index.md","raw":"---\ntitle: Articles\ndate: 2017-09-13 22:43:52\n---\n\n# Articles\n\nThis is a collection of articles, blog posts, scientific papers and other resources I found on the internet, which I consider interesting, helpful, well-written or something to think about. They are not in any particular order.\n\n ## General\n * [Please do learn to code](https://medium.freecodecamp.org/please-do-learn-to-code-233597dd141c)\n * [My Google Internship](http://www.goldsborough.me/google/internship/2016/11/18/01-57-54-my_google_internship_/)\n * [What are 10 things that you should definitely do before turning 30?](https://www.quora.com/What-are-10-things-that-you-should-definitely-do-before-turning-30/answer/K-John-25?srid=uBHCu)\n * [From Coding To Management To Leadership](https://dev.to/lpasqualis/from-coding-to-management-to-leadership)\n\n## Web Development\n * [The State of Developer Ecosystem in 2017](https://www.jetbrains.com/research/devecosystem-2017/)\n * [Stack Overflow Developer Survey 2017](http://stackoverflow.com/insights/survey/2017/#technology-most-loved-dreaded-and-wanted-languages)\n * [Web Developer Security Checklist](https://simplesecurity.sensedeep.com/web-developer-security-checklist-f2e4f43c9c56)\n * [Websocket Shootout: Clojure, C++, Elixir, Go, NodeJS, and Ruby](https://hashrocket.com/blog/posts/websocket-shootout)\n * [Understanding the NodeJS event loop](http://blog.mixu.net/2011/02/01/understanding-the-node-js-event-loop/)\n * [5 Reasons to Use Protocol Buffers Instead of JSON](http://blog.codeclimate.com/blog/2014/06/05/choose-protocol-buffers/)\n * [Understanding Reactive Programming and RxJS](https://auth0.com/blog/understanding-reactive-programming-and-rxjs)\n * [How We Moved Our API From Ruby to Go and Saved Our Sanity](http://blog.parse.com/learn/how-we-moved-our-api-from-ruby-to-go-and-saved-our-sanity/)\n * [10 things I learned making the fastest site in the world](https://hackernoon.com/10-things-i-learned-making-the-fastest-site-in-the-world-18a0e1cdf4a7#.syz3poebn)\n\n## Operations & Other\n * [Why arenâ€™t we using SSH for everything?](https://medium.com/@shazow/ssh-how-does-it-even-9e43586e4ffc)\n * [what-happens-when](https://github.com/alex/what-happens-when/blob/master/README.rst#the-g-key-is-pressed)\n\n## Machine Learning & Data Analytics\n * [Introduction to Deep Learning 2016](https://blog.algorithmia.com/introduction-to-deep-learning-2016/)\n * [Instagram photos reveal predictive markers of depression](https://epjdatascience.springeropen.com/articles/10.1140/epjds/s13688-017-0110-z)\n * [Deep Q-Learning with Keras and Gym](https://keon.io/deep-q-learning/)","updated":"2018-03-19T09:30:08.000Z","path":"articles/index.html","comments":1,"layout":"page","_id":"cjh2gioli0000cxrgkdlef1rm","content":"<h1 id=\"Articles\"><a href=\"#Articles\" class=\"headerlink\" title=\"Articles\"></a>Articles</h1><p>This is a collection of articles, blog posts, scientific papers and other resources I found on the internet, which I consider interesting, helpful, well-written or something to think about. They are not in any particular order.</p>\n<h2 id=\"General\"><a href=\"#General\" class=\"headerlink\" title=\"General\"></a>General</h2><ul>\n<li><a href=\"https://medium.freecodecamp.org/please-do-learn-to-code-233597dd141c\" target=\"_blank\" rel=\"noopener\">Please do learn to code</a></li>\n<li><a href=\"http://www.goldsborough.me/google/internship/2016/11/18/01-57-54-my_google_internship_/\" target=\"_blank\" rel=\"noopener\">My Google Internship</a></li>\n<li><a href=\"https://www.quora.com/What-are-10-things-that-you-should-definitely-do-before-turning-30/answer/K-John-25?srid=uBHCu\" target=\"_blank\" rel=\"noopener\">What are 10 things that you should definitely do before turning 30?</a></li>\n<li><a href=\"https://dev.to/lpasqualis/from-coding-to-management-to-leadership\" target=\"_blank\" rel=\"noopener\">From Coding To Management To Leadership</a></li>\n</ul>\n<h2 id=\"Web-Development\"><a href=\"#Web-Development\" class=\"headerlink\" title=\"Web Development\"></a>Web Development</h2><ul>\n<li><a href=\"https://www.jetbrains.com/research/devecosystem-2017/\" target=\"_blank\" rel=\"noopener\">The State of Developer Ecosystem in 2017</a></li>\n<li><a href=\"http://stackoverflow.com/insights/survey/2017/#technology-most-loved-dreaded-and-wanted-languages\" target=\"_blank\" rel=\"noopener\">Stack Overflow Developer Survey 2017</a></li>\n<li><a href=\"https://simplesecurity.sensedeep.com/web-developer-security-checklist-f2e4f43c9c56\" target=\"_blank\" rel=\"noopener\">Web Developer Security Checklist</a></li>\n<li><a href=\"https://hashrocket.com/blog/posts/websocket-shootout\" target=\"_blank\" rel=\"noopener\">Websocket Shootout: Clojure, C++, Elixir, Go, NodeJS, and Ruby</a></li>\n<li><a href=\"http://blog.mixu.net/2011/02/01/understanding-the-node-js-event-loop/\" target=\"_blank\" rel=\"noopener\">Understanding the NodeJS event loop</a></li>\n<li><a href=\"http://blog.codeclimate.com/blog/2014/06/05/choose-protocol-buffers/\" target=\"_blank\" rel=\"noopener\">5 Reasons to Use Protocol Buffers Instead of JSON</a></li>\n<li><a href=\"https://auth0.com/blog/understanding-reactive-programming-and-rxjs\" target=\"_blank\" rel=\"noopener\">Understanding Reactive Programming and RxJS</a></li>\n<li><a href=\"http://blog.parse.com/learn/how-we-moved-our-api-from-ruby-to-go-and-saved-our-sanity/\" target=\"_blank\" rel=\"noopener\">How We Moved Our API From Ruby to Go and Saved Our Sanity</a></li>\n<li><a href=\"https://hackernoon.com/10-things-i-learned-making-the-fastest-site-in-the-world-18a0e1cdf4a7#.syz3poebn\" target=\"_blank\" rel=\"noopener\">10 things I learned making the fastest site in the world</a></li>\n</ul>\n<h2 id=\"Operations-amp-Other\"><a href=\"#Operations-amp-Other\" class=\"headerlink\" title=\"Operations &amp; Other\"></a>Operations &amp; Other</h2><ul>\n<li><a href=\"https://medium.com/@shazow/ssh-how-does-it-even-9e43586e4ffc\" target=\"_blank\" rel=\"noopener\">Why arenâ€™t we using SSH for everything?</a></li>\n<li><a href=\"https://github.com/alex/what-happens-when/blob/master/README.rst#the-g-key-is-pressed\" target=\"_blank\" rel=\"noopener\">what-happens-when</a></li>\n</ul>\n<h2 id=\"Machine-Learning-amp-Data-Analytics\"><a href=\"#Machine-Learning-amp-Data-Analytics\" class=\"headerlink\" title=\"Machine Learning &amp; Data Analytics\"></a>Machine Learning &amp; Data Analytics</h2><ul>\n<li><a href=\"https://blog.algorithmia.com/introduction-to-deep-learning-2016/\" target=\"_blank\" rel=\"noopener\">Introduction to Deep Learning 2016</a></li>\n<li><a href=\"https://epjdatascience.springeropen.com/articles/10.1140/epjds/s13688-017-0110-z\" target=\"_blank\" rel=\"noopener\">Instagram photos reveal predictive markers of depression</a></li>\n<li><a href=\"https://keon.io/deep-q-learning/\" target=\"_blank\" rel=\"noopener\">Deep Q-Learning with Keras and Gym</a></li>\n</ul>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<h1 id=\"Articles\"><a href=\"#Articles\" class=\"headerlink\" title=\"Articles\"></a>Articles</h1><p>This is a collection of articles, blog posts, scientific papers and other resources I found on the internet, which I consider interesting, helpful, well-written or something to think about. They are not in any particular order.</p>\n<h2 id=\"General\"><a href=\"#General\" class=\"headerlink\" title=\"General\"></a>General</h2><ul>\n<li><a href=\"https://medium.freecodecamp.org/please-do-learn-to-code-233597dd141c\" target=\"_blank\" rel=\"noopener\">Please do learn to code</a></li>\n<li><a href=\"http://www.goldsborough.me/google/internship/2016/11/18/01-57-54-my_google_internship_/\" target=\"_blank\" rel=\"noopener\">My Google Internship</a></li>\n<li><a href=\"https://www.quora.com/What-are-10-things-that-you-should-definitely-do-before-turning-30/answer/K-John-25?srid=uBHCu\" target=\"_blank\" rel=\"noopener\">What are 10 things that you should definitely do before turning 30?</a></li>\n<li><a href=\"https://dev.to/lpasqualis/from-coding-to-management-to-leadership\" target=\"_blank\" rel=\"noopener\">From Coding To Management To Leadership</a></li>\n</ul>\n<h2 id=\"Web-Development\"><a href=\"#Web-Development\" class=\"headerlink\" title=\"Web Development\"></a>Web Development</h2><ul>\n<li><a href=\"https://www.jetbrains.com/research/devecosystem-2017/\" target=\"_blank\" rel=\"noopener\">The State of Developer Ecosystem in 2017</a></li>\n<li><a href=\"http://stackoverflow.com/insights/survey/2017/#technology-most-loved-dreaded-and-wanted-languages\" target=\"_blank\" rel=\"noopener\">Stack Overflow Developer Survey 2017</a></li>\n<li><a href=\"https://simplesecurity.sensedeep.com/web-developer-security-checklist-f2e4f43c9c56\" target=\"_blank\" rel=\"noopener\">Web Developer Security Checklist</a></li>\n<li><a href=\"https://hashrocket.com/blog/posts/websocket-shootout\" target=\"_blank\" rel=\"noopener\">Websocket Shootout: Clojure, C++, Elixir, Go, NodeJS, and Ruby</a></li>\n<li><a href=\"http://blog.mixu.net/2011/02/01/understanding-the-node-js-event-loop/\" target=\"_blank\" rel=\"noopener\">Understanding the NodeJS event loop</a></li>\n<li><a href=\"http://blog.codeclimate.com/blog/2014/06/05/choose-protocol-buffers/\" target=\"_blank\" rel=\"noopener\">5 Reasons to Use Protocol Buffers Instead of JSON</a></li>\n<li><a href=\"https://auth0.com/blog/understanding-reactive-programming-and-rxjs\" target=\"_blank\" rel=\"noopener\">Understanding Reactive Programming and RxJS</a></li>\n<li><a href=\"http://blog.parse.com/learn/how-we-moved-our-api-from-ruby-to-go-and-saved-our-sanity/\" target=\"_blank\" rel=\"noopener\">How We Moved Our API From Ruby to Go and Saved Our Sanity</a></li>\n<li><a href=\"https://hackernoon.com/10-things-i-learned-making-the-fastest-site-in-the-world-18a0e1cdf4a7#.syz3poebn\" target=\"_blank\" rel=\"noopener\">10 things I learned making the fastest site in the world</a></li>\n</ul>\n<h2 id=\"Operations-amp-Other\"><a href=\"#Operations-amp-Other\" class=\"headerlink\" title=\"Operations &amp; Other\"></a>Operations &amp; Other</h2><ul>\n<li><a href=\"https://medium.com/@shazow/ssh-how-does-it-even-9e43586e4ffc\" target=\"_blank\" rel=\"noopener\">Why arenâ€™t we using SSH for everything?</a></li>\n<li><a href=\"https://github.com/alex/what-happens-when/blob/master/README.rst#the-g-key-is-pressed\" target=\"_blank\" rel=\"noopener\">what-happens-when</a></li>\n</ul>\n<h2 id=\"Machine-Learning-amp-Data-Analytics\"><a href=\"#Machine-Learning-amp-Data-Analytics\" class=\"headerlink\" title=\"Machine Learning &amp; Data Analytics\"></a>Machine Learning &amp; Data Analytics</h2><ul>\n<li><a href=\"https://blog.algorithmia.com/introduction-to-deep-learning-2016/\" target=\"_blank\" rel=\"noopener\">Introduction to Deep Learning 2016</a></li>\n<li><a href=\"https://epjdatascience.springeropen.com/articles/10.1140/epjds/s13688-017-0110-z\" target=\"_blank\" rel=\"noopener\">Instagram photos reveal predictive markers of depression</a></li>\n<li><a href=\"https://keon.io/deep-q-learning/\" target=\"_blank\" rel=\"noopener\">Deep Q-Learning with Keras and Gym</a></li>\n</ul>\n"},{"title":"about","date":"2017-05-03T20:21:16.000Z","_content":"\n# About\n\nHey, welcome and thank you for visiting my webpage! My name is Ferdinand MÃ¼tsch,  aâ€™m 23 years young and currently living in Karlsruhe, Germany. I am studying [information engineering and management](http://informationswirtschaft.org), which basically is a mixture of 40 % computer science, 40 % economics and 20 % law â€“ at the [Karlsruhe Institute of Technology](http://kit.edu). Currently, I am in the fourth Master's semester after having finished my Bachelor's thesis at [TECO](http://teco.edu) in 2016 and about to graduate as a Master Of Science by the end of 2018.\n\nMy interests are â€“ among others â€“ software development, especially in a web- and mobile context as well as IT operations. I consider myself pretty open-minded and I am continuously interested in new technology. Currently I am deepening on the subjects of Data Mining and Machine Learning.\n\nBesides my studies I am working as a student employee at [Inovex](http://inovex.de) in Karlsruhe and as a self-employed **Freelancer developer**. Accordingly, I have participated in realizing software projects for small and mid-sized businesses in the context of Industry 4.0, customer data analytics, corporate intranet solutions and customer self-service platforms. If you are curious about my projects as a Freelancer or interested in working with me please feel free to contact me!\n\n__My topics__:\nFull-Stack Web, Mobile, Machine Learning, Data Mining\n\n__My programming languages:__\nJavaScript (++++), Java (+++), Pyhton (+++), TypeScript (++), Go (++), PHP (++), R (+)\n\n__My technologies:__\n[NodeJS](http://nodejs.org), [ExpressJS](http://expressjs.com/), [AngularJS](https://angularjs.org/), [Angular2](http://angular.io), [Ionic](http://ionicframework.com/), [Spring Boot](http://projects.spring.io/spring-boot/), Android SDK, [GraphQL](http://graphql.org/), [Scikit-Learn](http://scikit-learn.org/), [Docker](http://docker.com/) and many more...\n\nIf you are interested in some of my private software projects, check out the [Projects section](/#projects) or take a look at [my profile on GitHub](https://github.com/n1try). Please also take a look at my [Xing profile](https://www.xing.com/profile/Ferdinand_Muetsch).","source":"about/index.md","raw":"---\ntitle: about\ndate: 2017-05-03 22:21:16\n---\n\n# About\n\nHey, welcome and thank you for visiting my webpage! My name is Ferdinand MÃ¼tsch,  aâ€™m 23 years young and currently living in Karlsruhe, Germany. I am studying [information engineering and management](http://informationswirtschaft.org), which basically is a mixture of 40 % computer science, 40 % economics and 20 % law â€“ at the [Karlsruhe Institute of Technology](http://kit.edu). Currently, I am in the fourth Master's semester after having finished my Bachelor's thesis at [TECO](http://teco.edu) in 2016 and about to graduate as a Master Of Science by the end of 2018.\n\nMy interests are â€“ among others â€“ software development, especially in a web- and mobile context as well as IT operations. I consider myself pretty open-minded and I am continuously interested in new technology. Currently I am deepening on the subjects of Data Mining and Machine Learning.\n\nBesides my studies I am working as a student employee at [Inovex](http://inovex.de) in Karlsruhe and as a self-employed **Freelancer developer**. Accordingly, I have participated in realizing software projects for small and mid-sized businesses in the context of Industry 4.0, customer data analytics, corporate intranet solutions and customer self-service platforms. If you are curious about my projects as a Freelancer or interested in working with me please feel free to contact me!\n\n__My topics__:\nFull-Stack Web, Mobile, Machine Learning, Data Mining\n\n__My programming languages:__\nJavaScript (++++), Java (+++), Pyhton (+++), TypeScript (++), Go (++), PHP (++), R (+)\n\n__My technologies:__\n[NodeJS](http://nodejs.org), [ExpressJS](http://expressjs.com/), [AngularJS](https://angularjs.org/), [Angular2](http://angular.io), [Ionic](http://ionicframework.com/), [Spring Boot](http://projects.spring.io/spring-boot/), Android SDK, [GraphQL](http://graphql.org/), [Scikit-Learn](http://scikit-learn.org/), [Docker](http://docker.com/) and many more...\n\nIf you are interested in some of my private software projects, check out the [Projects section](/#projects) or take a look at [my profile on GitHub](https://github.com/n1try). Please also take a look at my [Xing profile](https://www.xing.com/profile/Ferdinand_Muetsch).","updated":"2018-05-11T21:11:30.235Z","path":"about/index.html","comments":1,"layout":"page","_id":"cjh2gioln0002cxrgbjxviknz","content":"<h1 id=\"About\"><a href=\"#About\" class=\"headerlink\" title=\"About\"></a>About</h1><p>Hey, welcome and thank you for visiting my webpage! My name is Ferdinand MÃ¼tsch,  aâ€™m 23 years young and currently living in Karlsruhe, Germany. I am studying <a href=\"http://informationswirtschaft.org\" target=\"_blank\" rel=\"noopener\">information engineering and management</a>, which basically is a mixture of 40 % computer science, 40 % economics and 20 % law â€“ at the <a href=\"http://kit.edu\" target=\"_blank\" rel=\"noopener\">Karlsruhe Institute of Technology</a>. Currently, I am in the fourth Masterâ€™s semester after having finished my Bachelorâ€™s thesis at <a href=\"http://teco.edu\" target=\"_blank\" rel=\"noopener\">TECO</a> in 2016 and about to graduate as a Master Of Science by the end of 2018.</p>\n<p>My interests are â€“ among others â€“ software development, especially in a web- and mobile context as well as IT operations. I consider myself pretty open-minded and I am continuously interested in new technology. Currently I am deepening on the subjects of Data Mining and Machine Learning.</p>\n<p>Besides my studies I am working as a student employee at <a href=\"http://inovex.de\" target=\"_blank\" rel=\"noopener\">Inovex</a> in Karlsruhe and as a self-employed <strong>Freelancer developer</strong>. Accordingly, I have participated in realizing software projects for small and mid-sized businesses in the context of Industry 4.0, customer data analytics, corporate intranet solutions and customer self-service platforms. If you are curious about my projects as a Freelancer or interested in working with me please feel free to contact me!</p>\n<p><strong>My topics</strong>:<br>Full-Stack Web, Mobile, Machine Learning, Data Mining</p>\n<p><strong>My programming languages:</strong><br>JavaScript (++++), Java (+++), Pyhton (+++), TypeScript (++), Go (++), PHP (++), R (+)</p>\n<p><strong>My technologies:</strong><br><a href=\"http://nodejs.org\" target=\"_blank\" rel=\"noopener\">NodeJS</a>, <a href=\"http://expressjs.com/\" target=\"_blank\" rel=\"noopener\">ExpressJS</a>, <a href=\"https://angularjs.org/\" target=\"_blank\" rel=\"noopener\">AngularJS</a>, <a href=\"http://angular.io\" target=\"_blank\" rel=\"noopener\">Angular2</a>, <a href=\"http://ionicframework.com/\" target=\"_blank\" rel=\"noopener\">Ionic</a>, <a href=\"http://projects.spring.io/spring-boot/\" target=\"_blank\" rel=\"noopener\">Spring Boot</a>, Android SDK, <a href=\"http://graphql.org/\" target=\"_blank\" rel=\"noopener\">GraphQL</a>, <a href=\"http://scikit-learn.org/\" target=\"_blank\" rel=\"noopener\">Scikit-Learn</a>, <a href=\"http://docker.com/\" target=\"_blank\" rel=\"noopener\">Docker</a> and many moreâ€¦</p>\n<p>If you are interested in some of my private software projects, check out the <a href=\"/#projects\">Projects section</a> or take a look at <a href=\"https://github.com/n1try\" target=\"_blank\" rel=\"noopener\">my profile on GitHub</a>. Please also take a look at my <a href=\"https://www.xing.com/profile/Ferdinand_Muetsch\" target=\"_blank\" rel=\"noopener\">Xing profile</a>.</p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<h1 id=\"About\"><a href=\"#About\" class=\"headerlink\" title=\"About\"></a>About</h1><p>Hey, welcome and thank you for visiting my webpage! My name is Ferdinand MÃ¼tsch,  aâ€™m 23 years young and currently living in Karlsruhe, Germany. I am studying <a href=\"http://informationswirtschaft.org\" target=\"_blank\" rel=\"noopener\">information engineering and management</a>, which basically is a mixture of 40 % computer science, 40 % economics and 20 % law â€“ at the <a href=\"http://kit.edu\" target=\"_blank\" rel=\"noopener\">Karlsruhe Institute of Technology</a>. Currently, I am in the fourth Masterâ€™s semester after having finished my Bachelorâ€™s thesis at <a href=\"http://teco.edu\" target=\"_blank\" rel=\"noopener\">TECO</a> in 2016 and about to graduate as a Master Of Science by the end of 2018.</p>\n<p>My interests are â€“ among others â€“ software development, especially in a web- and mobile context as well as IT operations. I consider myself pretty open-minded and I am continuously interested in new technology. Currently I am deepening on the subjects of Data Mining and Machine Learning.</p>\n<p>Besides my studies I am working as a student employee at <a href=\"http://inovex.de\" target=\"_blank\" rel=\"noopener\">Inovex</a> in Karlsruhe and as a self-employed <strong>Freelancer developer</strong>. Accordingly, I have participated in realizing software projects for small and mid-sized businesses in the context of Industry 4.0, customer data analytics, corporate intranet solutions and customer self-service platforms. If you are curious about my projects as a Freelancer or interested in working with me please feel free to contact me!</p>\n<p><strong>My topics</strong>:<br>Full-Stack Web, Mobile, Machine Learning, Data Mining</p>\n<p><strong>My programming languages:</strong><br>JavaScript (++++), Java (+++), Pyhton (+++), TypeScript (++), Go (++), PHP (++), R (+)</p>\n<p><strong>My technologies:</strong><br><a href=\"http://nodejs.org\" target=\"_blank\" rel=\"noopener\">NodeJS</a>, <a href=\"http://expressjs.com/\" target=\"_blank\" rel=\"noopener\">ExpressJS</a>, <a href=\"https://angularjs.org/\" target=\"_blank\" rel=\"noopener\">AngularJS</a>, <a href=\"http://angular.io\" target=\"_blank\" rel=\"noopener\">Angular2</a>, <a href=\"http://ionicframework.com/\" target=\"_blank\" rel=\"noopener\">Ionic</a>, <a href=\"http://projects.spring.io/spring-boot/\" target=\"_blank\" rel=\"noopener\">Spring Boot</a>, Android SDK, <a href=\"http://graphql.org/\" target=\"_blank\" rel=\"noopener\">GraphQL</a>, <a href=\"http://scikit-learn.org/\" target=\"_blank\" rel=\"noopener\">Scikit-Learn</a>, <a href=\"http://docker.com/\" target=\"_blank\" rel=\"noopener\">Docker</a> and many moreâ€¦</p>\n<p>If you are interested in some of my private software projects, check out the <a href=\"/#projects\">Projects section</a> or take a look at <a href=\"https://github.com/n1try\" target=\"_blank\" rel=\"noopener\">my profile on GitHub</a>. Please also take a look at my <a href=\"https://www.xing.com/profile/Ferdinand_Muetsch\" target=\"_blank\" rel=\"noopener\">Xing profile</a>.</p>\n"},{"title":"imprint","date":"2017-05-03T20:30:32.000Z","_content":"\n# Imprint\n\n### Legal Disclosure & Privacy Statement\nInformation in accordance with section 5 German TMG\n\n```\nFerdinand MÃ¼tsch\nVorholzstraÃŸe 11 \n76137 Karlsruhe\nGermany\n```\n\n### Contact\n```\nTelephone: 0ï¸âƒ£1ï¸âƒ£7ï¸âƒ£6ï¸âƒ£4ï¸âƒ£5ï¸âƒ£6ï¸âƒ£4ï¸âƒ£1ï¸âƒ£9ï¸âƒ£7ï¸âƒ£4ï¸âƒ£\nE-Mail: mail@ferdinand-muetsch.de\nWeb: www.ferdinand-muetsch.de\n```\n\n### Disclaimer\n#### Accountability for content\nThe contents of our pages have been created with the utmost care. However, we cannot guarantee the contents' accuracy, completeness or topicality. According to statutory provisions, we are furthermore responsible for our own content on these web pages. In this context, please note that we are accordingly not obliged to monitor merely the transmitted or saved information of third parties, or investigate circumstances pointing to illegal activity. Our obligations to remove or block the use of information under generally applicable laws remain unaffected by this as per Â§Â§ 8 to 10 of the Telemedia Act (TMG).\n\n#### Accountability for links\nResponsibility for the content of external links (to web pages of third parties) lies solely with the operators of the linked pages. No violations were evident to us at the time of linking. Should any legal infringement become known to us, we will remove the respective link immediately. \n\n#### Copyright\nOur web pages and their contents are subject to German copyright law. Unless expressly permitted by law (Â§ 44a et seq. of the copyright law), every form of utilizing, reproducing or processing works subject to copyright protection on our web pages requires the prior consent of the respective owner of the rights. Individual reproductions of a work are allowed only for private use, so must not serve either directly or indirectly for earnings. Unauthorized utilization of copyrighted works is punishable (Â§ 106 of the copyright law).\n\n#### General\nYour personal data (e.g. title, name, house address, e-mail address, phone number, bank details, credit card number) are processed by us only in accordance with the provisions of German data privacy laws. The following provisions describe the type, scope and purpose of collecting, processing and utilizing personal data. This data privacy policy applies only to our web pages. If links on our pages route you to other pages, please inquire there about how your data are handled in such cases.\n\n#### Inventory data\n(1) Your personal data, insofar as these are necessary for this contractual relationship (inventory data) in terms of its establishment, organization of content and modifications, are used exclusively for fulfilling the contract. For goods to be delivered, for instance, your name and address must be relayed to the supplier of the goods. \n(2) Without your explicit consent or a legal basis, your personal data are not passed on to third parties outside the scope of fulfilling this contract. After completion of the contract, your data are blocked against further use. After expiry of deadlines as per tax-related and commercial regulations, these data are deleted unless you have expressly consented to their further use.\n\n#### Information about cookies\n(1) To optimize our web presence, we use cookies. These are small text files stored in your computer's main memory. These cookies are deleted after you close the browser. Other cookies remain on your computer (long-term cookies) and permit its recognition on your next visit. This allows us to improve your access to our site.\n(2) You can prevent storage of cookies by choosing a \"disable cookies\" option in your browser settings. But this can limit the functionality of our Internet offers as a result.\n\n#### Disclosure\nAccording to the Federal Data Protection Act, you have a right to free-of-charge information about your stored data, and possibly entitlement to correction, blocking or deletion of such data. Inquiries can be directed to the following e-mail addresses: ( [mail@ferdinand-muetsch.de](mailto:mail@ferdinand-muetsch.de) )\n\nSource: [twiggs translations](http://www.twigg.de/)\n\n### German Privacy Policy (DatenschutzerklÃ¤rung)\nDiese DatenschutzerklÃ¤rung klÃ¤rt Sie Ã¼ber die Art, den Umfang und Zweck der Verarbeitung von personenbezogenen Daten (nachfolgend kurz â€žDatenâ€œ) innerhalb unseres Onlineangebotes und der mit ihm verbundenen Webseiten, Funktionen und Inhalte sowie externen OnlineprÃ¤senzen, wie z.B. unser Social Media Profile auf. (nachfolgend gemeinsam bezeichnet als â€žOnlineangebotâ€œ). Im Hinblick auf die verwendeten Begrifflichkeiten, wie z.B. â€žVerarbeitungâ€œ oder â€žVerantwortlicherâ€œ verweisen wir auf die Definitionen im Art. 4 der Datenschutzgrundverordnung (DSGVO).\n\n#### Arten der verarbeiteten Daten:\n- Bestandsdaten (z.B., Namen, Adressen).\n- Kontaktdaten (z.B., E-Mail, Telefonnummern).\n- Inhaltsdaten (z.B., Texteingaben, Fotografien, Videos).\n- Nutzungsdaten (z.B., besuchte Webseiten, Interesse an Inhalten, Zugriffszeiten).\n- Meta-/Kommunikationsdaten (z.B., GerÃ¤te-Informationen, IP-Adressen).\n\n#### Kategorien betroffener Personen\nBesucher und Nutzer des Onlineangebotes (Nachfolgend bezeichnen wir die betroffenen Personen zusammenfassend auch als â€žNutzerâ€œ).\n\n#### Zweck der Verarbeitung\n- ZurverfÃ¼gungstellung des Onlineangebotes, seiner Funktionen und Inhalte.\n- Beantwortung von Kontaktanfragen und Kommunikation mit Nutzern.\n- SicherheitsmaÃŸnahmen.\n- Reichweitenmessung/Marketing\n\n#### Verwendete Begrifflichkeiten \nâ€žPersonenbezogene Datenâ€œ sind alle Informationen, die sich auf eine identifizierte oder identifizierbare natÃ¼rliche Person (im Folgenden â€žbetroffene Personâ€œ) beziehen; als identifizierbar wird eine natÃ¼rliche Person angesehen, die direkt oder indirekt, insbesondere mittels Zuordnung zu einer Kennung wie einem Namen, zu einer Kennnummer, zu Standortdaten, zu einer Online-Kennung (z.B. Cookie) oder zu einem oder mehreren besonderen Merkmalen identifiziert werden kann, die Ausdruck der physischen, physiologischen, genetischen, psychischen, wirtschaftlichen, kulturellen oder sozialen IdentitÃ¤t dieser natÃ¼rlichen Person sind.\n\nâ€žVerarbeitungâ€œ ist jeder mit oder ohne Hilfe automatisierter Verfahren ausgefÃ¼hrten Vorgang oder jede solche Vorgangsreihe im Zusammenhang mit personenbezogenen Daten. Der Begriff reicht weit und umfasst praktisch jeden Umgang mit Daten.\n\nAls â€žVerantwortlicherâ€œ wird die natÃ¼rliche oder juristische Person, BehÃ¶rde, Einrichtung oder andere Stelle, die allein oder gemeinsam mit anderen Ã¼ber die Zwecke und Mittel der Verarbeitung von personenbezogenen Daten entscheidet, bezeichnet.\n\n#### MaÃŸgebliche Rechtsgrundlagen\nNach MaÃŸgabe des Art. 13 DSGVO teilen wir Ihnen die Rechtsgrundlagen unserer Datenverarbeitungen mit. Sofern die Rechtsgrundlage in der DatenschutzerklÃ¤rung nicht genannt wird, gilt Folgendes: Die Rechtsgrundlage fÃ¼r die Einholung von Einwilligungen ist Art. 6 Abs. 1 lit. a und Art. 7 DSGVO, die Rechtsgrundlage fÃ¼r die Verarbeitung zur ErfÃ¼llung unserer Leistungen und DurchfÃ¼hrung vertraglicher MaÃŸnahmen sowie Beantwortung von Anfragen ist Art. 6 Abs. 1 lit. b DSGVO, die Rechtsgrundlage fÃ¼r die Verarbeitung zur ErfÃ¼llung unserer rechtlichen Verpflichtungen ist Art. 6 Abs. 1 lit. c DSGVO, und die Rechtsgrundlage fÃ¼r die Verarbeitung zur Wahrung unserer berechtigten Interessen ist Art. 6 Abs. 1 lit. f DSGVO. FÃ¼r den Fall, dass lebenswichtige Interessen der betroffenen Person oder einer anderen natÃ¼rlichen Person eine Verarbeitung personenbezogener Daten erforderlich machen, dient Art. 6 Abs. 1 lit. d DSGVO als Rechtsgrundlage.\n\n#### Zusammenarbeit mit Auftragsverarbeitern und Dritten\nSofern wir im Rahmen unserer Verarbeitung Daten gegenÃ¼ber anderen Personen und Unternehmen (Auftragsverarbeitern oder Dritten) offenbaren, sie an diese Ã¼bermitteln oder ihnen sonst Zugriff auf die Daten gewÃ¤hren, erfolgt dies nur auf Grundlage einer gesetzlichen Erlaubnis (z.B. wenn eine Ãœbermittlung der Daten an Dritte, wie an Zahlungsdienstleister, gem. Art. 6 Abs. 1 lit. b DSGVO zur VertragserfÃ¼llung erforderlich ist), Sie eingewilligt haben, eine rechtliche Verpflichtung dies vorsieht oder auf Grundlage unserer berechtigten Interessen (z.B. beim Einsatz von Beauftragten, Webhostern, etc.).\n\nSofern wir Dritte mit der Verarbeitung von Daten auf Grundlage eines sog. â€žAuftragsverarbeitungsvertragesâ€œ beauftragen, geschieht dies auf Grundlage des Art. 28 DSGVO.\n\n#### Ãœbermittlungen in DrittlÃ¤nder\nSofern wir Daten in einem Drittland (d.h. auÃŸerhalb der EuropÃ¤ischen Union (EU) oder des EuropÃ¤ischen Wirtschaftsraums (EWR)) verarbeiten oder dies im Rahmen der Inanspruchnahme von Diensten Dritter oder Offenlegung, bzw. Ãœbermittlung von Daten an Dritte geschieht, erfolgt dies nur, wenn es zur ErfÃ¼llung unserer (vor)vertraglichen Pflichten, auf Grundlage Ihrer Einwilligung, aufgrund einer rechtlichen Verpflichtung oder auf Grundlage unserer berechtigten Interessen geschieht. Vorbehaltlich gesetzlicher oder vertraglicher Erlaubnisse, verarbeiten oder lassen wir die Daten in einem Drittland nur beim Vorliegen der besonderen Voraussetzungen der Art. 44 ff. DSGVO verarbeiten. D.h. die Verarbeitung erfolgt z.B. auf Grundlage besonderer Garantien, wie der offiziell anerkannten Feststellung eines der EU entsprechenden Datenschutzniveaus (z.B. fÃ¼r die USA durch das â€žPrivacy Shieldâ€œ) oder Beachtung offiziell anerkannter spezieller vertraglicher Verpflichtungen (so genannte â€žStandardvertragsklauselnâ€œ).\n\n#### Rechte der betroffenen Personen\nSie haben das Recht, eine BestÃ¤tigung darÃ¼ber zu verlangen, ob betreffende Daten verarbeitet werden und auf Auskunft Ã¼ber diese Daten sowie auf weitere Informationen und Kopie der Daten entsprechend Art. 15 DSGVO.\n\nSie haben entsprechend. Art. 16 DSGVO das Recht, die VervollstÃ¤ndigung der Sie betreffenden Daten oder die Berichtigung der Sie betreffenden unrichtigen Daten zu verlangen.\n\nSie haben nach MaÃŸgabe des Art. 17 DSGVO das Recht zu verlangen, dass betreffende Daten unverzÃ¼glich gelÃ¶scht werden, bzw. alternativ nach MaÃŸgabe des Art. 18 DSGVO eine EinschrÃ¤nkung der Verarbeitung der Daten zu verlangen.\n\nSie haben das Recht zu verlangen, dass die Sie betreffenden Daten, die Sie uns bereitgestellt haben nach MaÃŸgabe des Art. 20 DSGVO zu erhalten und deren Ãœbermittlung an andere Verantwortliche zu fordern.\n\nSie haben ferner gem. Art. 77 DSGVO das Recht, eine Beschwerde bei der zustÃ¤ndigen AufsichtsbehÃ¶rde einzureichen.\n\n#### Widerrufsrecht\nSie haben das Recht, erteilte Einwilligungen gem. Art. 7 Abs. 3 DSGVO mit Wirkung fÃ¼r die Zukunft zu widerrufen\n\n#### Widerspruchsrecht\nSie kÃ¶nnen der kÃ¼nftigen Verarbeitung der Sie betreffenden Daten nach MaÃŸgabe des Art. 21 DSGVO jederzeit widersprechen. Der Widerspruch kann insbesondere gegen die Verarbeitung fÃ¼r Zwecke der Direktwerbung erfolgen.\n\n#### Cookies und Widerspruchsrecht bei Direktwerbung\nAls â€žCookiesâ€œ werden kleine Dateien bezeichnet, die auf Rechnern der Nutzer gespeichert werden. Innerhalb der Cookies kÃ¶nnen unterschiedliche Angaben gespeichert werden. Ein Cookie dient primÃ¤r dazu, die Angaben zu einem Nutzer (bzw. dem GerÃ¤t auf dem das Cookie gespeichert ist) wÃ¤hrend oder auch nach seinem Besuch innerhalb eines Onlineangebotes zu speichern. Als temporÃ¤re Cookies, bzw. â€žSession-Cookiesâ€œ oder â€žtransiente Cookiesâ€œ, werden Cookies bezeichnet, die gelÃ¶scht werden, nachdem ein Nutzer ein Onlineangebot verlÃ¤sst und seinen Browser schlieÃŸt. In einem solchen Cookie kann z.B. der Inhalt eines Warenkorbs in einem Onlineshop oder ein Login-Staus gespeichert werden. Als â€žpermanentâ€œ oder â€žpersistentâ€œ werden Cookies bezeichnet, die auch nach dem SchlieÃŸen des Browsers gespeichert bleiben. So kann z.B. der Login-Status gespeichert werden, wenn die Nutzer diese nach mehreren Tagen aufsuchen. Ebenso kÃ¶nnen in einem solchen Cookie die Interessen der Nutzer gespeichert werden, die fÃ¼r Reichweitenmessung oder Marketingzwecke verwendet werden. Als â€žThird-Party-Cookieâ€œ werden Cookies bezeichnet, die von anderen Anbietern als dem Verantwortlichen, der das Onlineangebot betreibt, angeboten werden (andernfalls, wenn es nur dessen Cookies sind spricht man von â€žFirst-Party Cookiesâ€œ).\n\nWir kÃ¶nnen temporÃ¤re und permanente Cookies einsetzen und klÃ¤ren hierÃ¼ber im Rahmen unserer DatenschutzerklÃ¤rung auf.\n\nFalls die Nutzer nicht mÃ¶chten, dass Cookies auf ihrem Rechner gespeichert werden, werden sie gebeten die entsprechende Option in den Systemeinstellungen ihres Browsers zu deaktivieren. Gespeicherte Cookies kÃ¶nnen in den Systemeinstellungen des Browsers gelÃ¶scht werden. Der Ausschluss von Cookies kann zu FunktionseinschrÃ¤nkungen dieses Onlineangebotes fÃ¼hren.\n\nEin genereller Widerspruch gegen den Einsatz der zu Zwecken des Onlinemarketing eingesetzten Cookies kann bei einer Vielzahl der Dienste, vor allem im Fall des Trackings, Ã¼ber die US-amerikanische Seite http://www.aboutads.info/choices/ oder die EU-Seite http://www.youronlinechoices.com/ erklÃ¤rt werden. Des Weiteren kann die Speicherung von Cookies mittels deren Abschaltung in den Einstellungen des Browsers erreicht werden. Bitte beachten Sie, dass dann gegebenenfalls nicht alle Funktionen dieses Onlineangebotes genutzt werden kÃ¶nnen.\n\n#### LÃ¶schung von Daten\nDie von uns verarbeiteten Daten werden nach MaÃŸgabe der Art. 17 und 18 DSGVO gelÃ¶scht oder in ihrer Verarbeitung eingeschrÃ¤nkt. Sofern nicht im Rahmen dieser DatenschutzerklÃ¤rung ausdrÃ¼cklich angegeben, werden die bei uns gespeicherten Daten gelÃ¶scht, sobald sie fÃ¼r ihre Zweckbestimmung nicht mehr erforderlich sind und der LÃ¶schung keine gesetzlichen Aufbewahrungspflichten entgegenstehen. Sofern die Daten nicht gelÃ¶scht werden, weil sie fÃ¼r andere und gesetzlich zulÃ¤ssige Zwecke erforderlich sind, wird deren Verarbeitung eingeschrÃ¤nkt. D.h. die Daten werden gesperrt und nicht fÃ¼r andere Zwecke verarbeitet. Das gilt z.B. fÃ¼r Daten, die aus handels- oder steuerrechtlichen GrÃ¼nden aufbewahrt werden mÃ¼ssen.\n\nNach gesetzlichen Vorgaben in Deutschland erfolgt die Aufbewahrung insbesondere fÃ¼r 6 Jahre gemÃ¤ÃŸ Â§ 257 Abs. 1 HGB (HandelsbÃ¼cher, Inventare, ErÃ¶ffnungsbilanzen, JahresabschlÃ¼sse, Handelsbriefe, Buchungsbelege, etc.) sowie fÃ¼r 10 Jahre gemÃ¤ÃŸ Â§ 147 Abs. 1 AO (BÃ¼cher, Aufzeichnungen, Lageberichte, Buchungsbelege, Handels- und GeschÃ¤ftsbriefe, FÃ¼r Besteuerung relevante Unterlagen, etc.).\n\nNach gesetzlichen Vorgaben in Ã–sterreich erfolgt die Aufbewahrung insbesondere fÃ¼r 7 J gemÃ¤ÃŸ Â§ 132 Abs. 1 BAO (Buchhaltungsunterlagen, Belege/Rechnungen, Konten, Belege, GeschÃ¤ftspapiere, Aufstellung der Einnahmen und Ausgaben, etc.), fÃ¼r 22 Jahre im Zusammenhang mit GrundstÃ¼cken und fÃ¼r 10 Jahre bei Unterlagen im Zusammenhang mit elektronisch erbrachten Leistungen, Telekommunikations-, Rundfunk- und Fernsehleistungen, die an Nichtunternehmer in EU-Mitgliedstaaten erbracht werden und fÃ¼r die der Mini-One-Stop-Shop (MOSS) in Anspruch genommen wird.\n\n#### Hosting\nDie von uns in Anspruch genommenen Hosting-Leistungen dienen der ZurverfÃ¼gungstellung der folgenden Leistungen: Infrastruktur- und Plattformdienstleistungen, RechenkapazitÃ¤t, Speicherplatz und Datenbankdienste, Sicherheitsleistungen sowie technische Wartungsleistungen, die wir zum Zwecke des Betriebs dieses Onlineangebotes einsetzen.\n\nHierbei verarbeiten wir, bzw. unser Hostinganbieter Bestandsdaten, Kontaktdaten, Inhaltsdaten, Vertragsdaten, Nutzungsdaten, Meta- und Kommunikationsdaten von Kunden, Interessenten und Besuchern dieses Onlineangebotes auf Grundlage unserer berechtigten Interessen an einer effizienten und sicheren ZurverfÃ¼gungstellung dieses Onlineangebotes gem. Art. 6 Abs. 1 lit. f DSGVO i.V.m. Art. 28 DSGVO (Abschluss Auftragsverarbeitungsvertrag).\n\n#### Erhebung von Zugriffsdaten und Logfiles\nWir, bzw. unser Hostinganbieter, erhebt auf Grundlage unserer berechtigten Interessen im Sinne des Art. 6 Abs. 1 lit. f. DSGVO Daten Ã¼ber jeden Zugriff auf den Server, auf dem sich dieser Dienst befindet (sogenannte Serverlogfiles). Zu den Zugriffsdaten gehÃ¶ren Name der abgerufenen Webseite, Datei, Datum und Uhrzeit des Abrufs, Ã¼bertragene Datenmenge, Meldung Ã¼ber erfolgreichen Abruf, Browsertyp nebst Version, das Betriebssystem des Nutzers, Referrer URL (die zuvor besuchte Seite), IP-Adresse und der anfragende Provider.\n\nLogfile-Informationen werden aus SicherheitsgrÃ¼nden (z.B. zur AufklÃ¤rung von Missbrauchs- oder Betrugshandlungen) fÃ¼r die Dauer von maximal 7 Tagen gespeichert und danach gelÃ¶scht. Daten, deren weitere Aufbewahrung zu Beweiszwecken erforderlich ist, sind bis zur endgÃ¼ltigen KlÃ¤rung des jeweiligen Vorfalls von der LÃ¶schung ausgenommen.\n\n#### Google Universal Analytics\nWir setzen auf Grundlage unserer berechtigten Interessen (d.h. Interesse an der Analyse, Optimierung und wirtschaftlichem Betrieb unseres Onlineangebotes im Sinne des Art. 6 Abs. 1 lit. f. DSGVO) Google Analytics, einen Webanalysedienst der Google LLC (â€žGoogleâ€œ) ein. Google verwendet Cookies. Die durch das Cookie erzeugten Informationen Ã¼ber Benutzung des Onlineangebotes durch die Nutzer werden in der Regel an einen Server von Google in den USA Ã¼bertragen und dort gespeichert.\n\nGoogle ist unter dem Privacy-Shield-Abkommen zertifiziert und bietet hierdurch eine Garantie, das europÃ¤ische Datenschutzrecht einzuhalten (https://www.privacyshield.gov/participant?id=a2zt000000001L5AAI&status=Active).\n\nGoogle wird diese Informationen in unserem Auftrag benutzen, um die Nutzung unseres Onlineangebotes durch die Nutzer auszuwerten, um Reports Ã¼ber die AktivitÃ¤ten innerhalb dieses Onlineangebotes zusammenzustellen und um weitere, mit der Nutzung dieses Onlineangebotes und der Internetnutzung verbundene Dienstleistungen, uns gegenÃ¼ber zu erbringen. Dabei kÃ¶nnen aus den verarbeiteten Daten pseudonyme Nutzungsprofile der Nutzer erstellt werden.\n\nWir setzen Google Analytics in der Ausgestaltung als â€žUniversal-Analyticsâ€œ ein. â€žUniversal Analyticsâ€œ bezeichnet ein Verfahren von Google Analytics, bei dem die Nutzeranalyse auf Grundlage einer pseudonymen Nutzer-ID erfolgt und damit ein pseudonymes Profil des Nutzers mit Informationen aus der Nutzung verschiedener GerÃ¤ten erstellt wird (sog. â€žCross-Device-Trackingâ€œ).\n\nWir setzen Google Analytics nur mit aktivierter IP-Anonymisierung ein. Das bedeutet, die IP-Adresse der Nutzer wird von Google innerhalb von Mitgliedstaaten der EuropÃ¤ischen Union oder in anderen Vertragsstaaten des Abkommens Ã¼ber den EuropÃ¤ischen Wirtschaftsraum gekÃ¼rzt. Nur in AusnahmefÃ¤llen wird die volle IP-Adresse an einen Server von Google in den USA Ã¼bertragen und dort gekÃ¼rzt.\n\nDie von dem Browser des Nutzers Ã¼bermittelte IP-Adresse wird nicht mit anderen Daten von Google zusammengefÃ¼hrt. Die Nutzer kÃ¶nnen die Speicherung der Cookies durch eine entsprechende Einstellung ihrer Browser-Software verhindern; die Nutzer kÃ¶nnen darÃ¼ber hinaus die Erfassung der durch das Cookie erzeugten und auf ihre Nutzung des Onlineangebotes bezogenen Daten an Google sowie die Verarbeitung dieser Daten durch Google verhindern, indem sie das unter folgendem Link verfÃ¼gbare Browser-Plugin herunterladen und installieren: http://tools.google.com/dlpage/gaoptout?hl=de.\n\nWeitere Informationen zur Datennutzung durch Google, Einstellungs- und WiderspruchsmÃ¶glichkeiten erfahren Sie auf den Webseiten von Google: https://www.google.com/intl/de/policies/privacy/partners (â€žDatennutzung durch Google bei Ihrer Nutzung von Websites oder Apps unserer Partnerâ€œ), http://www.google.com/policies/technologies/ads (â€žDatennutzung zu Werbezweckenâ€œ), http://www.google.de/settings/ads (â€žInformationen verwalten, die Google verwendet, um Ihnen Werbung einzublendenâ€œ).\n\n#### Youtube\nWir binden die Videos der Plattform â€œYouTubeâ€ des Anbieters Google LLC, 1600 Amphitheatre Parkway, Mountain View, CA 94043, USA, ein. DatenschutzerklÃ¤rung: https://www.google.com/policies/privacy/, Opt-Out: https://adssettings.google.com/authenticated.\n\n[Erstellt mit Datenschutz-Generator.de von RA Dr. Thomas Schwenke](https://datenschutz-generator.de/)","source":"imprint/index.md","raw":"---\ntitle: imprint\ndate: 2017-05-03 22:30:32\n---\n\n# Imprint\n\n### Legal Disclosure & Privacy Statement\nInformation in accordance with section 5 German TMG\n\n```\nFerdinand MÃ¼tsch\nVorholzstraÃŸe 11 \n76137 Karlsruhe\nGermany\n```\n\n### Contact\n```\nTelephone: 0ï¸âƒ£1ï¸âƒ£7ï¸âƒ£6ï¸âƒ£4ï¸âƒ£5ï¸âƒ£6ï¸âƒ£4ï¸âƒ£1ï¸âƒ£9ï¸âƒ£7ï¸âƒ£4ï¸âƒ£\nE-Mail: mail@ferdinand-muetsch.de\nWeb: www.ferdinand-muetsch.de\n```\n\n### Disclaimer\n#### Accountability for content\nThe contents of our pages have been created with the utmost care. However, we cannot guarantee the contents' accuracy, completeness or topicality. According to statutory provisions, we are furthermore responsible for our own content on these web pages. In this context, please note that we are accordingly not obliged to monitor merely the transmitted or saved information of third parties, or investigate circumstances pointing to illegal activity. Our obligations to remove or block the use of information under generally applicable laws remain unaffected by this as per Â§Â§ 8 to 10 of the Telemedia Act (TMG).\n\n#### Accountability for links\nResponsibility for the content of external links (to web pages of third parties) lies solely with the operators of the linked pages. No violations were evident to us at the time of linking. Should any legal infringement become known to us, we will remove the respective link immediately. \n\n#### Copyright\nOur web pages and their contents are subject to German copyright law. Unless expressly permitted by law (Â§ 44a et seq. of the copyright law), every form of utilizing, reproducing or processing works subject to copyright protection on our web pages requires the prior consent of the respective owner of the rights. Individual reproductions of a work are allowed only for private use, so must not serve either directly or indirectly for earnings. Unauthorized utilization of copyrighted works is punishable (Â§ 106 of the copyright law).\n\n#### General\nYour personal data (e.g. title, name, house address, e-mail address, phone number, bank details, credit card number) are processed by us only in accordance with the provisions of German data privacy laws. The following provisions describe the type, scope and purpose of collecting, processing and utilizing personal data. This data privacy policy applies only to our web pages. If links on our pages route you to other pages, please inquire there about how your data are handled in such cases.\n\n#### Inventory data\n(1) Your personal data, insofar as these are necessary for this contractual relationship (inventory data) in terms of its establishment, organization of content and modifications, are used exclusively for fulfilling the contract. For goods to be delivered, for instance, your name and address must be relayed to the supplier of the goods. \n(2) Without your explicit consent or a legal basis, your personal data are not passed on to third parties outside the scope of fulfilling this contract. After completion of the contract, your data are blocked against further use. After expiry of deadlines as per tax-related and commercial regulations, these data are deleted unless you have expressly consented to their further use.\n\n#### Information about cookies\n(1) To optimize our web presence, we use cookies. These are small text files stored in your computer's main memory. These cookies are deleted after you close the browser. Other cookies remain on your computer (long-term cookies) and permit its recognition on your next visit. This allows us to improve your access to our site.\n(2) You can prevent storage of cookies by choosing a \"disable cookies\" option in your browser settings. But this can limit the functionality of our Internet offers as a result.\n\n#### Disclosure\nAccording to the Federal Data Protection Act, you have a right to free-of-charge information about your stored data, and possibly entitlement to correction, blocking or deletion of such data. Inquiries can be directed to the following e-mail addresses: ( [mail@ferdinand-muetsch.de](mailto:mail@ferdinand-muetsch.de) )\n\nSource: [twiggs translations](http://www.twigg.de/)\n\n### German Privacy Policy (DatenschutzerklÃ¤rung)\nDiese DatenschutzerklÃ¤rung klÃ¤rt Sie Ã¼ber die Art, den Umfang und Zweck der Verarbeitung von personenbezogenen Daten (nachfolgend kurz â€žDatenâ€œ) innerhalb unseres Onlineangebotes und der mit ihm verbundenen Webseiten, Funktionen und Inhalte sowie externen OnlineprÃ¤senzen, wie z.B. unser Social Media Profile auf. (nachfolgend gemeinsam bezeichnet als â€žOnlineangebotâ€œ). Im Hinblick auf die verwendeten Begrifflichkeiten, wie z.B. â€žVerarbeitungâ€œ oder â€žVerantwortlicherâ€œ verweisen wir auf die Definitionen im Art. 4 der Datenschutzgrundverordnung (DSGVO).\n\n#### Arten der verarbeiteten Daten:\n- Bestandsdaten (z.B., Namen, Adressen).\n- Kontaktdaten (z.B., E-Mail, Telefonnummern).\n- Inhaltsdaten (z.B., Texteingaben, Fotografien, Videos).\n- Nutzungsdaten (z.B., besuchte Webseiten, Interesse an Inhalten, Zugriffszeiten).\n- Meta-/Kommunikationsdaten (z.B., GerÃ¤te-Informationen, IP-Adressen).\n\n#### Kategorien betroffener Personen\nBesucher und Nutzer des Onlineangebotes (Nachfolgend bezeichnen wir die betroffenen Personen zusammenfassend auch als â€žNutzerâ€œ).\n\n#### Zweck der Verarbeitung\n- ZurverfÃ¼gungstellung des Onlineangebotes, seiner Funktionen und Inhalte.\n- Beantwortung von Kontaktanfragen und Kommunikation mit Nutzern.\n- SicherheitsmaÃŸnahmen.\n- Reichweitenmessung/Marketing\n\n#### Verwendete Begrifflichkeiten \nâ€žPersonenbezogene Datenâ€œ sind alle Informationen, die sich auf eine identifizierte oder identifizierbare natÃ¼rliche Person (im Folgenden â€žbetroffene Personâ€œ) beziehen; als identifizierbar wird eine natÃ¼rliche Person angesehen, die direkt oder indirekt, insbesondere mittels Zuordnung zu einer Kennung wie einem Namen, zu einer Kennnummer, zu Standortdaten, zu einer Online-Kennung (z.B. Cookie) oder zu einem oder mehreren besonderen Merkmalen identifiziert werden kann, die Ausdruck der physischen, physiologischen, genetischen, psychischen, wirtschaftlichen, kulturellen oder sozialen IdentitÃ¤t dieser natÃ¼rlichen Person sind.\n\nâ€žVerarbeitungâ€œ ist jeder mit oder ohne Hilfe automatisierter Verfahren ausgefÃ¼hrten Vorgang oder jede solche Vorgangsreihe im Zusammenhang mit personenbezogenen Daten. Der Begriff reicht weit und umfasst praktisch jeden Umgang mit Daten.\n\nAls â€žVerantwortlicherâ€œ wird die natÃ¼rliche oder juristische Person, BehÃ¶rde, Einrichtung oder andere Stelle, die allein oder gemeinsam mit anderen Ã¼ber die Zwecke und Mittel der Verarbeitung von personenbezogenen Daten entscheidet, bezeichnet.\n\n#### MaÃŸgebliche Rechtsgrundlagen\nNach MaÃŸgabe des Art. 13 DSGVO teilen wir Ihnen die Rechtsgrundlagen unserer Datenverarbeitungen mit. Sofern die Rechtsgrundlage in der DatenschutzerklÃ¤rung nicht genannt wird, gilt Folgendes: Die Rechtsgrundlage fÃ¼r die Einholung von Einwilligungen ist Art. 6 Abs. 1 lit. a und Art. 7 DSGVO, die Rechtsgrundlage fÃ¼r die Verarbeitung zur ErfÃ¼llung unserer Leistungen und DurchfÃ¼hrung vertraglicher MaÃŸnahmen sowie Beantwortung von Anfragen ist Art. 6 Abs. 1 lit. b DSGVO, die Rechtsgrundlage fÃ¼r die Verarbeitung zur ErfÃ¼llung unserer rechtlichen Verpflichtungen ist Art. 6 Abs. 1 lit. c DSGVO, und die Rechtsgrundlage fÃ¼r die Verarbeitung zur Wahrung unserer berechtigten Interessen ist Art. 6 Abs. 1 lit. f DSGVO. FÃ¼r den Fall, dass lebenswichtige Interessen der betroffenen Person oder einer anderen natÃ¼rlichen Person eine Verarbeitung personenbezogener Daten erforderlich machen, dient Art. 6 Abs. 1 lit. d DSGVO als Rechtsgrundlage.\n\n#### Zusammenarbeit mit Auftragsverarbeitern und Dritten\nSofern wir im Rahmen unserer Verarbeitung Daten gegenÃ¼ber anderen Personen und Unternehmen (Auftragsverarbeitern oder Dritten) offenbaren, sie an diese Ã¼bermitteln oder ihnen sonst Zugriff auf die Daten gewÃ¤hren, erfolgt dies nur auf Grundlage einer gesetzlichen Erlaubnis (z.B. wenn eine Ãœbermittlung der Daten an Dritte, wie an Zahlungsdienstleister, gem. Art. 6 Abs. 1 lit. b DSGVO zur VertragserfÃ¼llung erforderlich ist), Sie eingewilligt haben, eine rechtliche Verpflichtung dies vorsieht oder auf Grundlage unserer berechtigten Interessen (z.B. beim Einsatz von Beauftragten, Webhostern, etc.).\n\nSofern wir Dritte mit der Verarbeitung von Daten auf Grundlage eines sog. â€žAuftragsverarbeitungsvertragesâ€œ beauftragen, geschieht dies auf Grundlage des Art. 28 DSGVO.\n\n#### Ãœbermittlungen in DrittlÃ¤nder\nSofern wir Daten in einem Drittland (d.h. auÃŸerhalb der EuropÃ¤ischen Union (EU) oder des EuropÃ¤ischen Wirtschaftsraums (EWR)) verarbeiten oder dies im Rahmen der Inanspruchnahme von Diensten Dritter oder Offenlegung, bzw. Ãœbermittlung von Daten an Dritte geschieht, erfolgt dies nur, wenn es zur ErfÃ¼llung unserer (vor)vertraglichen Pflichten, auf Grundlage Ihrer Einwilligung, aufgrund einer rechtlichen Verpflichtung oder auf Grundlage unserer berechtigten Interessen geschieht. Vorbehaltlich gesetzlicher oder vertraglicher Erlaubnisse, verarbeiten oder lassen wir die Daten in einem Drittland nur beim Vorliegen der besonderen Voraussetzungen der Art. 44 ff. DSGVO verarbeiten. D.h. die Verarbeitung erfolgt z.B. auf Grundlage besonderer Garantien, wie der offiziell anerkannten Feststellung eines der EU entsprechenden Datenschutzniveaus (z.B. fÃ¼r die USA durch das â€žPrivacy Shieldâ€œ) oder Beachtung offiziell anerkannter spezieller vertraglicher Verpflichtungen (so genannte â€žStandardvertragsklauselnâ€œ).\n\n#### Rechte der betroffenen Personen\nSie haben das Recht, eine BestÃ¤tigung darÃ¼ber zu verlangen, ob betreffende Daten verarbeitet werden und auf Auskunft Ã¼ber diese Daten sowie auf weitere Informationen und Kopie der Daten entsprechend Art. 15 DSGVO.\n\nSie haben entsprechend. Art. 16 DSGVO das Recht, die VervollstÃ¤ndigung der Sie betreffenden Daten oder die Berichtigung der Sie betreffenden unrichtigen Daten zu verlangen.\n\nSie haben nach MaÃŸgabe des Art. 17 DSGVO das Recht zu verlangen, dass betreffende Daten unverzÃ¼glich gelÃ¶scht werden, bzw. alternativ nach MaÃŸgabe des Art. 18 DSGVO eine EinschrÃ¤nkung der Verarbeitung der Daten zu verlangen.\n\nSie haben das Recht zu verlangen, dass die Sie betreffenden Daten, die Sie uns bereitgestellt haben nach MaÃŸgabe des Art. 20 DSGVO zu erhalten und deren Ãœbermittlung an andere Verantwortliche zu fordern.\n\nSie haben ferner gem. Art. 77 DSGVO das Recht, eine Beschwerde bei der zustÃ¤ndigen AufsichtsbehÃ¶rde einzureichen.\n\n#### Widerrufsrecht\nSie haben das Recht, erteilte Einwilligungen gem. Art. 7 Abs. 3 DSGVO mit Wirkung fÃ¼r die Zukunft zu widerrufen\n\n#### Widerspruchsrecht\nSie kÃ¶nnen der kÃ¼nftigen Verarbeitung der Sie betreffenden Daten nach MaÃŸgabe des Art. 21 DSGVO jederzeit widersprechen. Der Widerspruch kann insbesondere gegen die Verarbeitung fÃ¼r Zwecke der Direktwerbung erfolgen.\n\n#### Cookies und Widerspruchsrecht bei Direktwerbung\nAls â€žCookiesâ€œ werden kleine Dateien bezeichnet, die auf Rechnern der Nutzer gespeichert werden. Innerhalb der Cookies kÃ¶nnen unterschiedliche Angaben gespeichert werden. Ein Cookie dient primÃ¤r dazu, die Angaben zu einem Nutzer (bzw. dem GerÃ¤t auf dem das Cookie gespeichert ist) wÃ¤hrend oder auch nach seinem Besuch innerhalb eines Onlineangebotes zu speichern. Als temporÃ¤re Cookies, bzw. â€žSession-Cookiesâ€œ oder â€žtransiente Cookiesâ€œ, werden Cookies bezeichnet, die gelÃ¶scht werden, nachdem ein Nutzer ein Onlineangebot verlÃ¤sst und seinen Browser schlieÃŸt. In einem solchen Cookie kann z.B. der Inhalt eines Warenkorbs in einem Onlineshop oder ein Login-Staus gespeichert werden. Als â€žpermanentâ€œ oder â€žpersistentâ€œ werden Cookies bezeichnet, die auch nach dem SchlieÃŸen des Browsers gespeichert bleiben. So kann z.B. der Login-Status gespeichert werden, wenn die Nutzer diese nach mehreren Tagen aufsuchen. Ebenso kÃ¶nnen in einem solchen Cookie die Interessen der Nutzer gespeichert werden, die fÃ¼r Reichweitenmessung oder Marketingzwecke verwendet werden. Als â€žThird-Party-Cookieâ€œ werden Cookies bezeichnet, die von anderen Anbietern als dem Verantwortlichen, der das Onlineangebot betreibt, angeboten werden (andernfalls, wenn es nur dessen Cookies sind spricht man von â€žFirst-Party Cookiesâ€œ).\n\nWir kÃ¶nnen temporÃ¤re und permanente Cookies einsetzen und klÃ¤ren hierÃ¼ber im Rahmen unserer DatenschutzerklÃ¤rung auf.\n\nFalls die Nutzer nicht mÃ¶chten, dass Cookies auf ihrem Rechner gespeichert werden, werden sie gebeten die entsprechende Option in den Systemeinstellungen ihres Browsers zu deaktivieren. Gespeicherte Cookies kÃ¶nnen in den Systemeinstellungen des Browsers gelÃ¶scht werden. Der Ausschluss von Cookies kann zu FunktionseinschrÃ¤nkungen dieses Onlineangebotes fÃ¼hren.\n\nEin genereller Widerspruch gegen den Einsatz der zu Zwecken des Onlinemarketing eingesetzten Cookies kann bei einer Vielzahl der Dienste, vor allem im Fall des Trackings, Ã¼ber die US-amerikanische Seite http://www.aboutads.info/choices/ oder die EU-Seite http://www.youronlinechoices.com/ erklÃ¤rt werden. Des Weiteren kann die Speicherung von Cookies mittels deren Abschaltung in den Einstellungen des Browsers erreicht werden. Bitte beachten Sie, dass dann gegebenenfalls nicht alle Funktionen dieses Onlineangebotes genutzt werden kÃ¶nnen.\n\n#### LÃ¶schung von Daten\nDie von uns verarbeiteten Daten werden nach MaÃŸgabe der Art. 17 und 18 DSGVO gelÃ¶scht oder in ihrer Verarbeitung eingeschrÃ¤nkt. Sofern nicht im Rahmen dieser DatenschutzerklÃ¤rung ausdrÃ¼cklich angegeben, werden die bei uns gespeicherten Daten gelÃ¶scht, sobald sie fÃ¼r ihre Zweckbestimmung nicht mehr erforderlich sind und der LÃ¶schung keine gesetzlichen Aufbewahrungspflichten entgegenstehen. Sofern die Daten nicht gelÃ¶scht werden, weil sie fÃ¼r andere und gesetzlich zulÃ¤ssige Zwecke erforderlich sind, wird deren Verarbeitung eingeschrÃ¤nkt. D.h. die Daten werden gesperrt und nicht fÃ¼r andere Zwecke verarbeitet. Das gilt z.B. fÃ¼r Daten, die aus handels- oder steuerrechtlichen GrÃ¼nden aufbewahrt werden mÃ¼ssen.\n\nNach gesetzlichen Vorgaben in Deutschland erfolgt die Aufbewahrung insbesondere fÃ¼r 6 Jahre gemÃ¤ÃŸ Â§ 257 Abs. 1 HGB (HandelsbÃ¼cher, Inventare, ErÃ¶ffnungsbilanzen, JahresabschlÃ¼sse, Handelsbriefe, Buchungsbelege, etc.) sowie fÃ¼r 10 Jahre gemÃ¤ÃŸ Â§ 147 Abs. 1 AO (BÃ¼cher, Aufzeichnungen, Lageberichte, Buchungsbelege, Handels- und GeschÃ¤ftsbriefe, FÃ¼r Besteuerung relevante Unterlagen, etc.).\n\nNach gesetzlichen Vorgaben in Ã–sterreich erfolgt die Aufbewahrung insbesondere fÃ¼r 7 J gemÃ¤ÃŸ Â§ 132 Abs. 1 BAO (Buchhaltungsunterlagen, Belege/Rechnungen, Konten, Belege, GeschÃ¤ftspapiere, Aufstellung der Einnahmen und Ausgaben, etc.), fÃ¼r 22 Jahre im Zusammenhang mit GrundstÃ¼cken und fÃ¼r 10 Jahre bei Unterlagen im Zusammenhang mit elektronisch erbrachten Leistungen, Telekommunikations-, Rundfunk- und Fernsehleistungen, die an Nichtunternehmer in EU-Mitgliedstaaten erbracht werden und fÃ¼r die der Mini-One-Stop-Shop (MOSS) in Anspruch genommen wird.\n\n#### Hosting\nDie von uns in Anspruch genommenen Hosting-Leistungen dienen der ZurverfÃ¼gungstellung der folgenden Leistungen: Infrastruktur- und Plattformdienstleistungen, RechenkapazitÃ¤t, Speicherplatz und Datenbankdienste, Sicherheitsleistungen sowie technische Wartungsleistungen, die wir zum Zwecke des Betriebs dieses Onlineangebotes einsetzen.\n\nHierbei verarbeiten wir, bzw. unser Hostinganbieter Bestandsdaten, Kontaktdaten, Inhaltsdaten, Vertragsdaten, Nutzungsdaten, Meta- und Kommunikationsdaten von Kunden, Interessenten und Besuchern dieses Onlineangebotes auf Grundlage unserer berechtigten Interessen an einer effizienten und sicheren ZurverfÃ¼gungstellung dieses Onlineangebotes gem. Art. 6 Abs. 1 lit. f DSGVO i.V.m. Art. 28 DSGVO (Abschluss Auftragsverarbeitungsvertrag).\n\n#### Erhebung von Zugriffsdaten und Logfiles\nWir, bzw. unser Hostinganbieter, erhebt auf Grundlage unserer berechtigten Interessen im Sinne des Art. 6 Abs. 1 lit. f. DSGVO Daten Ã¼ber jeden Zugriff auf den Server, auf dem sich dieser Dienst befindet (sogenannte Serverlogfiles). Zu den Zugriffsdaten gehÃ¶ren Name der abgerufenen Webseite, Datei, Datum und Uhrzeit des Abrufs, Ã¼bertragene Datenmenge, Meldung Ã¼ber erfolgreichen Abruf, Browsertyp nebst Version, das Betriebssystem des Nutzers, Referrer URL (die zuvor besuchte Seite), IP-Adresse und der anfragende Provider.\n\nLogfile-Informationen werden aus SicherheitsgrÃ¼nden (z.B. zur AufklÃ¤rung von Missbrauchs- oder Betrugshandlungen) fÃ¼r die Dauer von maximal 7 Tagen gespeichert und danach gelÃ¶scht. Daten, deren weitere Aufbewahrung zu Beweiszwecken erforderlich ist, sind bis zur endgÃ¼ltigen KlÃ¤rung des jeweiligen Vorfalls von der LÃ¶schung ausgenommen.\n\n#### Google Universal Analytics\nWir setzen auf Grundlage unserer berechtigten Interessen (d.h. Interesse an der Analyse, Optimierung und wirtschaftlichem Betrieb unseres Onlineangebotes im Sinne des Art. 6 Abs. 1 lit. f. DSGVO) Google Analytics, einen Webanalysedienst der Google LLC (â€žGoogleâ€œ) ein. Google verwendet Cookies. Die durch das Cookie erzeugten Informationen Ã¼ber Benutzung des Onlineangebotes durch die Nutzer werden in der Regel an einen Server von Google in den USA Ã¼bertragen und dort gespeichert.\n\nGoogle ist unter dem Privacy-Shield-Abkommen zertifiziert und bietet hierdurch eine Garantie, das europÃ¤ische Datenschutzrecht einzuhalten (https://www.privacyshield.gov/participant?id=a2zt000000001L5AAI&status=Active).\n\nGoogle wird diese Informationen in unserem Auftrag benutzen, um die Nutzung unseres Onlineangebotes durch die Nutzer auszuwerten, um Reports Ã¼ber die AktivitÃ¤ten innerhalb dieses Onlineangebotes zusammenzustellen und um weitere, mit der Nutzung dieses Onlineangebotes und der Internetnutzung verbundene Dienstleistungen, uns gegenÃ¼ber zu erbringen. Dabei kÃ¶nnen aus den verarbeiteten Daten pseudonyme Nutzungsprofile der Nutzer erstellt werden.\n\nWir setzen Google Analytics in der Ausgestaltung als â€žUniversal-Analyticsâ€œ ein. â€žUniversal Analyticsâ€œ bezeichnet ein Verfahren von Google Analytics, bei dem die Nutzeranalyse auf Grundlage einer pseudonymen Nutzer-ID erfolgt und damit ein pseudonymes Profil des Nutzers mit Informationen aus der Nutzung verschiedener GerÃ¤ten erstellt wird (sog. â€žCross-Device-Trackingâ€œ).\n\nWir setzen Google Analytics nur mit aktivierter IP-Anonymisierung ein. Das bedeutet, die IP-Adresse der Nutzer wird von Google innerhalb von Mitgliedstaaten der EuropÃ¤ischen Union oder in anderen Vertragsstaaten des Abkommens Ã¼ber den EuropÃ¤ischen Wirtschaftsraum gekÃ¼rzt. Nur in AusnahmefÃ¤llen wird die volle IP-Adresse an einen Server von Google in den USA Ã¼bertragen und dort gekÃ¼rzt.\n\nDie von dem Browser des Nutzers Ã¼bermittelte IP-Adresse wird nicht mit anderen Daten von Google zusammengefÃ¼hrt. Die Nutzer kÃ¶nnen die Speicherung der Cookies durch eine entsprechende Einstellung ihrer Browser-Software verhindern; die Nutzer kÃ¶nnen darÃ¼ber hinaus die Erfassung der durch das Cookie erzeugten und auf ihre Nutzung des Onlineangebotes bezogenen Daten an Google sowie die Verarbeitung dieser Daten durch Google verhindern, indem sie das unter folgendem Link verfÃ¼gbare Browser-Plugin herunterladen und installieren: http://tools.google.com/dlpage/gaoptout?hl=de.\n\nWeitere Informationen zur Datennutzung durch Google, Einstellungs- und WiderspruchsmÃ¶glichkeiten erfahren Sie auf den Webseiten von Google: https://www.google.com/intl/de/policies/privacy/partners (â€žDatennutzung durch Google bei Ihrer Nutzung von Websites oder Apps unserer Partnerâ€œ), http://www.google.com/policies/technologies/ads (â€žDatennutzung zu Werbezweckenâ€œ), http://www.google.de/settings/ads (â€žInformationen verwalten, die Google verwendet, um Ihnen Werbung einzublendenâ€œ).\n\n#### Youtube\nWir binden die Videos der Plattform â€œYouTubeâ€ des Anbieters Google LLC, 1600 Amphitheatre Parkway, Mountain View, CA 94043, USA, ein. DatenschutzerklÃ¤rung: https://www.google.com/policies/privacy/, Opt-Out: https://adssettings.google.com/authenticated.\n\n[Erstellt mit Datenschutz-Generator.de von RA Dr. Thomas Schwenke](https://datenschutz-generator.de/)","updated":"2018-05-08T13:34:01.169Z","path":"imprint/index.html","comments":1,"layout":"page","_id":"cjh2giolq0004cxrgyhym6njl","content":"<h1 id=\"Imprint\"><a href=\"#Imprint\" class=\"headerlink\" title=\"Imprint\"></a>Imprint</h1><h3 id=\"Legal-Disclosure-amp-Privacy-Statement\"><a href=\"#Legal-Disclosure-amp-Privacy-Statement\" class=\"headerlink\" title=\"Legal Disclosure &amp; Privacy Statement\"></a>Legal Disclosure &amp; Privacy Statement</h3><p>Information in accordance with section 5 German TMG</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Ferdinand MÃ¼tsch</span><br><span class=\"line\">VorholzstraÃŸe 11 </span><br><span class=\"line\">76137 Karlsruhe</span><br><span class=\"line\">Germany</span><br></pre></td></tr></table></figure>\n<h3 id=\"Contact\"><a href=\"#Contact\" class=\"headerlink\" title=\"Contact\"></a>Contact</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Telephone: 0ï¸âƒ£1ï¸âƒ£7ï¸âƒ£6ï¸âƒ£4ï¸âƒ£5ï¸âƒ£6ï¸âƒ£4ï¸âƒ£1ï¸âƒ£9ï¸âƒ£7ï¸âƒ£4ï¸âƒ£</span><br><span class=\"line\">E-Mail: mail@ferdinand-muetsch.de</span><br><span class=\"line\">Web: www.ferdinand-muetsch.de</span><br></pre></td></tr></table></figure>\n<h3 id=\"Disclaimer\"><a href=\"#Disclaimer\" class=\"headerlink\" title=\"Disclaimer\"></a>Disclaimer</h3><h4 id=\"Accountability-for-content\"><a href=\"#Accountability-for-content\" class=\"headerlink\" title=\"Accountability for content\"></a>Accountability for content</h4><p>The contents of our pages have been created with the utmost care. However, we cannot guarantee the contentsâ€™ accuracy, completeness or topicality. According to statutory provisions, we are furthermore responsible for our own content on these web pages. In this context, please note that we are accordingly not obliged to monitor merely the transmitted or saved information of third parties, or investigate circumstances pointing to illegal activity. Our obligations to remove or block the use of information under generally applicable laws remain unaffected by this as per Â§Â§ 8 to 10 of the Telemedia Act (TMG).</p>\n<h4 id=\"Accountability-for-links\"><a href=\"#Accountability-for-links\" class=\"headerlink\" title=\"Accountability for links\"></a>Accountability for links</h4><p>Responsibility for the content of external links (to web pages of third parties) lies solely with the operators of the linked pages. No violations were evident to us at the time of linking. Should any legal infringement become known to us, we will remove the respective link immediately. </p>\n<h4 id=\"Copyright\"><a href=\"#Copyright\" class=\"headerlink\" title=\"Copyright\"></a>Copyright</h4><p>Our web pages and their contents are subject to German copyright law. Unless expressly permitted by law (Â§ 44a et seq. of the copyright law), every form of utilizing, reproducing or processing works subject to copyright protection on our web pages requires the prior consent of the respective owner of the rights. Individual reproductions of a work are allowed only for private use, so must not serve either directly or indirectly for earnings. Unauthorized utilization of copyrighted works is punishable (Â§ 106 of the copyright law).</p>\n<h4 id=\"General\"><a href=\"#General\" class=\"headerlink\" title=\"General\"></a>General</h4><p>Your personal data (e.g. title, name, house address, e-mail address, phone number, bank details, credit card number) are processed by us only in accordance with the provisions of German data privacy laws. The following provisions describe the type, scope and purpose of collecting, processing and utilizing personal data. This data privacy policy applies only to our web pages. If links on our pages route you to other pages, please inquire there about how your data are handled in such cases.</p>\n<h4 id=\"Inventory-data\"><a href=\"#Inventory-data\" class=\"headerlink\" title=\"Inventory data\"></a>Inventory data</h4><p>(1) Your personal data, insofar as these are necessary for this contractual relationship (inventory data) in terms of its establishment, organization of content and modifications, are used exclusively for fulfilling the contract. For goods to be delivered, for instance, your name and address must be relayed to the supplier of the goods.<br>(2) Without your explicit consent or a legal basis, your personal data are not passed on to third parties outside the scope of fulfilling this contract. After completion of the contract, your data are blocked against further use. After expiry of deadlines as per tax-related and commercial regulations, these data are deleted unless you have expressly consented to their further use.</p>\n<h4 id=\"Information-about-cookies\"><a href=\"#Information-about-cookies\" class=\"headerlink\" title=\"Information about cookies\"></a>Information about cookies</h4><p>(1) To optimize our web presence, we use cookies. These are small text files stored in your computerâ€™s main memory. These cookies are deleted after you close the browser. Other cookies remain on your computer (long-term cookies) and permit its recognition on your next visit. This allows us to improve your access to our site.<br>(2) You can prevent storage of cookies by choosing a â€œdisable cookiesâ€ option in your browser settings. But this can limit the functionality of our Internet offers as a result.</p>\n<h4 id=\"Disclosure\"><a href=\"#Disclosure\" class=\"headerlink\" title=\"Disclosure\"></a>Disclosure</h4><p>According to the Federal Data Protection Act, you have a right to free-of-charge information about your stored data, and possibly entitlement to correction, blocking or deletion of such data. Inquiries can be directed to the following e-mail addresses: ( <a href=\"mailto:mail@ferdinand-muetsch.de\">mail@ferdinand-muetsch.de</a> )</p>\n<p>Source: <a href=\"http://www.twigg.de/\" target=\"_blank\" rel=\"noopener\">twiggs translations</a></p>\n<h3 id=\"German-Privacy-Policy-Datenschutzerklarung\"><a href=\"#German-Privacy-Policy-Datenschutzerklarung\" class=\"headerlink\" title=\"German Privacy Policy (DatenschutzerklÃ¤rung)\"></a>German Privacy Policy (DatenschutzerklÃ¤rung)</h3><p>Diese DatenschutzerklÃ¤rung klÃ¤rt Sie Ã¼ber die Art, den Umfang und Zweck der Verarbeitung von personenbezogenen Daten (nachfolgend kurz â€žDatenâ€œ) innerhalb unseres Onlineangebotes und der mit ihm verbundenen Webseiten, Funktionen und Inhalte sowie externen OnlineprÃ¤senzen, wie z.B. unser Social Media Profile auf. (nachfolgend gemeinsam bezeichnet als â€žOnlineangebotâ€œ). Im Hinblick auf die verwendeten Begrifflichkeiten, wie z.B. â€žVerarbeitungâ€œ oder â€žVerantwortlicherâ€œ verweisen wir auf die Definitionen im Art. 4 der Datenschutzgrundverordnung (DSGVO).</p>\n<h4 id=\"Arten-der-verarbeiteten-Daten\"><a href=\"#Arten-der-verarbeiteten-Daten\" class=\"headerlink\" title=\"Arten der verarbeiteten Daten:\"></a>Arten der verarbeiteten Daten:</h4><ul>\n<li>Bestandsdaten (z.B., Namen, Adressen).</li>\n<li>Kontaktdaten (z.B., E-Mail, Telefonnummern).</li>\n<li>Inhaltsdaten (z.B., Texteingaben, Fotografien, Videos).</li>\n<li>Nutzungsdaten (z.B., besuchte Webseiten, Interesse an Inhalten, Zugriffszeiten).</li>\n<li>Meta-/Kommunikationsdaten (z.B., GerÃ¤te-Informationen, IP-Adressen).</li>\n</ul>\n<h4 id=\"Kategorien-betroffener-Personen\"><a href=\"#Kategorien-betroffener-Personen\" class=\"headerlink\" title=\"Kategorien betroffener Personen\"></a>Kategorien betroffener Personen</h4><p>Besucher und Nutzer des Onlineangebotes (Nachfolgend bezeichnen wir die betroffenen Personen zusammenfassend auch als â€žNutzerâ€œ).</p>\n<h4 id=\"Zweck-der-Verarbeitung\"><a href=\"#Zweck-der-Verarbeitung\" class=\"headerlink\" title=\"Zweck der Verarbeitung\"></a>Zweck der Verarbeitung</h4><ul>\n<li>ZurverfÃ¼gungstellung des Onlineangebotes, seiner Funktionen und Inhalte.</li>\n<li>Beantwortung von Kontaktanfragen und Kommunikation mit Nutzern.</li>\n<li>SicherheitsmaÃŸnahmen.</li>\n<li>Reichweitenmessung/Marketing</li>\n</ul>\n<h4 id=\"Verwendete-Begrifflichkeiten\"><a href=\"#Verwendete-Begrifflichkeiten\" class=\"headerlink\" title=\"Verwendete Begrifflichkeiten\"></a>Verwendete Begrifflichkeiten</h4><p>â€žPersonenbezogene Datenâ€œ sind alle Informationen, die sich auf eine identifizierte oder identifizierbare natÃ¼rliche Person (im Folgenden â€žbetroffene Personâ€œ) beziehen; als identifizierbar wird eine natÃ¼rliche Person angesehen, die direkt oder indirekt, insbesondere mittels Zuordnung zu einer Kennung wie einem Namen, zu einer Kennnummer, zu Standortdaten, zu einer Online-Kennung (z.B. Cookie) oder zu einem oder mehreren besonderen Merkmalen identifiziert werden kann, die Ausdruck der physischen, physiologischen, genetischen, psychischen, wirtschaftlichen, kulturellen oder sozialen IdentitÃ¤t dieser natÃ¼rlichen Person sind.</p>\n<p>â€žVerarbeitungâ€œ ist jeder mit oder ohne Hilfe automatisierter Verfahren ausgefÃ¼hrten Vorgang oder jede solche Vorgangsreihe im Zusammenhang mit personenbezogenen Daten. Der Begriff reicht weit und umfasst praktisch jeden Umgang mit Daten.</p>\n<p>Als â€žVerantwortlicherâ€œ wird die natÃ¼rliche oder juristische Person, BehÃ¶rde, Einrichtung oder andere Stelle, die allein oder gemeinsam mit anderen Ã¼ber die Zwecke und Mittel der Verarbeitung von personenbezogenen Daten entscheidet, bezeichnet.</p>\n<h4 id=\"Masgebliche-Rechtsgrundlagen\"><a href=\"#Masgebliche-Rechtsgrundlagen\" class=\"headerlink\" title=\"MaÃŸgebliche Rechtsgrundlagen\"></a>MaÃŸgebliche Rechtsgrundlagen</h4><p>Nach MaÃŸgabe des Art. 13 DSGVO teilen wir Ihnen die Rechtsgrundlagen unserer Datenverarbeitungen mit. Sofern die Rechtsgrundlage in der DatenschutzerklÃ¤rung nicht genannt wird, gilt Folgendes: Die Rechtsgrundlage fÃ¼r die Einholung von Einwilligungen ist Art. 6 Abs. 1 lit. a und Art. 7 DSGVO, die Rechtsgrundlage fÃ¼r die Verarbeitung zur ErfÃ¼llung unserer Leistungen und DurchfÃ¼hrung vertraglicher MaÃŸnahmen sowie Beantwortung von Anfragen ist Art. 6 Abs. 1 lit. b DSGVO, die Rechtsgrundlage fÃ¼r die Verarbeitung zur ErfÃ¼llung unserer rechtlichen Verpflichtungen ist Art. 6 Abs. 1 lit. c DSGVO, und die Rechtsgrundlage fÃ¼r die Verarbeitung zur Wahrung unserer berechtigten Interessen ist Art. 6 Abs. 1 lit. f DSGVO. FÃ¼r den Fall, dass lebenswichtige Interessen der betroffenen Person oder einer anderen natÃ¼rlichen Person eine Verarbeitung personenbezogener Daten erforderlich machen, dient Art. 6 Abs. 1 lit. d DSGVO als Rechtsgrundlage.</p>\n<h4 id=\"Zusammenarbeit-mit-Auftragsverarbeitern-und-Dritten\"><a href=\"#Zusammenarbeit-mit-Auftragsverarbeitern-und-Dritten\" class=\"headerlink\" title=\"Zusammenarbeit mit Auftragsverarbeitern und Dritten\"></a>Zusammenarbeit mit Auftragsverarbeitern und Dritten</h4><p>Sofern wir im Rahmen unserer Verarbeitung Daten gegenÃ¼ber anderen Personen und Unternehmen (Auftragsverarbeitern oder Dritten) offenbaren, sie an diese Ã¼bermitteln oder ihnen sonst Zugriff auf die Daten gewÃ¤hren, erfolgt dies nur auf Grundlage einer gesetzlichen Erlaubnis (z.B. wenn eine Ãœbermittlung der Daten an Dritte, wie an Zahlungsdienstleister, gem. Art. 6 Abs. 1 lit. b DSGVO zur VertragserfÃ¼llung erforderlich ist), Sie eingewilligt haben, eine rechtliche Verpflichtung dies vorsieht oder auf Grundlage unserer berechtigten Interessen (z.B. beim Einsatz von Beauftragten, Webhostern, etc.).</p>\n<p>Sofern wir Dritte mit der Verarbeitung von Daten auf Grundlage eines sog. â€žAuftragsverarbeitungsvertragesâ€œ beauftragen, geschieht dies auf Grundlage des Art. 28 DSGVO.</p>\n<h4 id=\"Ubermittlungen-in-Drittlander\"><a href=\"#Ubermittlungen-in-Drittlander\" class=\"headerlink\" title=\"Ãœbermittlungen in DrittlÃ¤nder\"></a>Ãœbermittlungen in DrittlÃ¤nder</h4><p>Sofern wir Daten in einem Drittland (d.h. auÃŸerhalb der EuropÃ¤ischen Union (EU) oder des EuropÃ¤ischen Wirtschaftsraums (EWR)) verarbeiten oder dies im Rahmen der Inanspruchnahme von Diensten Dritter oder Offenlegung, bzw. Ãœbermittlung von Daten an Dritte geschieht, erfolgt dies nur, wenn es zur ErfÃ¼llung unserer (vor)vertraglichen Pflichten, auf Grundlage Ihrer Einwilligung, aufgrund einer rechtlichen Verpflichtung oder auf Grundlage unserer berechtigten Interessen geschieht. Vorbehaltlich gesetzlicher oder vertraglicher Erlaubnisse, verarbeiten oder lassen wir die Daten in einem Drittland nur beim Vorliegen der besonderen Voraussetzungen der Art. 44 ff. DSGVO verarbeiten. D.h. die Verarbeitung erfolgt z.B. auf Grundlage besonderer Garantien, wie der offiziell anerkannten Feststellung eines der EU entsprechenden Datenschutzniveaus (z.B. fÃ¼r die USA durch das â€žPrivacy Shieldâ€œ) oder Beachtung offiziell anerkannter spezieller vertraglicher Verpflichtungen (so genannte â€žStandardvertragsklauselnâ€œ).</p>\n<h4 id=\"Rechte-der-betroffenen-Personen\"><a href=\"#Rechte-der-betroffenen-Personen\" class=\"headerlink\" title=\"Rechte der betroffenen Personen\"></a>Rechte der betroffenen Personen</h4><p>Sie haben das Recht, eine BestÃ¤tigung darÃ¼ber zu verlangen, ob betreffende Daten verarbeitet werden und auf Auskunft Ã¼ber diese Daten sowie auf weitere Informationen und Kopie der Daten entsprechend Art. 15 DSGVO.</p>\n<p>Sie haben entsprechend. Art. 16 DSGVO das Recht, die VervollstÃ¤ndigung der Sie betreffenden Daten oder die Berichtigung der Sie betreffenden unrichtigen Daten zu verlangen.</p>\n<p>Sie haben nach MaÃŸgabe des Art. 17 DSGVO das Recht zu verlangen, dass betreffende Daten unverzÃ¼glich gelÃ¶scht werden, bzw. alternativ nach MaÃŸgabe des Art. 18 DSGVO eine EinschrÃ¤nkung der Verarbeitung der Daten zu verlangen.</p>\n<p>Sie haben das Recht zu verlangen, dass die Sie betreffenden Daten, die Sie uns bereitgestellt haben nach MaÃŸgabe des Art. 20 DSGVO zu erhalten und deren Ãœbermittlung an andere Verantwortliche zu fordern.</p>\n<p>Sie haben ferner gem. Art. 77 DSGVO das Recht, eine Beschwerde bei der zustÃ¤ndigen AufsichtsbehÃ¶rde einzureichen.</p>\n<h4 id=\"Widerrufsrecht\"><a href=\"#Widerrufsrecht\" class=\"headerlink\" title=\"Widerrufsrecht\"></a>Widerrufsrecht</h4><p>Sie haben das Recht, erteilte Einwilligungen gem. Art. 7 Abs. 3 DSGVO mit Wirkung fÃ¼r die Zukunft zu widerrufen</p>\n<h4 id=\"Widerspruchsrecht\"><a href=\"#Widerspruchsrecht\" class=\"headerlink\" title=\"Widerspruchsrecht\"></a>Widerspruchsrecht</h4><p>Sie kÃ¶nnen der kÃ¼nftigen Verarbeitung der Sie betreffenden Daten nach MaÃŸgabe des Art. 21 DSGVO jederzeit widersprechen. Der Widerspruch kann insbesondere gegen die Verarbeitung fÃ¼r Zwecke der Direktwerbung erfolgen.</p>\n<h4 id=\"Cookies-und-Widerspruchsrecht-bei-Direktwerbung\"><a href=\"#Cookies-und-Widerspruchsrecht-bei-Direktwerbung\" class=\"headerlink\" title=\"Cookies und Widerspruchsrecht bei Direktwerbung\"></a>Cookies und Widerspruchsrecht bei Direktwerbung</h4><p>Als â€žCookiesâ€œ werden kleine Dateien bezeichnet, die auf Rechnern der Nutzer gespeichert werden. Innerhalb der Cookies kÃ¶nnen unterschiedliche Angaben gespeichert werden. Ein Cookie dient primÃ¤r dazu, die Angaben zu einem Nutzer (bzw. dem GerÃ¤t auf dem das Cookie gespeichert ist) wÃ¤hrend oder auch nach seinem Besuch innerhalb eines Onlineangebotes zu speichern. Als temporÃ¤re Cookies, bzw. â€žSession-Cookiesâ€œ oder â€žtransiente Cookiesâ€œ, werden Cookies bezeichnet, die gelÃ¶scht werden, nachdem ein Nutzer ein Onlineangebot verlÃ¤sst und seinen Browser schlieÃŸt. In einem solchen Cookie kann z.B. der Inhalt eines Warenkorbs in einem Onlineshop oder ein Login-Staus gespeichert werden. Als â€žpermanentâ€œ oder â€žpersistentâ€œ werden Cookies bezeichnet, die auch nach dem SchlieÃŸen des Browsers gespeichert bleiben. So kann z.B. der Login-Status gespeichert werden, wenn die Nutzer diese nach mehreren Tagen aufsuchen. Ebenso kÃ¶nnen in einem solchen Cookie die Interessen der Nutzer gespeichert werden, die fÃ¼r Reichweitenmessung oder Marketingzwecke verwendet werden. Als â€žThird-Party-Cookieâ€œ werden Cookies bezeichnet, die von anderen Anbietern als dem Verantwortlichen, der das Onlineangebot betreibt, angeboten werden (andernfalls, wenn es nur dessen Cookies sind spricht man von â€žFirst-Party Cookiesâ€œ).</p>\n<p>Wir kÃ¶nnen temporÃ¤re und permanente Cookies einsetzen und klÃ¤ren hierÃ¼ber im Rahmen unserer DatenschutzerklÃ¤rung auf.</p>\n<p>Falls die Nutzer nicht mÃ¶chten, dass Cookies auf ihrem Rechner gespeichert werden, werden sie gebeten die entsprechende Option in den Systemeinstellungen ihres Browsers zu deaktivieren. Gespeicherte Cookies kÃ¶nnen in den Systemeinstellungen des Browsers gelÃ¶scht werden. Der Ausschluss von Cookies kann zu FunktionseinschrÃ¤nkungen dieses Onlineangebotes fÃ¼hren.</p>\n<p>Ein genereller Widerspruch gegen den Einsatz der zu Zwecken des Onlinemarketing eingesetzten Cookies kann bei einer Vielzahl der Dienste, vor allem im Fall des Trackings, Ã¼ber die US-amerikanische Seite <a href=\"http://www.aboutads.info/choices/\" target=\"_blank\" rel=\"noopener\">http://www.aboutads.info/choices/</a> oder die EU-Seite <a href=\"http://www.youronlinechoices.com/\" target=\"_blank\" rel=\"noopener\">http://www.youronlinechoices.com/</a> erklÃ¤rt werden. Des Weiteren kann die Speicherung von Cookies mittels deren Abschaltung in den Einstellungen des Browsers erreicht werden. Bitte beachten Sie, dass dann gegebenenfalls nicht alle Funktionen dieses Onlineangebotes genutzt werden kÃ¶nnen.</p>\n<h4 id=\"Loschung-von-Daten\"><a href=\"#Loschung-von-Daten\" class=\"headerlink\" title=\"LÃ¶schung von Daten\"></a>LÃ¶schung von Daten</h4><p>Die von uns verarbeiteten Daten werden nach MaÃŸgabe der Art. 17 und 18 DSGVO gelÃ¶scht oder in ihrer Verarbeitung eingeschrÃ¤nkt. Sofern nicht im Rahmen dieser DatenschutzerklÃ¤rung ausdrÃ¼cklich angegeben, werden die bei uns gespeicherten Daten gelÃ¶scht, sobald sie fÃ¼r ihre Zweckbestimmung nicht mehr erforderlich sind und der LÃ¶schung keine gesetzlichen Aufbewahrungspflichten entgegenstehen. Sofern die Daten nicht gelÃ¶scht werden, weil sie fÃ¼r andere und gesetzlich zulÃ¤ssige Zwecke erforderlich sind, wird deren Verarbeitung eingeschrÃ¤nkt. D.h. die Daten werden gesperrt und nicht fÃ¼r andere Zwecke verarbeitet. Das gilt z.B. fÃ¼r Daten, die aus handels- oder steuerrechtlichen GrÃ¼nden aufbewahrt werden mÃ¼ssen.</p>\n<p>Nach gesetzlichen Vorgaben in Deutschland erfolgt die Aufbewahrung insbesondere fÃ¼r 6 Jahre gemÃ¤ÃŸ Â§ 257 Abs. 1 HGB (HandelsbÃ¼cher, Inventare, ErÃ¶ffnungsbilanzen, JahresabschlÃ¼sse, Handelsbriefe, Buchungsbelege, etc.) sowie fÃ¼r 10 Jahre gemÃ¤ÃŸ Â§ 147 Abs. 1 AO (BÃ¼cher, Aufzeichnungen, Lageberichte, Buchungsbelege, Handels- und GeschÃ¤ftsbriefe, FÃ¼r Besteuerung relevante Unterlagen, etc.).</p>\n<p>Nach gesetzlichen Vorgaben in Ã–sterreich erfolgt die Aufbewahrung insbesondere fÃ¼r 7 J gemÃ¤ÃŸ Â§ 132 Abs. 1 BAO (Buchhaltungsunterlagen, Belege/Rechnungen, Konten, Belege, GeschÃ¤ftspapiere, Aufstellung der Einnahmen und Ausgaben, etc.), fÃ¼r 22 Jahre im Zusammenhang mit GrundstÃ¼cken und fÃ¼r 10 Jahre bei Unterlagen im Zusammenhang mit elektronisch erbrachten Leistungen, Telekommunikations-, Rundfunk- und Fernsehleistungen, die an Nichtunternehmer in EU-Mitgliedstaaten erbracht werden und fÃ¼r die der Mini-One-Stop-Shop (MOSS) in Anspruch genommen wird.</p>\n<h4 id=\"Hosting\"><a href=\"#Hosting\" class=\"headerlink\" title=\"Hosting\"></a>Hosting</h4><p>Die von uns in Anspruch genommenen Hosting-Leistungen dienen der ZurverfÃ¼gungstellung der folgenden Leistungen: Infrastruktur- und Plattformdienstleistungen, RechenkapazitÃ¤t, Speicherplatz und Datenbankdienste, Sicherheitsleistungen sowie technische Wartungsleistungen, die wir zum Zwecke des Betriebs dieses Onlineangebotes einsetzen.</p>\n<p>Hierbei verarbeiten wir, bzw. unser Hostinganbieter Bestandsdaten, Kontaktdaten, Inhaltsdaten, Vertragsdaten, Nutzungsdaten, Meta- und Kommunikationsdaten von Kunden, Interessenten und Besuchern dieses Onlineangebotes auf Grundlage unserer berechtigten Interessen an einer effizienten und sicheren ZurverfÃ¼gungstellung dieses Onlineangebotes gem. Art. 6 Abs. 1 lit. f DSGVO i.V.m. Art. 28 DSGVO (Abschluss Auftragsverarbeitungsvertrag).</p>\n<h4 id=\"Erhebung-von-Zugriffsdaten-und-Logfiles\"><a href=\"#Erhebung-von-Zugriffsdaten-und-Logfiles\" class=\"headerlink\" title=\"Erhebung von Zugriffsdaten und Logfiles\"></a>Erhebung von Zugriffsdaten und Logfiles</h4><p>Wir, bzw. unser Hostinganbieter, erhebt auf Grundlage unserer berechtigten Interessen im Sinne des Art. 6 Abs. 1 lit. f. DSGVO Daten Ã¼ber jeden Zugriff auf den Server, auf dem sich dieser Dienst befindet (sogenannte Serverlogfiles). Zu den Zugriffsdaten gehÃ¶ren Name der abgerufenen Webseite, Datei, Datum und Uhrzeit des Abrufs, Ã¼bertragene Datenmenge, Meldung Ã¼ber erfolgreichen Abruf, Browsertyp nebst Version, das Betriebssystem des Nutzers, Referrer URL (die zuvor besuchte Seite), IP-Adresse und der anfragende Provider.</p>\n<p>Logfile-Informationen werden aus SicherheitsgrÃ¼nden (z.B. zur AufklÃ¤rung von Missbrauchs- oder Betrugshandlungen) fÃ¼r die Dauer von maximal 7 Tagen gespeichert und danach gelÃ¶scht. Daten, deren weitere Aufbewahrung zu Beweiszwecken erforderlich ist, sind bis zur endgÃ¼ltigen KlÃ¤rung des jeweiligen Vorfalls von der LÃ¶schung ausgenommen.</p>\n<h4 id=\"Google-Universal-Analytics\"><a href=\"#Google-Universal-Analytics\" class=\"headerlink\" title=\"Google Universal Analytics\"></a>Google Universal Analytics</h4><p>Wir setzen auf Grundlage unserer berechtigten Interessen (d.h. Interesse an der Analyse, Optimierung und wirtschaftlichem Betrieb unseres Onlineangebotes im Sinne des Art. 6 Abs. 1 lit. f. DSGVO) Google Analytics, einen Webanalysedienst der Google LLC (â€žGoogleâ€œ) ein. Google verwendet Cookies. Die durch das Cookie erzeugten Informationen Ã¼ber Benutzung des Onlineangebotes durch die Nutzer werden in der Regel an einen Server von Google in den USA Ã¼bertragen und dort gespeichert.</p>\n<p>Google ist unter dem Privacy-Shield-Abkommen zertifiziert und bietet hierdurch eine Garantie, das europÃ¤ische Datenschutzrecht einzuhalten (<a href=\"https://www.privacyshield.gov/participant?id=a2zt000000001L5AAI&amp;status=Active)\" target=\"_blank\" rel=\"noopener\">https://www.privacyshield.gov/participant?id=a2zt000000001L5AAI&amp;status=Active)</a>.</p>\n<p>Google wird diese Informationen in unserem Auftrag benutzen, um die Nutzung unseres Onlineangebotes durch die Nutzer auszuwerten, um Reports Ã¼ber die AktivitÃ¤ten innerhalb dieses Onlineangebotes zusammenzustellen und um weitere, mit der Nutzung dieses Onlineangebotes und der Internetnutzung verbundene Dienstleistungen, uns gegenÃ¼ber zu erbringen. Dabei kÃ¶nnen aus den verarbeiteten Daten pseudonyme Nutzungsprofile der Nutzer erstellt werden.</p>\n<p>Wir setzen Google Analytics in der Ausgestaltung als â€žUniversal-Analyticsâ€œ ein. â€žUniversal Analyticsâ€œ bezeichnet ein Verfahren von Google Analytics, bei dem die Nutzeranalyse auf Grundlage einer pseudonymen Nutzer-ID erfolgt und damit ein pseudonymes Profil des Nutzers mit Informationen aus der Nutzung verschiedener GerÃ¤ten erstellt wird (sog. â€žCross-Device-Trackingâ€œ).</p>\n<p>Wir setzen Google Analytics nur mit aktivierter IP-Anonymisierung ein. Das bedeutet, die IP-Adresse der Nutzer wird von Google innerhalb von Mitgliedstaaten der EuropÃ¤ischen Union oder in anderen Vertragsstaaten des Abkommens Ã¼ber den EuropÃ¤ischen Wirtschaftsraum gekÃ¼rzt. Nur in AusnahmefÃ¤llen wird die volle IP-Adresse an einen Server von Google in den USA Ã¼bertragen und dort gekÃ¼rzt.</p>\n<p>Die von dem Browser des Nutzers Ã¼bermittelte IP-Adresse wird nicht mit anderen Daten von Google zusammengefÃ¼hrt. Die Nutzer kÃ¶nnen die Speicherung der Cookies durch eine entsprechende Einstellung ihrer Browser-Software verhindern; die Nutzer kÃ¶nnen darÃ¼ber hinaus die Erfassung der durch das Cookie erzeugten und auf ihre Nutzung des Onlineangebotes bezogenen Daten an Google sowie die Verarbeitung dieser Daten durch Google verhindern, indem sie das unter folgendem Link verfÃ¼gbare Browser-Plugin herunterladen und installieren: <a href=\"http://tools.google.com/dlpage/gaoptout?hl=de\" target=\"_blank\" rel=\"noopener\">http://tools.google.com/dlpage/gaoptout?hl=de</a>.</p>\n<p>Weitere Informationen zur Datennutzung durch Google, Einstellungs- und WiderspruchsmÃ¶glichkeiten erfahren Sie auf den Webseiten von Google: <a href=\"https://www.google.com/intl/de/policies/privacy/partners\" target=\"_blank\" rel=\"noopener\">https://www.google.com/intl/de/policies/privacy/partners</a> (â€žDatennutzung durch Google bei Ihrer Nutzung von Websites oder Apps unserer Partnerâ€œ), <a href=\"http://www.google.com/policies/technologies/ads\" target=\"_blank\" rel=\"noopener\">http://www.google.com/policies/technologies/ads</a> (â€žDatennutzung zu Werbezweckenâ€œ), <a href=\"http://www.google.de/settings/ads\" target=\"_blank\" rel=\"noopener\">http://www.google.de/settings/ads</a> (â€žInformationen verwalten, die Google verwendet, um Ihnen Werbung einzublendenâ€œ).</p>\n<h4 id=\"Youtube\"><a href=\"#Youtube\" class=\"headerlink\" title=\"Youtube\"></a>Youtube</h4><p>Wir binden die Videos der Plattform â€œYouTubeâ€ des Anbieters Google LLC, 1600 Amphitheatre Parkway, Mountain View, CA 94043, USA, ein. DatenschutzerklÃ¤rung: <a href=\"https://www.google.com/policies/privacy/\" target=\"_blank\" rel=\"noopener\">https://www.google.com/policies/privacy/</a>, Opt-Out: <a href=\"https://adssettings.google.com/authenticated\" target=\"_blank\" rel=\"noopener\">https://adssettings.google.com/authenticated</a>.</p>\n<p><a href=\"https://datenschutz-generator.de/\" target=\"_blank\" rel=\"noopener\">Erstellt mit Datenschutz-Generator.de von RA Dr. Thomas Schwenke</a></p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<h1 id=\"Imprint\"><a href=\"#Imprint\" class=\"headerlink\" title=\"Imprint\"></a>Imprint</h1><h3 id=\"Legal-Disclosure-amp-Privacy-Statement\"><a href=\"#Legal-Disclosure-amp-Privacy-Statement\" class=\"headerlink\" title=\"Legal Disclosure &amp; Privacy Statement\"></a>Legal Disclosure &amp; Privacy Statement</h3><p>Information in accordance with section 5 German TMG</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Ferdinand MÃ¼tsch</span><br><span class=\"line\">VorholzstraÃŸe 11 </span><br><span class=\"line\">76137 Karlsruhe</span><br><span class=\"line\">Germany</span><br></pre></td></tr></table></figure>\n<h3 id=\"Contact\"><a href=\"#Contact\" class=\"headerlink\" title=\"Contact\"></a>Contact</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Telephone: 0ï¸âƒ£1ï¸âƒ£7ï¸âƒ£6ï¸âƒ£4ï¸âƒ£5ï¸âƒ£6ï¸âƒ£4ï¸âƒ£1ï¸âƒ£9ï¸âƒ£7ï¸âƒ£4ï¸âƒ£</span><br><span class=\"line\">E-Mail: mail@ferdinand-muetsch.de</span><br><span class=\"line\">Web: www.ferdinand-muetsch.de</span><br></pre></td></tr></table></figure>\n<h3 id=\"Disclaimer\"><a href=\"#Disclaimer\" class=\"headerlink\" title=\"Disclaimer\"></a>Disclaimer</h3><h4 id=\"Accountability-for-content\"><a href=\"#Accountability-for-content\" class=\"headerlink\" title=\"Accountability for content\"></a>Accountability for content</h4><p>The contents of our pages have been created with the utmost care. However, we cannot guarantee the contentsâ€™ accuracy, completeness or topicality. According to statutory provisions, we are furthermore responsible for our own content on these web pages. In this context, please note that we are accordingly not obliged to monitor merely the transmitted or saved information of third parties, or investigate circumstances pointing to illegal activity. Our obligations to remove or block the use of information under generally applicable laws remain unaffected by this as per Â§Â§ 8 to 10 of the Telemedia Act (TMG).</p>\n<h4 id=\"Accountability-for-links\"><a href=\"#Accountability-for-links\" class=\"headerlink\" title=\"Accountability for links\"></a>Accountability for links</h4><p>Responsibility for the content of external links (to web pages of third parties) lies solely with the operators of the linked pages. No violations were evident to us at the time of linking. Should any legal infringement become known to us, we will remove the respective link immediately. </p>\n<h4 id=\"Copyright\"><a href=\"#Copyright\" class=\"headerlink\" title=\"Copyright\"></a>Copyright</h4><p>Our web pages and their contents are subject to German copyright law. Unless expressly permitted by law (Â§ 44a et seq. of the copyright law), every form of utilizing, reproducing or processing works subject to copyright protection on our web pages requires the prior consent of the respective owner of the rights. Individual reproductions of a work are allowed only for private use, so must not serve either directly or indirectly for earnings. Unauthorized utilization of copyrighted works is punishable (Â§ 106 of the copyright law).</p>\n<h4 id=\"General\"><a href=\"#General\" class=\"headerlink\" title=\"General\"></a>General</h4><p>Your personal data (e.g. title, name, house address, e-mail address, phone number, bank details, credit card number) are processed by us only in accordance with the provisions of German data privacy laws. The following provisions describe the type, scope and purpose of collecting, processing and utilizing personal data. This data privacy policy applies only to our web pages. If links on our pages route you to other pages, please inquire there about how your data are handled in such cases.</p>\n<h4 id=\"Inventory-data\"><a href=\"#Inventory-data\" class=\"headerlink\" title=\"Inventory data\"></a>Inventory data</h4><p>(1) Your personal data, insofar as these are necessary for this contractual relationship (inventory data) in terms of its establishment, organization of content and modifications, are used exclusively for fulfilling the contract. For goods to be delivered, for instance, your name and address must be relayed to the supplier of the goods.<br>(2) Without your explicit consent or a legal basis, your personal data are not passed on to third parties outside the scope of fulfilling this contract. After completion of the contract, your data are blocked against further use. After expiry of deadlines as per tax-related and commercial regulations, these data are deleted unless you have expressly consented to their further use.</p>\n<h4 id=\"Information-about-cookies\"><a href=\"#Information-about-cookies\" class=\"headerlink\" title=\"Information about cookies\"></a>Information about cookies</h4><p>(1) To optimize our web presence, we use cookies. These are small text files stored in your computerâ€™s main memory. These cookies are deleted after you close the browser. Other cookies remain on your computer (long-term cookies) and permit its recognition on your next visit. This allows us to improve your access to our site.<br>(2) You can prevent storage of cookies by choosing a â€œdisable cookiesâ€ option in your browser settings. But this can limit the functionality of our Internet offers as a result.</p>\n<h4 id=\"Disclosure\"><a href=\"#Disclosure\" class=\"headerlink\" title=\"Disclosure\"></a>Disclosure</h4><p>According to the Federal Data Protection Act, you have a right to free-of-charge information about your stored data, and possibly entitlement to correction, blocking or deletion of such data. Inquiries can be directed to the following e-mail addresses: ( <a href=\"mailto:mail@ferdinand-muetsch.de\">mail@ferdinand-muetsch.de</a> )</p>\n<p>Source: <a href=\"http://www.twigg.de/\" target=\"_blank\" rel=\"noopener\">twiggs translations</a></p>\n<h3 id=\"German-Privacy-Policy-Datenschutzerklarung\"><a href=\"#German-Privacy-Policy-Datenschutzerklarung\" class=\"headerlink\" title=\"German Privacy Policy (DatenschutzerklÃ¤rung)\"></a>German Privacy Policy (DatenschutzerklÃ¤rung)</h3><p>Diese DatenschutzerklÃ¤rung klÃ¤rt Sie Ã¼ber die Art, den Umfang und Zweck der Verarbeitung von personenbezogenen Daten (nachfolgend kurz â€žDatenâ€œ) innerhalb unseres Onlineangebotes und der mit ihm verbundenen Webseiten, Funktionen und Inhalte sowie externen OnlineprÃ¤senzen, wie z.B. unser Social Media Profile auf. (nachfolgend gemeinsam bezeichnet als â€žOnlineangebotâ€œ). Im Hinblick auf die verwendeten Begrifflichkeiten, wie z.B. â€žVerarbeitungâ€œ oder â€žVerantwortlicherâ€œ verweisen wir auf die Definitionen im Art. 4 der Datenschutzgrundverordnung (DSGVO).</p>\n<h4 id=\"Arten-der-verarbeiteten-Daten\"><a href=\"#Arten-der-verarbeiteten-Daten\" class=\"headerlink\" title=\"Arten der verarbeiteten Daten:\"></a>Arten der verarbeiteten Daten:</h4><ul>\n<li>Bestandsdaten (z.B., Namen, Adressen).</li>\n<li>Kontaktdaten (z.B., E-Mail, Telefonnummern).</li>\n<li>Inhaltsdaten (z.B., Texteingaben, Fotografien, Videos).</li>\n<li>Nutzungsdaten (z.B., besuchte Webseiten, Interesse an Inhalten, Zugriffszeiten).</li>\n<li>Meta-/Kommunikationsdaten (z.B., GerÃ¤te-Informationen, IP-Adressen).</li>\n</ul>\n<h4 id=\"Kategorien-betroffener-Personen\"><a href=\"#Kategorien-betroffener-Personen\" class=\"headerlink\" title=\"Kategorien betroffener Personen\"></a>Kategorien betroffener Personen</h4><p>Besucher und Nutzer des Onlineangebotes (Nachfolgend bezeichnen wir die betroffenen Personen zusammenfassend auch als â€žNutzerâ€œ).</p>\n<h4 id=\"Zweck-der-Verarbeitung\"><a href=\"#Zweck-der-Verarbeitung\" class=\"headerlink\" title=\"Zweck der Verarbeitung\"></a>Zweck der Verarbeitung</h4><ul>\n<li>ZurverfÃ¼gungstellung des Onlineangebotes, seiner Funktionen und Inhalte.</li>\n<li>Beantwortung von Kontaktanfragen und Kommunikation mit Nutzern.</li>\n<li>SicherheitsmaÃŸnahmen.</li>\n<li>Reichweitenmessung/Marketing</li>\n</ul>\n<h4 id=\"Verwendete-Begrifflichkeiten\"><a href=\"#Verwendete-Begrifflichkeiten\" class=\"headerlink\" title=\"Verwendete Begrifflichkeiten\"></a>Verwendete Begrifflichkeiten</h4><p>â€žPersonenbezogene Datenâ€œ sind alle Informationen, die sich auf eine identifizierte oder identifizierbare natÃ¼rliche Person (im Folgenden â€žbetroffene Personâ€œ) beziehen; als identifizierbar wird eine natÃ¼rliche Person angesehen, die direkt oder indirekt, insbesondere mittels Zuordnung zu einer Kennung wie einem Namen, zu einer Kennnummer, zu Standortdaten, zu einer Online-Kennung (z.B. Cookie) oder zu einem oder mehreren besonderen Merkmalen identifiziert werden kann, die Ausdruck der physischen, physiologischen, genetischen, psychischen, wirtschaftlichen, kulturellen oder sozialen IdentitÃ¤t dieser natÃ¼rlichen Person sind.</p>\n<p>â€žVerarbeitungâ€œ ist jeder mit oder ohne Hilfe automatisierter Verfahren ausgefÃ¼hrten Vorgang oder jede solche Vorgangsreihe im Zusammenhang mit personenbezogenen Daten. Der Begriff reicht weit und umfasst praktisch jeden Umgang mit Daten.</p>\n<p>Als â€žVerantwortlicherâ€œ wird die natÃ¼rliche oder juristische Person, BehÃ¶rde, Einrichtung oder andere Stelle, die allein oder gemeinsam mit anderen Ã¼ber die Zwecke und Mittel der Verarbeitung von personenbezogenen Daten entscheidet, bezeichnet.</p>\n<h4 id=\"Masgebliche-Rechtsgrundlagen\"><a href=\"#Masgebliche-Rechtsgrundlagen\" class=\"headerlink\" title=\"MaÃŸgebliche Rechtsgrundlagen\"></a>MaÃŸgebliche Rechtsgrundlagen</h4><p>Nach MaÃŸgabe des Art. 13 DSGVO teilen wir Ihnen die Rechtsgrundlagen unserer Datenverarbeitungen mit. Sofern die Rechtsgrundlage in der DatenschutzerklÃ¤rung nicht genannt wird, gilt Folgendes: Die Rechtsgrundlage fÃ¼r die Einholung von Einwilligungen ist Art. 6 Abs. 1 lit. a und Art. 7 DSGVO, die Rechtsgrundlage fÃ¼r die Verarbeitung zur ErfÃ¼llung unserer Leistungen und DurchfÃ¼hrung vertraglicher MaÃŸnahmen sowie Beantwortung von Anfragen ist Art. 6 Abs. 1 lit. b DSGVO, die Rechtsgrundlage fÃ¼r die Verarbeitung zur ErfÃ¼llung unserer rechtlichen Verpflichtungen ist Art. 6 Abs. 1 lit. c DSGVO, und die Rechtsgrundlage fÃ¼r die Verarbeitung zur Wahrung unserer berechtigten Interessen ist Art. 6 Abs. 1 lit. f DSGVO. FÃ¼r den Fall, dass lebenswichtige Interessen der betroffenen Person oder einer anderen natÃ¼rlichen Person eine Verarbeitung personenbezogener Daten erforderlich machen, dient Art. 6 Abs. 1 lit. d DSGVO als Rechtsgrundlage.</p>\n<h4 id=\"Zusammenarbeit-mit-Auftragsverarbeitern-und-Dritten\"><a href=\"#Zusammenarbeit-mit-Auftragsverarbeitern-und-Dritten\" class=\"headerlink\" title=\"Zusammenarbeit mit Auftragsverarbeitern und Dritten\"></a>Zusammenarbeit mit Auftragsverarbeitern und Dritten</h4><p>Sofern wir im Rahmen unserer Verarbeitung Daten gegenÃ¼ber anderen Personen und Unternehmen (Auftragsverarbeitern oder Dritten) offenbaren, sie an diese Ã¼bermitteln oder ihnen sonst Zugriff auf die Daten gewÃ¤hren, erfolgt dies nur auf Grundlage einer gesetzlichen Erlaubnis (z.B. wenn eine Ãœbermittlung der Daten an Dritte, wie an Zahlungsdienstleister, gem. Art. 6 Abs. 1 lit. b DSGVO zur VertragserfÃ¼llung erforderlich ist), Sie eingewilligt haben, eine rechtliche Verpflichtung dies vorsieht oder auf Grundlage unserer berechtigten Interessen (z.B. beim Einsatz von Beauftragten, Webhostern, etc.).</p>\n<p>Sofern wir Dritte mit der Verarbeitung von Daten auf Grundlage eines sog. â€žAuftragsverarbeitungsvertragesâ€œ beauftragen, geschieht dies auf Grundlage des Art. 28 DSGVO.</p>\n<h4 id=\"Ubermittlungen-in-Drittlander\"><a href=\"#Ubermittlungen-in-Drittlander\" class=\"headerlink\" title=\"Ãœbermittlungen in DrittlÃ¤nder\"></a>Ãœbermittlungen in DrittlÃ¤nder</h4><p>Sofern wir Daten in einem Drittland (d.h. auÃŸerhalb der EuropÃ¤ischen Union (EU) oder des EuropÃ¤ischen Wirtschaftsraums (EWR)) verarbeiten oder dies im Rahmen der Inanspruchnahme von Diensten Dritter oder Offenlegung, bzw. Ãœbermittlung von Daten an Dritte geschieht, erfolgt dies nur, wenn es zur ErfÃ¼llung unserer (vor)vertraglichen Pflichten, auf Grundlage Ihrer Einwilligung, aufgrund einer rechtlichen Verpflichtung oder auf Grundlage unserer berechtigten Interessen geschieht. Vorbehaltlich gesetzlicher oder vertraglicher Erlaubnisse, verarbeiten oder lassen wir die Daten in einem Drittland nur beim Vorliegen der besonderen Voraussetzungen der Art. 44 ff. DSGVO verarbeiten. D.h. die Verarbeitung erfolgt z.B. auf Grundlage besonderer Garantien, wie der offiziell anerkannten Feststellung eines der EU entsprechenden Datenschutzniveaus (z.B. fÃ¼r die USA durch das â€žPrivacy Shieldâ€œ) oder Beachtung offiziell anerkannter spezieller vertraglicher Verpflichtungen (so genannte â€žStandardvertragsklauselnâ€œ).</p>\n<h4 id=\"Rechte-der-betroffenen-Personen\"><a href=\"#Rechte-der-betroffenen-Personen\" class=\"headerlink\" title=\"Rechte der betroffenen Personen\"></a>Rechte der betroffenen Personen</h4><p>Sie haben das Recht, eine BestÃ¤tigung darÃ¼ber zu verlangen, ob betreffende Daten verarbeitet werden und auf Auskunft Ã¼ber diese Daten sowie auf weitere Informationen und Kopie der Daten entsprechend Art. 15 DSGVO.</p>\n<p>Sie haben entsprechend. Art. 16 DSGVO das Recht, die VervollstÃ¤ndigung der Sie betreffenden Daten oder die Berichtigung der Sie betreffenden unrichtigen Daten zu verlangen.</p>\n<p>Sie haben nach MaÃŸgabe des Art. 17 DSGVO das Recht zu verlangen, dass betreffende Daten unverzÃ¼glich gelÃ¶scht werden, bzw. alternativ nach MaÃŸgabe des Art. 18 DSGVO eine EinschrÃ¤nkung der Verarbeitung der Daten zu verlangen.</p>\n<p>Sie haben das Recht zu verlangen, dass die Sie betreffenden Daten, die Sie uns bereitgestellt haben nach MaÃŸgabe des Art. 20 DSGVO zu erhalten und deren Ãœbermittlung an andere Verantwortliche zu fordern.</p>\n<p>Sie haben ferner gem. Art. 77 DSGVO das Recht, eine Beschwerde bei der zustÃ¤ndigen AufsichtsbehÃ¶rde einzureichen.</p>\n<h4 id=\"Widerrufsrecht\"><a href=\"#Widerrufsrecht\" class=\"headerlink\" title=\"Widerrufsrecht\"></a>Widerrufsrecht</h4><p>Sie haben das Recht, erteilte Einwilligungen gem. Art. 7 Abs. 3 DSGVO mit Wirkung fÃ¼r die Zukunft zu widerrufen</p>\n<h4 id=\"Widerspruchsrecht\"><a href=\"#Widerspruchsrecht\" class=\"headerlink\" title=\"Widerspruchsrecht\"></a>Widerspruchsrecht</h4><p>Sie kÃ¶nnen der kÃ¼nftigen Verarbeitung der Sie betreffenden Daten nach MaÃŸgabe des Art. 21 DSGVO jederzeit widersprechen. Der Widerspruch kann insbesondere gegen die Verarbeitung fÃ¼r Zwecke der Direktwerbung erfolgen.</p>\n<h4 id=\"Cookies-und-Widerspruchsrecht-bei-Direktwerbung\"><a href=\"#Cookies-und-Widerspruchsrecht-bei-Direktwerbung\" class=\"headerlink\" title=\"Cookies und Widerspruchsrecht bei Direktwerbung\"></a>Cookies und Widerspruchsrecht bei Direktwerbung</h4><p>Als â€žCookiesâ€œ werden kleine Dateien bezeichnet, die auf Rechnern der Nutzer gespeichert werden. Innerhalb der Cookies kÃ¶nnen unterschiedliche Angaben gespeichert werden. Ein Cookie dient primÃ¤r dazu, die Angaben zu einem Nutzer (bzw. dem GerÃ¤t auf dem das Cookie gespeichert ist) wÃ¤hrend oder auch nach seinem Besuch innerhalb eines Onlineangebotes zu speichern. Als temporÃ¤re Cookies, bzw. â€žSession-Cookiesâ€œ oder â€žtransiente Cookiesâ€œ, werden Cookies bezeichnet, die gelÃ¶scht werden, nachdem ein Nutzer ein Onlineangebot verlÃ¤sst und seinen Browser schlieÃŸt. In einem solchen Cookie kann z.B. der Inhalt eines Warenkorbs in einem Onlineshop oder ein Login-Staus gespeichert werden. Als â€žpermanentâ€œ oder â€žpersistentâ€œ werden Cookies bezeichnet, die auch nach dem SchlieÃŸen des Browsers gespeichert bleiben. So kann z.B. der Login-Status gespeichert werden, wenn die Nutzer diese nach mehreren Tagen aufsuchen. Ebenso kÃ¶nnen in einem solchen Cookie die Interessen der Nutzer gespeichert werden, die fÃ¼r Reichweitenmessung oder Marketingzwecke verwendet werden. Als â€žThird-Party-Cookieâ€œ werden Cookies bezeichnet, die von anderen Anbietern als dem Verantwortlichen, der das Onlineangebot betreibt, angeboten werden (andernfalls, wenn es nur dessen Cookies sind spricht man von â€žFirst-Party Cookiesâ€œ).</p>\n<p>Wir kÃ¶nnen temporÃ¤re und permanente Cookies einsetzen und klÃ¤ren hierÃ¼ber im Rahmen unserer DatenschutzerklÃ¤rung auf.</p>\n<p>Falls die Nutzer nicht mÃ¶chten, dass Cookies auf ihrem Rechner gespeichert werden, werden sie gebeten die entsprechende Option in den Systemeinstellungen ihres Browsers zu deaktivieren. Gespeicherte Cookies kÃ¶nnen in den Systemeinstellungen des Browsers gelÃ¶scht werden. Der Ausschluss von Cookies kann zu FunktionseinschrÃ¤nkungen dieses Onlineangebotes fÃ¼hren.</p>\n<p>Ein genereller Widerspruch gegen den Einsatz der zu Zwecken des Onlinemarketing eingesetzten Cookies kann bei einer Vielzahl der Dienste, vor allem im Fall des Trackings, Ã¼ber die US-amerikanische Seite <a href=\"http://www.aboutads.info/choices/\" target=\"_blank\" rel=\"noopener\">http://www.aboutads.info/choices/</a> oder die EU-Seite <a href=\"http://www.youronlinechoices.com/\" target=\"_blank\" rel=\"noopener\">http://www.youronlinechoices.com/</a> erklÃ¤rt werden. Des Weiteren kann die Speicherung von Cookies mittels deren Abschaltung in den Einstellungen des Browsers erreicht werden. Bitte beachten Sie, dass dann gegebenenfalls nicht alle Funktionen dieses Onlineangebotes genutzt werden kÃ¶nnen.</p>\n<h4 id=\"Loschung-von-Daten\"><a href=\"#Loschung-von-Daten\" class=\"headerlink\" title=\"LÃ¶schung von Daten\"></a>LÃ¶schung von Daten</h4><p>Die von uns verarbeiteten Daten werden nach MaÃŸgabe der Art. 17 und 18 DSGVO gelÃ¶scht oder in ihrer Verarbeitung eingeschrÃ¤nkt. Sofern nicht im Rahmen dieser DatenschutzerklÃ¤rung ausdrÃ¼cklich angegeben, werden die bei uns gespeicherten Daten gelÃ¶scht, sobald sie fÃ¼r ihre Zweckbestimmung nicht mehr erforderlich sind und der LÃ¶schung keine gesetzlichen Aufbewahrungspflichten entgegenstehen. Sofern die Daten nicht gelÃ¶scht werden, weil sie fÃ¼r andere und gesetzlich zulÃ¤ssige Zwecke erforderlich sind, wird deren Verarbeitung eingeschrÃ¤nkt. D.h. die Daten werden gesperrt und nicht fÃ¼r andere Zwecke verarbeitet. Das gilt z.B. fÃ¼r Daten, die aus handels- oder steuerrechtlichen GrÃ¼nden aufbewahrt werden mÃ¼ssen.</p>\n<p>Nach gesetzlichen Vorgaben in Deutschland erfolgt die Aufbewahrung insbesondere fÃ¼r 6 Jahre gemÃ¤ÃŸ Â§ 257 Abs. 1 HGB (HandelsbÃ¼cher, Inventare, ErÃ¶ffnungsbilanzen, JahresabschlÃ¼sse, Handelsbriefe, Buchungsbelege, etc.) sowie fÃ¼r 10 Jahre gemÃ¤ÃŸ Â§ 147 Abs. 1 AO (BÃ¼cher, Aufzeichnungen, Lageberichte, Buchungsbelege, Handels- und GeschÃ¤ftsbriefe, FÃ¼r Besteuerung relevante Unterlagen, etc.).</p>\n<p>Nach gesetzlichen Vorgaben in Ã–sterreich erfolgt die Aufbewahrung insbesondere fÃ¼r 7 J gemÃ¤ÃŸ Â§ 132 Abs. 1 BAO (Buchhaltungsunterlagen, Belege/Rechnungen, Konten, Belege, GeschÃ¤ftspapiere, Aufstellung der Einnahmen und Ausgaben, etc.), fÃ¼r 22 Jahre im Zusammenhang mit GrundstÃ¼cken und fÃ¼r 10 Jahre bei Unterlagen im Zusammenhang mit elektronisch erbrachten Leistungen, Telekommunikations-, Rundfunk- und Fernsehleistungen, die an Nichtunternehmer in EU-Mitgliedstaaten erbracht werden und fÃ¼r die der Mini-One-Stop-Shop (MOSS) in Anspruch genommen wird.</p>\n<h4 id=\"Hosting\"><a href=\"#Hosting\" class=\"headerlink\" title=\"Hosting\"></a>Hosting</h4><p>Die von uns in Anspruch genommenen Hosting-Leistungen dienen der ZurverfÃ¼gungstellung der folgenden Leistungen: Infrastruktur- und Plattformdienstleistungen, RechenkapazitÃ¤t, Speicherplatz und Datenbankdienste, Sicherheitsleistungen sowie technische Wartungsleistungen, die wir zum Zwecke des Betriebs dieses Onlineangebotes einsetzen.</p>\n<p>Hierbei verarbeiten wir, bzw. unser Hostinganbieter Bestandsdaten, Kontaktdaten, Inhaltsdaten, Vertragsdaten, Nutzungsdaten, Meta- und Kommunikationsdaten von Kunden, Interessenten und Besuchern dieses Onlineangebotes auf Grundlage unserer berechtigten Interessen an einer effizienten und sicheren ZurverfÃ¼gungstellung dieses Onlineangebotes gem. Art. 6 Abs. 1 lit. f DSGVO i.V.m. Art. 28 DSGVO (Abschluss Auftragsverarbeitungsvertrag).</p>\n<h4 id=\"Erhebung-von-Zugriffsdaten-und-Logfiles\"><a href=\"#Erhebung-von-Zugriffsdaten-und-Logfiles\" class=\"headerlink\" title=\"Erhebung von Zugriffsdaten und Logfiles\"></a>Erhebung von Zugriffsdaten und Logfiles</h4><p>Wir, bzw. unser Hostinganbieter, erhebt auf Grundlage unserer berechtigten Interessen im Sinne des Art. 6 Abs. 1 lit. f. DSGVO Daten Ã¼ber jeden Zugriff auf den Server, auf dem sich dieser Dienst befindet (sogenannte Serverlogfiles). Zu den Zugriffsdaten gehÃ¶ren Name der abgerufenen Webseite, Datei, Datum und Uhrzeit des Abrufs, Ã¼bertragene Datenmenge, Meldung Ã¼ber erfolgreichen Abruf, Browsertyp nebst Version, das Betriebssystem des Nutzers, Referrer URL (die zuvor besuchte Seite), IP-Adresse und der anfragende Provider.</p>\n<p>Logfile-Informationen werden aus SicherheitsgrÃ¼nden (z.B. zur AufklÃ¤rung von Missbrauchs- oder Betrugshandlungen) fÃ¼r die Dauer von maximal 7 Tagen gespeichert und danach gelÃ¶scht. Daten, deren weitere Aufbewahrung zu Beweiszwecken erforderlich ist, sind bis zur endgÃ¼ltigen KlÃ¤rung des jeweiligen Vorfalls von der LÃ¶schung ausgenommen.</p>\n<h4 id=\"Google-Universal-Analytics\"><a href=\"#Google-Universal-Analytics\" class=\"headerlink\" title=\"Google Universal Analytics\"></a>Google Universal Analytics</h4><p>Wir setzen auf Grundlage unserer berechtigten Interessen (d.h. Interesse an der Analyse, Optimierung und wirtschaftlichem Betrieb unseres Onlineangebotes im Sinne des Art. 6 Abs. 1 lit. f. DSGVO) Google Analytics, einen Webanalysedienst der Google LLC (â€žGoogleâ€œ) ein. Google verwendet Cookies. Die durch das Cookie erzeugten Informationen Ã¼ber Benutzung des Onlineangebotes durch die Nutzer werden in der Regel an einen Server von Google in den USA Ã¼bertragen und dort gespeichert.</p>\n<p>Google ist unter dem Privacy-Shield-Abkommen zertifiziert und bietet hierdurch eine Garantie, das europÃ¤ische Datenschutzrecht einzuhalten (<a href=\"https://www.privacyshield.gov/participant?id=a2zt000000001L5AAI&amp;status=Active)\" target=\"_blank\" rel=\"noopener\">https://www.privacyshield.gov/participant?id=a2zt000000001L5AAI&amp;status=Active)</a>.</p>\n<p>Google wird diese Informationen in unserem Auftrag benutzen, um die Nutzung unseres Onlineangebotes durch die Nutzer auszuwerten, um Reports Ã¼ber die AktivitÃ¤ten innerhalb dieses Onlineangebotes zusammenzustellen und um weitere, mit der Nutzung dieses Onlineangebotes und der Internetnutzung verbundene Dienstleistungen, uns gegenÃ¼ber zu erbringen. Dabei kÃ¶nnen aus den verarbeiteten Daten pseudonyme Nutzungsprofile der Nutzer erstellt werden.</p>\n<p>Wir setzen Google Analytics in der Ausgestaltung als â€žUniversal-Analyticsâ€œ ein. â€žUniversal Analyticsâ€œ bezeichnet ein Verfahren von Google Analytics, bei dem die Nutzeranalyse auf Grundlage einer pseudonymen Nutzer-ID erfolgt und damit ein pseudonymes Profil des Nutzers mit Informationen aus der Nutzung verschiedener GerÃ¤ten erstellt wird (sog. â€žCross-Device-Trackingâ€œ).</p>\n<p>Wir setzen Google Analytics nur mit aktivierter IP-Anonymisierung ein. Das bedeutet, die IP-Adresse der Nutzer wird von Google innerhalb von Mitgliedstaaten der EuropÃ¤ischen Union oder in anderen Vertragsstaaten des Abkommens Ã¼ber den EuropÃ¤ischen Wirtschaftsraum gekÃ¼rzt. Nur in AusnahmefÃ¤llen wird die volle IP-Adresse an einen Server von Google in den USA Ã¼bertragen und dort gekÃ¼rzt.</p>\n<p>Die von dem Browser des Nutzers Ã¼bermittelte IP-Adresse wird nicht mit anderen Daten von Google zusammengefÃ¼hrt. Die Nutzer kÃ¶nnen die Speicherung der Cookies durch eine entsprechende Einstellung ihrer Browser-Software verhindern; die Nutzer kÃ¶nnen darÃ¼ber hinaus die Erfassung der durch das Cookie erzeugten und auf ihre Nutzung des Onlineangebotes bezogenen Daten an Google sowie die Verarbeitung dieser Daten durch Google verhindern, indem sie das unter folgendem Link verfÃ¼gbare Browser-Plugin herunterladen und installieren: <a href=\"http://tools.google.com/dlpage/gaoptout?hl=de\" target=\"_blank\" rel=\"noopener\">http://tools.google.com/dlpage/gaoptout?hl=de</a>.</p>\n<p>Weitere Informationen zur Datennutzung durch Google, Einstellungs- und WiderspruchsmÃ¶glichkeiten erfahren Sie auf den Webseiten von Google: <a href=\"https://www.google.com/intl/de/policies/privacy/partners\" target=\"_blank\" rel=\"noopener\">https://www.google.com/intl/de/policies/privacy/partners</a> (â€žDatennutzung durch Google bei Ihrer Nutzung von Websites oder Apps unserer Partnerâ€œ), <a href=\"http://www.google.com/policies/technologies/ads\" target=\"_blank\" rel=\"noopener\">http://www.google.com/policies/technologies/ads</a> (â€žDatennutzung zu Werbezweckenâ€œ), <a href=\"http://www.google.de/settings/ads\" target=\"_blank\" rel=\"noopener\">http://www.google.de/settings/ads</a> (â€žInformationen verwalten, die Google verwendet, um Ihnen Werbung einzublendenâ€œ).</p>\n<h4 id=\"Youtube\"><a href=\"#Youtube\" class=\"headerlink\" title=\"Youtube\"></a>Youtube</h4><p>Wir binden die Videos der Plattform â€œYouTubeâ€ des Anbieters Google LLC, 1600 Amphitheatre Parkway, Mountain View, CA 94043, USA, ein. DatenschutzerklÃ¤rung: <a href=\"https://www.google.com/policies/privacy/\" target=\"_blank\" rel=\"noopener\">https://www.google.com/policies/privacy/</a>, Opt-Out: <a href=\"https://adssettings.google.com/authenticated\" target=\"_blank\" rel=\"noopener\">https://adssettings.google.com/authenticated</a>.</p>\n<p><a href=\"https://datenschutz-generator.de/\" target=\"_blank\" rel=\"noopener\">Erstellt mit Datenschutz-Generator.de von RA Dr. Thomas Schwenke</a></p>\n"}],"Post":[{"title":"Anchr.io â€“ Image uploads, bookmarks and shortlink service","date":"2015-12-01T21:47:35.000Z","_content":"\nI want to present my latest project called [Anchr.io](https://anchr.io). It claims to be a useful little helper or toolbox or the like for common tasks on the internet. The idea arised when someday I considered it useful to have a collection of web links or bookmarks â€“ like those you have in Chrome or Firefox â€“ accessible from everywhere without needing to synchronize your browser profile. Just like if youâ€™re anywhere on an other PC, find a useful article on the internet and want to save it quickly for later at home. This is what Anchrâ€™s **collections** feature does. It saves links â€“ with an optional description for easier search and separated into seperate categories / collections.\n\n![Anchr collections](images/anchr_2.jpg)\n\nThe second feature is to **upload images**. You can easily upload one or more photos from your computer oder mobile device and send them to friends or include them into forum posts or the like. Special with Anchrâ€™s image hosting is that users are given the opportunity to client-sided **encrypt images** with a password. As a result no one without the password will ever see their photosâ€™ content.\n\n![Anchr images](/images/anchr_1.jpg)\n\nThe last feature are **shortlinks** â€“ actually not any different from those you know from [goo.gl](http://goo.gl) or [bit.ly](http://bit.ly). Theyâ€™re useful if you have a very long web link including many query parameters, access tokens, session ids, special characters and the like and want to share them. Often special characters break the linking or your chat application has a maximum length for hyperlinks. Or you just want to keep clarity in your document or emails. In this case it can be very helpful to make the links as short as any possible â€“ to be precise of a length of 22 bytes with Anchr.\n\nAnchrâ€™s focus is on ease and quickness of use â€“ short loading times, flat menu hierarchies, etc.\n\nAt the end just a few words about the technical aspect in addition. Anchr.io is separated clearly into backend and frontend or server- and client-application. Both are kept as modular as possible, trying to follow the MVC pattern. Interface between front- and backend is a REST API. The server is based in Node.js with a bunch of very cool new frameworks while the client is an Angular application. Concluding the development was both fun and such a good practice to me and the result will definitely make some of my daily processes a small little easier. I hope you give the app a try and leave me some feedback to dev(at)anchr.io.","source":"_posts/anchr-io-image-uploads-bookmarks-and-shortlink-service.md","raw":"---\ntitle: 'Anchr.io â€“ Image uploads, bookmarks and shortlink service'\ndate: 2015-12-01 22:47:35\ntags:\n---\n\nI want to present my latest project called [Anchr.io](https://anchr.io). It claims to be a useful little helper or toolbox or the like for common tasks on the internet. The idea arised when someday I considered it useful to have a collection of web links or bookmarks â€“ like those you have in Chrome or Firefox â€“ accessible from everywhere without needing to synchronize your browser profile. Just like if youâ€™re anywhere on an other PC, find a useful article on the internet and want to save it quickly for later at home. This is what Anchrâ€™s **collections** feature does. It saves links â€“ with an optional description for easier search and separated into seperate categories / collections.\n\n![Anchr collections](images/anchr_2.jpg)\n\nThe second feature is to **upload images**. You can easily upload one or more photos from your computer oder mobile device and send them to friends or include them into forum posts or the like. Special with Anchrâ€™s image hosting is that users are given the opportunity to client-sided **encrypt images** with a password. As a result no one without the password will ever see their photosâ€™ content.\n\n![Anchr images](/images/anchr_1.jpg)\n\nThe last feature are **shortlinks** â€“ actually not any different from those you know from [goo.gl](http://goo.gl) or [bit.ly](http://bit.ly). Theyâ€™re useful if you have a very long web link including many query parameters, access tokens, session ids, special characters and the like and want to share them. Often special characters break the linking or your chat application has a maximum length for hyperlinks. Or you just want to keep clarity in your document or emails. In this case it can be very helpful to make the links as short as any possible â€“ to be precise of a length of 22 bytes with Anchr.\n\nAnchrâ€™s focus is on ease and quickness of use â€“ short loading times, flat menu hierarchies, etc.\n\nAt the end just a few words about the technical aspect in addition. Anchr.io is separated clearly into backend and frontend or server- and client-application. Both are kept as modular as possible, trying to follow the MVC pattern. Interface between front- and backend is a REST API. The server is based in Node.js with a bunch of very cool new frameworks while the client is an Angular application. Concluding the development was both fun and such a good practice to me and the result will definitely make some of my daily processes a small little easier. I hope you give the app a try and leave me some feedback to dev(at)anchr.io.","slug":"anchr-io-image-uploads-bookmarks-and-shortlink-service","published":1,"updated":"2018-03-19T09:30:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2giolk0001cxrgm1uryanq","content":"<p>I want to present my latest project called <a href=\"https://anchr.io\" target=\"_blank\" rel=\"noopener\">Anchr.io</a>. It claims to be a useful little helper or toolbox or the like for common tasks on the internet. The idea arised when someday I considered it useful to have a collection of web links or bookmarks â€“ like those you have in Chrome or Firefox â€“ accessible from everywhere without needing to synchronize your browser profile. Just like if youâ€™re anywhere on an other PC, find a useful article on the internet and want to save it quickly for later at home. This is what Anchrâ€™s <strong>collections</strong> feature does. It saves links â€“ with an optional description for easier search and separated into seperate categories / collections.</p>\n<p><img src=\"images/anchr_2.jpg\" alt=\"Anchr collections\"></p>\n<p>The second feature is to <strong>upload images</strong>. You can easily upload one or more photos from your computer oder mobile device and send them to friends or include them into forum posts or the like. Special with Anchrâ€™s image hosting is that users are given the opportunity to client-sided <strong>encrypt images</strong> with a password. As a result no one without the password will ever see their photosâ€™ content.</p>\n<p><img src=\"/images/anchr_1.jpg\" alt=\"Anchr images\"></p>\n<p>The last feature are <strong>shortlinks</strong> â€“ actually not any different from those you know from <a href=\"http://goo.gl\" target=\"_blank\" rel=\"noopener\">goo.gl</a> or <a href=\"http://bit.ly\" target=\"_blank\" rel=\"noopener\">bit.ly</a>. Theyâ€™re useful if you have a very long web link including many query parameters, access tokens, session ids, special characters and the like and want to share them. Often special characters break the linking or your chat application has a maximum length for hyperlinks. Or you just want to keep clarity in your document or emails. In this case it can be very helpful to make the links as short as any possible â€“ to be precise of a length of 22 bytes with Anchr.</p>\n<p>Anchrâ€™s focus is on ease and quickness of use â€“ short loading times, flat menu hierarchies, etc.</p>\n<p>At the end just a few words about the technical aspect in addition. Anchr.io is separated clearly into backend and frontend or server- and client-application. Both are kept as modular as possible, trying to follow the MVC pattern. Interface between front- and backend is a REST API. The server is based in Node.js with a bunch of very cool new frameworks while the client is an Angular application. Concluding the development was both fun and such a good practice to me and the result will definitely make some of my daily processes a small little easier. I hope you give the app a try and leave me some feedback to dev(at)anchr.io.</p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<p>I want to present my latest project called <a href=\"https://anchr.io\" target=\"_blank\" rel=\"noopener\">Anchr.io</a>. It claims to be a useful little helper or toolbox or the like for common tasks on the internet. The idea arised when someday I considered it useful to have a collection of web links or bookmarks â€“ like those you have in Chrome or Firefox â€“ accessible from everywhere without needing to synchronize your browser profile. Just like if youâ€™re anywhere on an other PC, find a useful article on the internet and want to save it quickly for later at home. This is what Anchrâ€™s <strong>collections</strong> feature does. It saves links â€“ with an optional description for easier search and separated into seperate categories / collections.</p>\n<p><img src=\"images/anchr_2.jpg\" alt=\"Anchr collections\"></p>\n<p>The second feature is to <strong>upload images</strong>. You can easily upload one or more photos from your computer oder mobile device and send them to friends or include them into forum posts or the like. Special with Anchrâ€™s image hosting is that users are given the opportunity to client-sided <strong>encrypt images</strong> with a password. As a result no one without the password will ever see their photosâ€™ content.</p>\n<p><img src=\"/images/anchr_1.jpg\" alt=\"Anchr images\"></p>\n<p>The last feature are <strong>shortlinks</strong> â€“ actually not any different from those you know from <a href=\"http://goo.gl\" target=\"_blank\" rel=\"noopener\">goo.gl</a> or <a href=\"http://bit.ly\" target=\"_blank\" rel=\"noopener\">bit.ly</a>. Theyâ€™re useful if you have a very long web link including many query parameters, access tokens, session ids, special characters and the like and want to share them. Often special characters break the linking or your chat application has a maximum length for hyperlinks. Or you just want to keep clarity in your document or emails. In this case it can be very helpful to make the links as short as any possible â€“ to be precise of a length of 22 bytes with Anchr.</p>\n<p>Anchrâ€™s focus is on ease and quickness of use â€“ short loading times, flat menu hierarchies, etc.</p>\n<p>At the end just a few words about the technical aspect in addition. Anchr.io is separated clearly into backend and frontend or server- and client-application. Both are kept as modular as possible, trying to follow the MVC pattern. Interface between front- and backend is a REST API. The server is based in Node.js with a bunch of very cool new frameworks while the client is an Angular application. Concluding the development was both fun and such a good practice to me and the result will definitely make some of my daily processes a small little easier. I hope you give the app a try and leave me some feedback to dev(at)anchr.io.</p>\n"},{"title":"Caddy - a modern web server (vs. nginx)","date":"2017-01-09T22:07:55.000Z","_content":"\n__Update:__ I'm glad to tell that this article made it to the front page of [Hacker News](https://news.ycombinator.com/news) only a few hours after publication ðŸ¤“.\n\nAt the time of writing this article the web is effectively powered by three different major web server software packages. A web server, as covered in this article, basically has two purposes. One is to serve static (no dynamic functionality, no backend, no databse, ...) web sites, usually consisting of HTML, JavaScript and CSS plus images etc. The other is to act as a [reverse-proxy](https://en.wikipedia.org/wiki/Reverse_proxy) to web application backends. The three servers I just mentioned have a combined market share of 94.7 % (according to [this statistic](https://w3techs.com/technologies/overview/web_server/all)) and are named [Apache 2](https://httpd.apache.org/) (or _httpd_) (written in C), [nginx](https://www.nginx.com/solutions/web-server/) (say _\"engine ex\"_) (also written in C) and [Microsoft IIS](https://www.iis.net/) (written in C++). While the first two are platform independent and open-source, the latter is a proprietary, commercial, Windows-only Microsoft product and therefore more interesting at enterprise level rather than for smaller indie projects. Consequently I won't cover IIS further in the following. \n\n![Most popular web servers on the internet](images/webservers.png)\n\n_Most popular web servers on the internet ([Source](https://w3techs.com/technologies/overview/web_server/all))_\n\nnginx' first release was in 2004 and Apache2's roots even date back to 1995. Of course both projects are getting updates regularly, but their base concepts still remain the same. And at some point they might not perfectly fit today's requirements anymore. \n\nPersonally I switched from Apache2 to nginx a few months ago mainly because of two reasons. The first one was that I had really been annoyed by [Apache2's extremely high memory overhead](https://help.dreamhost.com/hc/en-us/articles/215945987-Web-server-performance-comparison). The second reason was that Apache2 still didn't have HTTP/2.0 support in 2016.\n\n![Apache2 vs. nginx memory usage](https://objects-us-west-1.dream.io/kbimages/images/Webserver_memory_graph.jpg)\n\n_Apache2 vs. nginx memory usage ([Source](https://help.dreamhost.com/hc/en-us/articles/215945987-Web-server-performance-comparison))_\n\nI was pretty happy with nginx and especially its performance as well as the large amount of documentation and forum posts on the web about every conceivable problem were great. But since I'm a developer and not a sysadmin there's one thing I didn't like. The configuration is not that intuitive and you really need to get into the syntax and concepts to get an understanding of knobs to turn in order to achieve a certain goal. It's also much more fine-grained than necessary for the average user. Personally I just want a simple config file with an intuitive syntax where I can tell my web server which static content to display or which backend to reverse-proxy for which route / domain. This, plus some additional features like handling compression, TLS encryption, authentication and maybe some basic rewrites, is fine. Looking for a more modern web server that fulfills these requirements I found [Caddy](https://caddyserver.com). As it turned out, it can even do a lot more cool things, while still being easy to use.\n\nCaddy is written is Go, open-source and pretty actively (according to commit history) developed on [GitHub](https://github.com/mholt/caddy). The goal when developing Caddy was exactly what I was looking for: easy configuration and fitness for today's web applications. It comes with HTTP/2.0 (and even QUIC) support out of the box and serves via HTTPS by default (HTTP to HTTPS redirection is also handled automatically, while you manually had to tell Apache2 or nginx to do so). It even obtains (and regularly renews!) [Let's Encrypt](https://letsencrypt.org/) certificates for every (sub)domain you specified in the config file. While enabling HTTPS for a site was really a pain some years ago, it's done completely automatically now. You don't need to run any script. You don't even need to create a Let's Encrypt account or install the _certbot_. At the center of Caddy are is the _middleware_ (or _directives_), which are added to the config as a one-liner. The [list of such](https://caddyserver.com/docs/) is long and you will find a middleware for almost everything. For instance there are middleware components for logging, gzipping, header modification, (basic or [JWT](https://jwt.io)-based) authentication and load balancing. But also more fancy things like automatically serving Markdown as HTML, a plug-and-play file browser GUI, HTML minification, IP filtering or pattern-based text replacement in HTML files are available as middlewares. Caddy also aligns well with PHP, using _php-fpm_, just as nginx does. As usual with Go applications, the entire program is shipped as a single binary (available for Windows, Mac, Linux and BSD), which includes all of its dependencies. Consequently you don't need to install any further libraries to be linked (-> no version conflicts), what really makes the installation a no-brainer. However, this introduces one little drawback in comparison to nginx modules: every middleware you want to use needs to be included into the binary and if it's not, you need to re-compile the program (which is done for you by the download script at Caddy website, actually). \n\nI migrated all of my websites and -apps from nginx to Caddy (which took me hardly more than an hour) and so far I'm happy with the setup. But what about performance?\n\nTo measure a very basic performance benchmark, I took [this script](https://github.com/n1try/http-server-benchmarks/blob/master/run-load.sh), which I used in [an earlier benchmark scenario](https://ferdinand-muetsch.de/http-performance-java-jersey-vs-go-vs-nodejs.html). This script uses the [h2load](https://github.com/nghttp2/nghttp2#benchmarking-tool) load test tool and I adjusted the parameters in a way that it performs a total of __100,000 requests__ against a specific route at my webserver with a number of __32 concurrent clients__ (each performing 3,125 requests) on __4 CPU threads__. I ran both servers with almost their default configuration, except that I turned on HTTP/2.0 with a self-signed certificate. The file served was a static HTML file containing 6.2 kBytes of data. Both h2load and the respective web server were executed locally on the same machine with the following specs.\n\n```\n===CPU:\nmodel name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores : 2\nmodel name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores : 2\nmodel name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores : 2\nmodel name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores : 2\n \n===RAM: \n              total        used        free      shared  buff/cache   available\nMem:           7,7G        1,8G        4,2G        316M        1,6G        5,3G\nSwap:           29G          0B         29G\n \n===OS: \nLinux ferdinand-ubuntu 4.8.0-32-generic #34-Ubuntu SMP Tue Dec 13 14:30:43 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n```\n\nThe results look like this.\n![](images/webserver_performance.png)\n\n_Caddy vs. nginx performance comparison_\n\nAs you can clearly see, nginx still performs way better, at least in this very simple scenario. However, Caddy is much more easy to use, in my opinion. Seems like we are having a classical trade-off here. Anyway, you should really give Caddy a try (and I'm not getting paid for this ðŸ˜‰). Concerning memory usage: I didn't observe that in detail, but suprisingly I found that neither the Caddy process nor the sum of nginx worker processes exceeded 10 MB of RAM usage (may I have done something wrong?).\n\nPlease note that I only measured one specific figure (concurrent req/s) in one specific scenario. One can think of other benchmark setups where results might be the complete opposite, potentially.\n\nBy the way, Apache2 was not included to this benchmark, because I wanted to use HTTP/2.0. Actually in the meantime there is a `mod_http2` for Apache2, but it's not included in the majority of the builds, yet, and to be honest, I didn't want to make an own one. If you're interested in that, you can get a rough idea of Apache2 vs. nginx performance in [this article](https://help.dreamhost.com/hc/en-us/articles/215945987-Web-server-performance-comparison) (spoiler: it's pretty poor).\n\nSo to conclude the discussion: Should you use Caddy in preference to nginx or Apache2? For private projects definitely yes, if you asked me. For more _serious_ projects you should probably wait until it's even a little more mature (e.g. when a 1.x.x version is out) and maybe also incorporating dynamic module loading. Until then I'd stick with nginx. Besides that I can't figure out a reason for preferring Apache2 over nginx, except for being too lazy to do the migration.\n\nPlease let me know if you liked my article and also if you don't agree with some of my arguments and insights.","source":"_posts/caddy-a-modern-web-server-vs-nginx.md","raw":"---\ntitle: Caddy - a modern web server (vs. nginx)\ndate: 2017-01-09 23:07:55\ntags:\n---\n\n__Update:__ I'm glad to tell that this article made it to the front page of [Hacker News](https://news.ycombinator.com/news) only a few hours after publication ðŸ¤“.\n\nAt the time of writing this article the web is effectively powered by three different major web server software packages. A web server, as covered in this article, basically has two purposes. One is to serve static (no dynamic functionality, no backend, no databse, ...) web sites, usually consisting of HTML, JavaScript and CSS plus images etc. The other is to act as a [reverse-proxy](https://en.wikipedia.org/wiki/Reverse_proxy) to web application backends. The three servers I just mentioned have a combined market share of 94.7 % (according to [this statistic](https://w3techs.com/technologies/overview/web_server/all)) and are named [Apache 2](https://httpd.apache.org/) (or _httpd_) (written in C), [nginx](https://www.nginx.com/solutions/web-server/) (say _\"engine ex\"_) (also written in C) and [Microsoft IIS](https://www.iis.net/) (written in C++). While the first two are platform independent and open-source, the latter is a proprietary, commercial, Windows-only Microsoft product and therefore more interesting at enterprise level rather than for smaller indie projects. Consequently I won't cover IIS further in the following. \n\n![Most popular web servers on the internet](images/webservers.png)\n\n_Most popular web servers on the internet ([Source](https://w3techs.com/technologies/overview/web_server/all))_\n\nnginx' first release was in 2004 and Apache2's roots even date back to 1995. Of course both projects are getting updates regularly, but their base concepts still remain the same. And at some point they might not perfectly fit today's requirements anymore. \n\nPersonally I switched from Apache2 to nginx a few months ago mainly because of two reasons. The first one was that I had really been annoyed by [Apache2's extremely high memory overhead](https://help.dreamhost.com/hc/en-us/articles/215945987-Web-server-performance-comparison). The second reason was that Apache2 still didn't have HTTP/2.0 support in 2016.\n\n![Apache2 vs. nginx memory usage](https://objects-us-west-1.dream.io/kbimages/images/Webserver_memory_graph.jpg)\n\n_Apache2 vs. nginx memory usage ([Source](https://help.dreamhost.com/hc/en-us/articles/215945987-Web-server-performance-comparison))_\n\nI was pretty happy with nginx and especially its performance as well as the large amount of documentation and forum posts on the web about every conceivable problem were great. But since I'm a developer and not a sysadmin there's one thing I didn't like. The configuration is not that intuitive and you really need to get into the syntax and concepts to get an understanding of knobs to turn in order to achieve a certain goal. It's also much more fine-grained than necessary for the average user. Personally I just want a simple config file with an intuitive syntax where I can tell my web server which static content to display or which backend to reverse-proxy for which route / domain. This, plus some additional features like handling compression, TLS encryption, authentication and maybe some basic rewrites, is fine. Looking for a more modern web server that fulfills these requirements I found [Caddy](https://caddyserver.com). As it turned out, it can even do a lot more cool things, while still being easy to use.\n\nCaddy is written is Go, open-source and pretty actively (according to commit history) developed on [GitHub](https://github.com/mholt/caddy). The goal when developing Caddy was exactly what I was looking for: easy configuration and fitness for today's web applications. It comes with HTTP/2.0 (and even QUIC) support out of the box and serves via HTTPS by default (HTTP to HTTPS redirection is also handled automatically, while you manually had to tell Apache2 or nginx to do so). It even obtains (and regularly renews!) [Let's Encrypt](https://letsencrypt.org/) certificates for every (sub)domain you specified in the config file. While enabling HTTPS for a site was really a pain some years ago, it's done completely automatically now. You don't need to run any script. You don't even need to create a Let's Encrypt account or install the _certbot_. At the center of Caddy are is the _middleware_ (or _directives_), which are added to the config as a one-liner. The [list of such](https://caddyserver.com/docs/) is long and you will find a middleware for almost everything. For instance there are middleware components for logging, gzipping, header modification, (basic or [JWT](https://jwt.io)-based) authentication and load balancing. But also more fancy things like automatically serving Markdown as HTML, a plug-and-play file browser GUI, HTML minification, IP filtering or pattern-based text replacement in HTML files are available as middlewares. Caddy also aligns well with PHP, using _php-fpm_, just as nginx does. As usual with Go applications, the entire program is shipped as a single binary (available for Windows, Mac, Linux and BSD), which includes all of its dependencies. Consequently you don't need to install any further libraries to be linked (-> no version conflicts), what really makes the installation a no-brainer. However, this introduces one little drawback in comparison to nginx modules: every middleware you want to use needs to be included into the binary and if it's not, you need to re-compile the program (which is done for you by the download script at Caddy website, actually). \n\nI migrated all of my websites and -apps from nginx to Caddy (which took me hardly more than an hour) and so far I'm happy with the setup. But what about performance?\n\nTo measure a very basic performance benchmark, I took [this script](https://github.com/n1try/http-server-benchmarks/blob/master/run-load.sh), which I used in [an earlier benchmark scenario](https://ferdinand-muetsch.de/http-performance-java-jersey-vs-go-vs-nodejs.html). This script uses the [h2load](https://github.com/nghttp2/nghttp2#benchmarking-tool) load test tool and I adjusted the parameters in a way that it performs a total of __100,000 requests__ against a specific route at my webserver with a number of __32 concurrent clients__ (each performing 3,125 requests) on __4 CPU threads__. I ran both servers with almost their default configuration, except that I turned on HTTP/2.0 with a self-signed certificate. The file served was a static HTML file containing 6.2 kBytes of data. Both h2load and the respective web server were executed locally on the same machine with the following specs.\n\n```\n===CPU:\nmodel name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores : 2\nmodel name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores : 2\nmodel name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores : 2\nmodel name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores : 2\n \n===RAM: \n              total        used        free      shared  buff/cache   available\nMem:           7,7G        1,8G        4,2G        316M        1,6G        5,3G\nSwap:           29G          0B         29G\n \n===OS: \nLinux ferdinand-ubuntu 4.8.0-32-generic #34-Ubuntu SMP Tue Dec 13 14:30:43 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n```\n\nThe results look like this.\n![](images/webserver_performance.png)\n\n_Caddy vs. nginx performance comparison_\n\nAs you can clearly see, nginx still performs way better, at least in this very simple scenario. However, Caddy is much more easy to use, in my opinion. Seems like we are having a classical trade-off here. Anyway, you should really give Caddy a try (and I'm not getting paid for this ðŸ˜‰). Concerning memory usage: I didn't observe that in detail, but suprisingly I found that neither the Caddy process nor the sum of nginx worker processes exceeded 10 MB of RAM usage (may I have done something wrong?).\n\nPlease note that I only measured one specific figure (concurrent req/s) in one specific scenario. One can think of other benchmark setups where results might be the complete opposite, potentially.\n\nBy the way, Apache2 was not included to this benchmark, because I wanted to use HTTP/2.0. Actually in the meantime there is a `mod_http2` for Apache2, but it's not included in the majority of the builds, yet, and to be honest, I didn't want to make an own one. If you're interested in that, you can get a rough idea of Apache2 vs. nginx performance in [this article](https://help.dreamhost.com/hc/en-us/articles/215945987-Web-server-performance-comparison) (spoiler: it's pretty poor).\n\nSo to conclude the discussion: Should you use Caddy in preference to nginx or Apache2? For private projects definitely yes, if you asked me. For more _serious_ projects you should probably wait until it's even a little more mature (e.g. when a 1.x.x version is out) and maybe also incorporating dynamic module loading. Until then I'd stick with nginx. Besides that I can't figure out a reason for preferring Apache2 over nginx, except for being too lazy to do the migration.\n\nPlease let me know if you liked my article and also if you don't agree with some of my arguments and insights.","slug":"caddy-a-modern-web-server-vs-nginx","published":1,"updated":"2018-03-19T09:30:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2giolo0003cxrgvhwcii5w","content":"<p><strong>Update:</strong> Iâ€™m glad to tell that this article made it to the front page of <a href=\"https://news.ycombinator.com/news\" target=\"_blank\" rel=\"noopener\">Hacker News</a> only a few hours after publication ðŸ¤“.</p>\n<p>At the time of writing this article the web is effectively powered by three different major web server software packages. A web server, as covered in this article, basically has two purposes. One is to serve static (no dynamic functionality, no backend, no databse, â€¦) web sites, usually consisting of HTML, JavaScript and CSS plus images etc. The other is to act as a <a href=\"https://en.wikipedia.org/wiki/Reverse_proxy\" target=\"_blank\" rel=\"noopener\">reverse-proxy</a> to web application backends. The three servers I just mentioned have a combined market share of 94.7 % (according to <a href=\"https://w3techs.com/technologies/overview/web_server/all\" target=\"_blank\" rel=\"noopener\">this statistic</a>) and are named <a href=\"https://httpd.apache.org/\" target=\"_blank\" rel=\"noopener\">Apache 2</a> (or <em>httpd</em>) (written in C), <a href=\"https://www.nginx.com/solutions/web-server/\" target=\"_blank\" rel=\"noopener\">nginx</a> (say <em>â€œengine exâ€</em>) (also written in C) and <a href=\"https://www.iis.net/\" target=\"_blank\" rel=\"noopener\">Microsoft IIS</a> (written in C++). While the first two are platform independent and open-source, the latter is a proprietary, commercial, Windows-only Microsoft product and therefore more interesting at enterprise level rather than for smaller indie projects. Consequently I wonâ€™t cover IIS further in the following. </p>\n<p><img src=\"images/webservers.png\" alt=\"Most popular web servers on the internet\"></p>\n<p>_Most popular web servers on the internet (<a href=\"https://w3techs.com/technologies/overview/web_server/all\" target=\"_blank\" rel=\"noopener\">Source</a>)_</p>\n<p>nginxâ€™ first release was in 2004 and Apache2â€™s roots even date back to 1995. Of course both projects are getting updates regularly, but their base concepts still remain the same. And at some point they might not perfectly fit todayâ€™s requirements anymore. </p>\n<p>Personally I switched from Apache2 to nginx a few months ago mainly because of two reasons. The first one was that I had really been annoyed by <a href=\"https://help.dreamhost.com/hc/en-us/articles/215945987-Web-server-performance-comparison\" target=\"_blank\" rel=\"noopener\">Apache2â€™s extremely high memory overhead</a>. The second reason was that Apache2 still didnâ€™t have HTTP/2.0 support in 2016.</p>\n<p><img src=\"https://objects-us-west-1.dream.io/kbimages/images/Webserver_memory_graph.jpg\" alt=\"Apache2 vs. nginx memory usage\"></p>\n<p><em>Apache2 vs. nginx memory usage (<a href=\"https://help.dreamhost.com/hc/en-us/articles/215945987-Web-server-performance-comparison\" target=\"_blank\" rel=\"noopener\">Source</a>)</em></p>\n<p>I was pretty happy with nginx and especially its performance as well as the large amount of documentation and forum posts on the web about every conceivable problem were great. But since Iâ€™m a developer and not a sysadmin thereâ€™s one thing I didnâ€™t like. The configuration is not that intuitive and you really need to get into the syntax and concepts to get an understanding of knobs to turn in order to achieve a certain goal. Itâ€™s also much more fine-grained than necessary for the average user. Personally I just want a simple config file with an intuitive syntax where I can tell my web server which static content to display or which backend to reverse-proxy for which route / domain. This, plus some additional features like handling compression, TLS encryption, authentication and maybe some basic rewrites, is fine. Looking for a more modern web server that fulfills these requirements I found <a href=\"https://caddyserver.com\" target=\"_blank\" rel=\"noopener\">Caddy</a>. As it turned out, it can even do a lot more cool things, while still being easy to use.</p>\n<p>Caddy is written is Go, open-source and pretty actively (according to commit history) developed on <a href=\"https://github.com/mholt/caddy\" target=\"_blank\" rel=\"noopener\">GitHub</a>. The goal when developing Caddy was exactly what I was looking for: easy configuration and fitness for todayâ€™s web applications. It comes with HTTP/2.0 (and even QUIC) support out of the box and serves via HTTPS by default (HTTP to HTTPS redirection is also handled automatically, while you manually had to tell Apache2 or nginx to do so). It even obtains (and regularly renews!) <a href=\"https://letsencrypt.org/\" target=\"_blank\" rel=\"noopener\">Letâ€™s Encrypt</a> certificates for every (sub)domain you specified in the config file. While enabling HTTPS for a site was really a pain some years ago, itâ€™s done completely automatically now. You donâ€™t need to run any script. You donâ€™t even need to create a Letâ€™s Encrypt account or install the <em>certbot</em>. At the center of Caddy are is the <em>middleware</em> (or <em>directives</em>), which are added to the config as a one-liner. The <a href=\"https://caddyserver.com/docs/\" target=\"_blank\" rel=\"noopener\">list of such</a> is long and you will find a middleware for almost everything. For instance there are middleware components for logging, gzipping, header modification, (basic or <a href=\"https://jwt.io\" target=\"_blank\" rel=\"noopener\">JWT</a>-based) authentication and load balancing. But also more fancy things like automatically serving Markdown as HTML, a plug-and-play file browser GUI, HTML minification, IP filtering or pattern-based text replacement in HTML files are available as middlewares. Caddy also aligns well with PHP, using <em>php-fpm</em>, just as nginx does. As usual with Go applications, the entire program is shipped as a single binary (available for Windows, Mac, Linux and BSD), which includes all of its dependencies. Consequently you donâ€™t need to install any further libraries to be linked (-&gt; no version conflicts), what really makes the installation a no-brainer. However, this introduces one little drawback in comparison to nginx modules: every middleware you want to use needs to be included into the binary and if itâ€™s not, you need to re-compile the program (which is done for you by the download script at Caddy website, actually). </p>\n<p>I migrated all of my websites and -apps from nginx to Caddy (which took me hardly more than an hour) and so far Iâ€™m happy with the setup. But what about performance?</p>\n<p>To measure a very basic performance benchmark, I took <a href=\"https://github.com/n1try/http-server-benchmarks/blob/master/run-load.sh\" target=\"_blank\" rel=\"noopener\">this script</a>, which I used in <a href=\"https://ferdinand-muetsch.de/http-performance-java-jersey-vs-go-vs-nodejs.html\">an earlier benchmark scenario</a>. This script uses the <a href=\"https://github.com/nghttp2/nghttp2#benchmarking-tool\" target=\"_blank\" rel=\"noopener\">h2load</a> load test tool and I adjusted the parameters in a way that it performs a total of <strong>100,000 requests</strong> against a specific route at my webserver with a number of <strong>32 concurrent clients</strong> (each performing 3,125 requests) on <strong>4 CPU threads</strong>. I ran both servers with almost their default configuration, except that I turned on HTTP/2.0 with a self-signed certificate. The file served was a static HTML file containing 6.2 kBytes of data. Both h2load and the respective web server were executed locally on the same machine with the following specs.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">===CPU:</span><br><span class=\"line\">model name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</span><br><span class=\"line\">cpu cores : 2</span><br><span class=\"line\">model name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</span><br><span class=\"line\">cpu cores : 2</span><br><span class=\"line\">model name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</span><br><span class=\"line\">cpu cores : 2</span><br><span class=\"line\">model name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</span><br><span class=\"line\">cpu cores : 2</span><br><span class=\"line\"> </span><br><span class=\"line\">===RAM: </span><br><span class=\"line\">              total        used        free      shared  buff/cache   available</span><br><span class=\"line\">Mem:           7,7G        1,8G        4,2G        316M        1,6G        5,3G</span><br><span class=\"line\">Swap:           29G          0B         29G</span><br><span class=\"line\"> </span><br><span class=\"line\">===OS: </span><br><span class=\"line\">Linux ferdinand-ubuntu 4.8.0-32-generic #34-Ubuntu SMP Tue Dec 13 14:30:43 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux</span><br></pre></td></tr></table></figure>\n<p>The results look like this.<br><img src=\"images/webserver_performance.png\" alt=\"\"></p>\n<p><em>Caddy vs. nginx performance comparison</em></p>\n<p>As you can clearly see, nginx still performs way better, at least in this very simple scenario. However, Caddy is much more easy to use, in my opinion. Seems like we are having a classical trade-off here. Anyway, you should really give Caddy a try (and Iâ€™m not getting paid for this ðŸ˜‰). Concerning memory usage: I didnâ€™t observe that in detail, but suprisingly I found that neither the Caddy process nor the sum of nginx worker processes exceeded 10 MB of RAM usage (may I have done something wrong?).</p>\n<p>Please note that I only measured one specific figure (concurrent req/s) in one specific scenario. One can think of other benchmark setups where results might be the complete opposite, potentially.</p>\n<p>By the way, Apache2 was not included to this benchmark, because I wanted to use HTTP/2.0. Actually in the meantime there is a <code>mod_http2</code> for Apache2, but itâ€™s not included in the majority of the builds, yet, and to be honest, I didnâ€™t want to make an own one. If youâ€™re interested in that, you can get a rough idea of Apache2 vs. nginx performance in <a href=\"https://help.dreamhost.com/hc/en-us/articles/215945987-Web-server-performance-comparison\" target=\"_blank\" rel=\"noopener\">this article</a> (spoiler: itâ€™s pretty poor).</p>\n<p>So to conclude the discussion: Should you use Caddy in preference to nginx or Apache2? For private projects definitely yes, if you asked me. For more <em>serious</em> projects you should probably wait until itâ€™s even a little more mature (e.g. when a 1.x.x version is out) and maybe also incorporating dynamic module loading. Until then Iâ€™d stick with nginx. Besides that I canâ€™t figure out a reason for preferring Apache2 over nginx, except for being too lazy to do the migration.</p>\n<p>Please let me know if you liked my article and also if you donâ€™t agree with some of my arguments and insights.</p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<p><strong>Update:</strong> Iâ€™m glad to tell that this article made it to the front page of <a href=\"https://news.ycombinator.com/news\" target=\"_blank\" rel=\"noopener\">Hacker News</a> only a few hours after publication ðŸ¤“.</p>\n<p>At the time of writing this article the web is effectively powered by three different major web server software packages. A web server, as covered in this article, basically has two purposes. One is to serve static (no dynamic functionality, no backend, no databse, â€¦) web sites, usually consisting of HTML, JavaScript and CSS plus images etc. The other is to act as a <a href=\"https://en.wikipedia.org/wiki/Reverse_proxy\" target=\"_blank\" rel=\"noopener\">reverse-proxy</a> to web application backends. The three servers I just mentioned have a combined market share of 94.7 % (according to <a href=\"https://w3techs.com/technologies/overview/web_server/all\" target=\"_blank\" rel=\"noopener\">this statistic</a>) and are named <a href=\"https://httpd.apache.org/\" target=\"_blank\" rel=\"noopener\">Apache 2</a> (or <em>httpd</em>) (written in C), <a href=\"https://www.nginx.com/solutions/web-server/\" target=\"_blank\" rel=\"noopener\">nginx</a> (say <em>â€œengine exâ€</em>) (also written in C) and <a href=\"https://www.iis.net/\" target=\"_blank\" rel=\"noopener\">Microsoft IIS</a> (written in C++). While the first two are platform independent and open-source, the latter is a proprietary, commercial, Windows-only Microsoft product and therefore more interesting at enterprise level rather than for smaller indie projects. Consequently I wonâ€™t cover IIS further in the following. </p>\n<p><img src=\"images/webservers.png\" alt=\"Most popular web servers on the internet\"></p>\n<p>_Most popular web servers on the internet (<a href=\"https://w3techs.com/technologies/overview/web_server/all\" target=\"_blank\" rel=\"noopener\">Source</a>)_</p>\n<p>nginxâ€™ first release was in 2004 and Apache2â€™s roots even date back to 1995. Of course both projects are getting updates regularly, but their base concepts still remain the same. And at some point they might not perfectly fit todayâ€™s requirements anymore. </p>\n<p>Personally I switched from Apache2 to nginx a few months ago mainly because of two reasons. The first one was that I had really been annoyed by <a href=\"https://help.dreamhost.com/hc/en-us/articles/215945987-Web-server-performance-comparison\" target=\"_blank\" rel=\"noopener\">Apache2â€™s extremely high memory overhead</a>. The second reason was that Apache2 still didnâ€™t have HTTP/2.0 support in 2016.</p>\n<p><img src=\"https://objects-us-west-1.dream.io/kbimages/images/Webserver_memory_graph.jpg\" alt=\"Apache2 vs. nginx memory usage\"></p>\n<p><em>Apache2 vs. nginx memory usage (<a href=\"https://help.dreamhost.com/hc/en-us/articles/215945987-Web-server-performance-comparison\" target=\"_blank\" rel=\"noopener\">Source</a>)</em></p>\n<p>I was pretty happy with nginx and especially its performance as well as the large amount of documentation and forum posts on the web about every conceivable problem were great. But since Iâ€™m a developer and not a sysadmin thereâ€™s one thing I didnâ€™t like. The configuration is not that intuitive and you really need to get into the syntax and concepts to get an understanding of knobs to turn in order to achieve a certain goal. Itâ€™s also much more fine-grained than necessary for the average user. Personally I just want a simple config file with an intuitive syntax where I can tell my web server which static content to display or which backend to reverse-proxy for which route / domain. This, plus some additional features like handling compression, TLS encryption, authentication and maybe some basic rewrites, is fine. Looking for a more modern web server that fulfills these requirements I found <a href=\"https://caddyserver.com\" target=\"_blank\" rel=\"noopener\">Caddy</a>. As it turned out, it can even do a lot more cool things, while still being easy to use.</p>\n<p>Caddy is written is Go, open-source and pretty actively (according to commit history) developed on <a href=\"https://github.com/mholt/caddy\" target=\"_blank\" rel=\"noopener\">GitHub</a>. The goal when developing Caddy was exactly what I was looking for: easy configuration and fitness for todayâ€™s web applications. It comes with HTTP/2.0 (and even QUIC) support out of the box and serves via HTTPS by default (HTTP to HTTPS redirection is also handled automatically, while you manually had to tell Apache2 or nginx to do so). It even obtains (and regularly renews!) <a href=\"https://letsencrypt.org/\" target=\"_blank\" rel=\"noopener\">Letâ€™s Encrypt</a> certificates for every (sub)domain you specified in the config file. While enabling HTTPS for a site was really a pain some years ago, itâ€™s done completely automatically now. You donâ€™t need to run any script. You donâ€™t even need to create a Letâ€™s Encrypt account or install the <em>certbot</em>. At the center of Caddy are is the <em>middleware</em> (or <em>directives</em>), which are added to the config as a one-liner. The <a href=\"https://caddyserver.com/docs/\" target=\"_blank\" rel=\"noopener\">list of such</a> is long and you will find a middleware for almost everything. For instance there are middleware components for logging, gzipping, header modification, (basic or <a href=\"https://jwt.io\" target=\"_blank\" rel=\"noopener\">JWT</a>-based) authentication and load balancing. But also more fancy things like automatically serving Markdown as HTML, a plug-and-play file browser GUI, HTML minification, IP filtering or pattern-based text replacement in HTML files are available as middlewares. Caddy also aligns well with PHP, using <em>php-fpm</em>, just as nginx does. As usual with Go applications, the entire program is shipped as a single binary (available for Windows, Mac, Linux and BSD), which includes all of its dependencies. Consequently you donâ€™t need to install any further libraries to be linked (-&gt; no version conflicts), what really makes the installation a no-brainer. However, this introduces one little drawback in comparison to nginx modules: every middleware you want to use needs to be included into the binary and if itâ€™s not, you need to re-compile the program (which is done for you by the download script at Caddy website, actually). </p>\n<p>I migrated all of my websites and -apps from nginx to Caddy (which took me hardly more than an hour) and so far Iâ€™m happy with the setup. But what about performance?</p>\n<p>To measure a very basic performance benchmark, I took <a href=\"https://github.com/n1try/http-server-benchmarks/blob/master/run-load.sh\" target=\"_blank\" rel=\"noopener\">this script</a>, which I used in <a href=\"https://ferdinand-muetsch.de/http-performance-java-jersey-vs-go-vs-nodejs.html\">an earlier benchmark scenario</a>. This script uses the <a href=\"https://github.com/nghttp2/nghttp2#benchmarking-tool\" target=\"_blank\" rel=\"noopener\">h2load</a> load test tool and I adjusted the parameters in a way that it performs a total of <strong>100,000 requests</strong> against a specific route at my webserver with a number of <strong>32 concurrent clients</strong> (each performing 3,125 requests) on <strong>4 CPU threads</strong>. I ran both servers with almost their default configuration, except that I turned on HTTP/2.0 with a self-signed certificate. The file served was a static HTML file containing 6.2 kBytes of data. Both h2load and the respective web server were executed locally on the same machine with the following specs.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">===CPU:</span><br><span class=\"line\">model name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</span><br><span class=\"line\">cpu cores : 2</span><br><span class=\"line\">model name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</span><br><span class=\"line\">cpu cores : 2</span><br><span class=\"line\">model name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</span><br><span class=\"line\">cpu cores : 2</span><br><span class=\"line\">model name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</span><br><span class=\"line\">cpu cores : 2</span><br><span class=\"line\"> </span><br><span class=\"line\">===RAM: </span><br><span class=\"line\">              total        used        free      shared  buff/cache   available</span><br><span class=\"line\">Mem:           7,7G        1,8G        4,2G        316M        1,6G        5,3G</span><br><span class=\"line\">Swap:           29G          0B         29G</span><br><span class=\"line\"> </span><br><span class=\"line\">===OS: </span><br><span class=\"line\">Linux ferdinand-ubuntu 4.8.0-32-generic #34-Ubuntu SMP Tue Dec 13 14:30:43 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux</span><br></pre></td></tr></table></figure>\n<p>The results look like this.<br><img src=\"images/webserver_performance.png\" alt=\"\"></p>\n<p><em>Caddy vs. nginx performance comparison</em></p>\n<p>As you can clearly see, nginx still performs way better, at least in this very simple scenario. However, Caddy is much more easy to use, in my opinion. Seems like we are having a classical trade-off here. Anyway, you should really give Caddy a try (and Iâ€™m not getting paid for this ðŸ˜‰). Concerning memory usage: I didnâ€™t observe that in detail, but suprisingly I found that neither the Caddy process nor the sum of nginx worker processes exceeded 10 MB of RAM usage (may I have done something wrong?).</p>\n<p>Please note that I only measured one specific figure (concurrent req/s) in one specific scenario. One can think of other benchmark setups where results might be the complete opposite, potentially.</p>\n<p>By the way, Apache2 was not included to this benchmark, because I wanted to use HTTP/2.0. Actually in the meantime there is a <code>mod_http2</code> for Apache2, but itâ€™s not included in the majority of the builds, yet, and to be honest, I didnâ€™t want to make an own one. If youâ€™re interested in that, you can get a rough idea of Apache2 vs. nginx performance in <a href=\"https://help.dreamhost.com/hc/en-us/articles/215945987-Web-server-performance-comparison\" target=\"_blank\" rel=\"noopener\">this article</a> (spoiler: itâ€™s pretty poor).</p>\n<p>So to conclude the discussion: Should you use Caddy in preference to nginx or Apache2? For private projects definitely yes, if you asked me. For more <em>serious</em> projects you should probably wait until itâ€™s even a little more mature (e.g. when a 1.x.x version is out) and maybe also incorporating dynamic module loading. Until then Iâ€™d stick with nginx. Besides that I canâ€™t figure out a reason for preferring Apache2 over nginx, except for being too lazy to do the migration.</p>\n<p>Please let me know if you liked my article and also if you donâ€™t agree with some of my arguments and insights.</p>\n"},{"title":"CartPole with a Deep Q-Network","date":"2017-09-11T16:47:39.000Z","_content":"In my [last post](https://ferdinand-muetsch.de/cartpole-with-qlearning-first-experiences-with-openai-gym.html) I developed a solution to [OpenAI Gym's CartPole environment](https://gym.openai.com/envs/CartPole-v0), based on a classical Q-Learning algorithm. **The best score I achieved with it was 120**, although the score I uploaded to the [leaderboard](https://gym.openai.com/evaluations/eval_emRbuGdHRnWoJuMUnPwd1Q) was 188. While this is certainly not a bad result, I wondered if I could do better using more advanced techniques. Besides that I also wanted to practice the concepts I had recently learned in the [Machine Learning 2](http://www.aifb.kit.edu/web/Lehre/Vorlesung_Maschinelles_Lernen_2_%E2%80%93_Fortgeschrittene_Verfahren/en) course at university. By the way, to all the students among you: I found that one of the best way to learn about new algorithms etc. is to actually **try to implement them in code**!\n\n## Motivation\nOne major limitation of my classical Q-Learning approach was that the number of possible states had to be reduced from basically infinity (due to the observations' continuous nature) to, in my case, `1 * 1 * 6 * 12 = 72` discrete states. Considering this extreme simpification, the results were astonishingly good! However, what if we could utilize more of the information, the observations give us? One solution is to combine Q-Learning with a (deep) neural network, which results in a technique called Deep Q-Learning (DQN). Neural networks are inherently efficient when handling very high dimensional problems. That's why they are doing so well with image-, video- and audio data. Additionally, they can easily handle continuous inputs, whereas with our classical approach we needed the Q-table to be a finite (in this case (4+1)-dimensional) matrix (or tensor). Accordingly, with DQN we don't need discrete buckets anymore, but are able to directly use the raw observations.\n\n## Deep Q-Learning\nBut how does this even work? While I don't want to explain DQN in detail here, the basic idea is to replace the Q-table by a neural network, which is trained to predict Q-values for a state. The input is a state-vector (or a batch of such) - consisting of four features in this case (which corresponds to four input neurons). The output is a vector of Q-values, one for each possible action - two in our case (corresponding to two output neurons). The training is done using **experience replay**. Basically, the agent begins to try some random actions and stores its \"experiences\" into a memory. An experience is a tuple like `(old_state, performed_action, received_reward, new_state)`. At fixed intervals (e.g. after each training episode, but NOT after each step), batches are sampled from memory and used as training data for the network. Consequently, the network (hopefully) improves every episode and predicts more precise Q-values for state-action pairs. \n\n## My implementation\nMy implementation is essentially based on [this great blog post](https://keon.io/deep-q-learning/) by [Keon](https://github.com/keon). It uses [Keras](http://keras.io) as a high-level abstraction on top of [TensorFlow](http://tensorflow.com). However, while I adopted the general structure, I made several tweaks and fixes to massively improve performance. \n\n### Tweak #1: More hidden neurons\nI slightly modified the network layout by **doubling the number of hidden neurons** in the second hidden layer. While randomly experimenting with some layouts I found that this one seemed to work better on average. Generally, determining a neural network's layout is basically trial and error for the most parts. Mainly you want to master the [bias-variance tradeoff](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff), but there is no rule on how to choose network structure in order to do so. Mine looks like this now:\n\n![](images/dqn4.png)\n\n### Tweak #2: Larger replay memory\nIn [Keon](https://github.com/keon)'s original implementation, the replay memory had a maxmimum size of 2,000. Assuming an average \"survival\" time of 100 steps, it would only hold experiences from 20 episodes, which is not much. I didn't see any reason why they shouldn't be a greater variety in training examples, so I increased the **memory size to 100,000**.\n\n### Tweak #3: Mini-batch training\nWhile originally the network trained from batches of 32 examples in each episode, the way the training was conducted was not efficient in my opinion. Instead of giving TensorFlow a **32 x 4 matrix**, it was given a **1 x 4 matrix 32 times**, so the actual training procedure effectively used a mini-batch size of 1. Without having technical knowledge on how TensorFlow works, I'm still pretty sure that training the network with one large batch instead of 32 small ones is faster - especially when using a GPU. \n\n### Tweak #4: Setting Î³ = 1\nAs already mentioned in my last post, I'm of the opinion that it wouldn't make sense to set the gamma parameter to less than one. Its purpose is to \"penalize\" the agent if it takes long to reach its goal. However, in CartPole **its even our goal** to do as many steps as possible. \n\n### Tweak #5: Logarithmic Îµ-decay\nSince the adaptive exploration rate from [@tuzzer's solution](https://medium.com/@tuzzer/cart-pole-balancing-with-q-learning-b54c6068d947) was very effective in my last implementation, I simply adopted it for this one, too. I didn't cross-validate whether it's better or worse than [Keon](https://github.com/keon)'s epsilon decay, but at least it doesn't seem to do bad.\n\n![](images/dqn3.png)\n\n### Tweak #6: tanh activation function\nI'm really not sure about this point, so please correct me if I'm wrong. The original implementation used the ReLU activation function, which is a linear function that maps the input to itself, but thesholded at zero.\n\n![](images/dqn2.png)\n\nHowever, since the input features can be negative, ReLU might cause dead neurons, doesn't it? To overcome that problem, I decided to _tanh_ as an activation function.\n\n### Tweak #7: Cross-validate hyperparameters\nEventually, I conducted a grid search (using my [script](https://gist.github.com/n1try/87b442fce7f7d58606f462191c6d6033) from the last time) to find good values for `alpha` (learning rate), `alpha_decay` and `epsilon_min` (minimum exploration rate). It turned out that `alpha=0.01`, `alpha_decay=0.01` and `epsilon_min=0.01` seem to work best among all tested values on average.\n\n## Results\nAfter all these optimizations, I ran the algorithm several times and the best score I achieved was actually **24**. However, I didn't record that run, so my best score in the [leaderboard](https://gym.openai.com/evaluations/eval_EIcM1ZBnQW2LBaFN6FY65g) in **85**, which is better then with my classical Q-Learning approach.\nHowever, I found that although the DQN approach _can_ converge faster, it also seems to be way more unstable at the same time. Performing two consecutive runs of the exact same algorithm and configuration often resulted in one score to be extremely good, while the second one didn't even solve the environment at all (> 999 episodes). In other words, DQN has a way larger variance, than the table-based approach, as depicted in the chart below, where I performed 25 runs of each algorithm. Additionally, as expected, the neural network is slower. Running DQN 25 times took **744 seconds**, while running table-based Q-Learning 25 times only took **24 seconds** on my machine's CPU using four threads on four cores. \n\n[>> Code on GitHub (dqn_cartpole.py)](https://gist.github.com/n1try/2a6722407117e4d668921fce53845432)\n\n![](images/dqn1.png)\n\n**Q**: `Min 120, Max 999, Mean 197.16, Std: 183.223`\n**DQN**: `Min 56, Max 999, Mean 600.04, Std: 356.046`","source":"_posts/cartpole-with-a-deep-q-network.md","raw":"---\ntitle: CartPole with a Deep Q-Network\ndate: 2017-09-11 18:47:39\ntags:\n---\nIn my [last post](https://ferdinand-muetsch.de/cartpole-with-qlearning-first-experiences-with-openai-gym.html) I developed a solution to [OpenAI Gym's CartPole environment](https://gym.openai.com/envs/CartPole-v0), based on a classical Q-Learning algorithm. **The best score I achieved with it was 120**, although the score I uploaded to the [leaderboard](https://gym.openai.com/evaluations/eval_emRbuGdHRnWoJuMUnPwd1Q) was 188. While this is certainly not a bad result, I wondered if I could do better using more advanced techniques. Besides that I also wanted to practice the concepts I had recently learned in the [Machine Learning 2](http://www.aifb.kit.edu/web/Lehre/Vorlesung_Maschinelles_Lernen_2_%E2%80%93_Fortgeschrittene_Verfahren/en) course at university. By the way, to all the students among you: I found that one of the best way to learn about new algorithms etc. is to actually **try to implement them in code**!\n\n## Motivation\nOne major limitation of my classical Q-Learning approach was that the number of possible states had to be reduced from basically infinity (due to the observations' continuous nature) to, in my case, `1 * 1 * 6 * 12 = 72` discrete states. Considering this extreme simpification, the results were astonishingly good! However, what if we could utilize more of the information, the observations give us? One solution is to combine Q-Learning with a (deep) neural network, which results in a technique called Deep Q-Learning (DQN). Neural networks are inherently efficient when handling very high dimensional problems. That's why they are doing so well with image-, video- and audio data. Additionally, they can easily handle continuous inputs, whereas with our classical approach we needed the Q-table to be a finite (in this case (4+1)-dimensional) matrix (or tensor). Accordingly, with DQN we don't need discrete buckets anymore, but are able to directly use the raw observations.\n\n## Deep Q-Learning\nBut how does this even work? While I don't want to explain DQN in detail here, the basic idea is to replace the Q-table by a neural network, which is trained to predict Q-values for a state. The input is a state-vector (or a batch of such) - consisting of four features in this case (which corresponds to four input neurons). The output is a vector of Q-values, one for each possible action - two in our case (corresponding to two output neurons). The training is done using **experience replay**. Basically, the agent begins to try some random actions and stores its \"experiences\" into a memory. An experience is a tuple like `(old_state, performed_action, received_reward, new_state)`. At fixed intervals (e.g. after each training episode, but NOT after each step), batches are sampled from memory and used as training data for the network. Consequently, the network (hopefully) improves every episode and predicts more precise Q-values for state-action pairs. \n\n## My implementation\nMy implementation is essentially based on [this great blog post](https://keon.io/deep-q-learning/) by [Keon](https://github.com/keon). It uses [Keras](http://keras.io) as a high-level abstraction on top of [TensorFlow](http://tensorflow.com). However, while I adopted the general structure, I made several tweaks and fixes to massively improve performance. \n\n### Tweak #1: More hidden neurons\nI slightly modified the network layout by **doubling the number of hidden neurons** in the second hidden layer. While randomly experimenting with some layouts I found that this one seemed to work better on average. Generally, determining a neural network's layout is basically trial and error for the most parts. Mainly you want to master the [bias-variance tradeoff](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff), but there is no rule on how to choose network structure in order to do so. Mine looks like this now:\n\n![](images/dqn4.png)\n\n### Tweak #2: Larger replay memory\nIn [Keon](https://github.com/keon)'s original implementation, the replay memory had a maxmimum size of 2,000. Assuming an average \"survival\" time of 100 steps, it would only hold experiences from 20 episodes, which is not much. I didn't see any reason why they shouldn't be a greater variety in training examples, so I increased the **memory size to 100,000**.\n\n### Tweak #3: Mini-batch training\nWhile originally the network trained from batches of 32 examples in each episode, the way the training was conducted was not efficient in my opinion. Instead of giving TensorFlow a **32 x 4 matrix**, it was given a **1 x 4 matrix 32 times**, so the actual training procedure effectively used a mini-batch size of 1. Without having technical knowledge on how TensorFlow works, I'm still pretty sure that training the network with one large batch instead of 32 small ones is faster - especially when using a GPU. \n\n### Tweak #4: Setting Î³ = 1\nAs already mentioned in my last post, I'm of the opinion that it wouldn't make sense to set the gamma parameter to less than one. Its purpose is to \"penalize\" the agent if it takes long to reach its goal. However, in CartPole **its even our goal** to do as many steps as possible. \n\n### Tweak #5: Logarithmic Îµ-decay\nSince the adaptive exploration rate from [@tuzzer's solution](https://medium.com/@tuzzer/cart-pole-balancing-with-q-learning-b54c6068d947) was very effective in my last implementation, I simply adopted it for this one, too. I didn't cross-validate whether it's better or worse than [Keon](https://github.com/keon)'s epsilon decay, but at least it doesn't seem to do bad.\n\n![](images/dqn3.png)\n\n### Tweak #6: tanh activation function\nI'm really not sure about this point, so please correct me if I'm wrong. The original implementation used the ReLU activation function, which is a linear function that maps the input to itself, but thesholded at zero.\n\n![](images/dqn2.png)\n\nHowever, since the input features can be negative, ReLU might cause dead neurons, doesn't it? To overcome that problem, I decided to _tanh_ as an activation function.\n\n### Tweak #7: Cross-validate hyperparameters\nEventually, I conducted a grid search (using my [script](https://gist.github.com/n1try/87b442fce7f7d58606f462191c6d6033) from the last time) to find good values for `alpha` (learning rate), `alpha_decay` and `epsilon_min` (minimum exploration rate). It turned out that `alpha=0.01`, `alpha_decay=0.01` and `epsilon_min=0.01` seem to work best among all tested values on average.\n\n## Results\nAfter all these optimizations, I ran the algorithm several times and the best score I achieved was actually **24**. However, I didn't record that run, so my best score in the [leaderboard](https://gym.openai.com/evaluations/eval_EIcM1ZBnQW2LBaFN6FY65g) in **85**, which is better then with my classical Q-Learning approach.\nHowever, I found that although the DQN approach _can_ converge faster, it also seems to be way more unstable at the same time. Performing two consecutive runs of the exact same algorithm and configuration often resulted in one score to be extremely good, while the second one didn't even solve the environment at all (> 999 episodes). In other words, DQN has a way larger variance, than the table-based approach, as depicted in the chart below, where I performed 25 runs of each algorithm. Additionally, as expected, the neural network is slower. Running DQN 25 times took **744 seconds**, while running table-based Q-Learning 25 times only took **24 seconds** on my machine's CPU using four threads on four cores. \n\n[>> Code on GitHub (dqn_cartpole.py)](https://gist.github.com/n1try/2a6722407117e4d668921fce53845432)\n\n![](images/dqn1.png)\n\n**Q**: `Min 120, Max 999, Mean 197.16, Std: 183.223`\n**DQN**: `Min 56, Max 999, Mean 600.04, Std: 356.046`","slug":"cartpole-with-a-deep-q-network","published":1,"updated":"2018-03-19T09:30:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2giolr0005cxrgps6ew7hc","content":"<p>In my <a href=\"https://ferdinand-muetsch.de/cartpole-with-qlearning-first-experiences-with-openai-gym.html\">last post</a> I developed a solution to <a href=\"https://gym.openai.com/envs/CartPole-v0\" target=\"_blank\" rel=\"noopener\">OpenAI Gymâ€™s CartPole environment</a>, based on a classical Q-Learning algorithm. <strong>The best score I achieved with it was 120</strong>, although the score I uploaded to the <a href=\"https://gym.openai.com/evaluations/eval_emRbuGdHRnWoJuMUnPwd1Q\" target=\"_blank\" rel=\"noopener\">leaderboard</a> was 188. While this is certainly not a bad result, I wondered if I could do better using more advanced techniques. Besides that I also wanted to practice the concepts I had recently learned in the <a href=\"http://www.aifb.kit.edu/web/Lehre/Vorlesung_Maschinelles_Lernen_2_%E2%80%93_Fortgeschrittene_Verfahren/en\" target=\"_blank\" rel=\"noopener\">Machine Learning 2</a> course at university. By the way, to all the students among you: I found that one of the best way to learn about new algorithms etc. is to actually <strong>try to implement them in code</strong>!</p>\n<h2 id=\"Motivation\"><a href=\"#Motivation\" class=\"headerlink\" title=\"Motivation\"></a>Motivation</h2><p>One major limitation of my classical Q-Learning approach was that the number of possible states had to be reduced from basically infinity (due to the observationsâ€™ continuous nature) to, in my case, <code>1 * 1 * 6 * 12 = 72</code> discrete states. Considering this extreme simpification, the results were astonishingly good! However, what if we could utilize more of the information, the observations give us? One solution is to combine Q-Learning with a (deep) neural network, which results in a technique called Deep Q-Learning (DQN). Neural networks are inherently efficient when handling very high dimensional problems. Thatâ€™s why they are doing so well with image-, video- and audio data. Additionally, they can easily handle continuous inputs, whereas with our classical approach we needed the Q-table to be a finite (in this case (4+1)-dimensional) matrix (or tensor). Accordingly, with DQN we donâ€™t need discrete buckets anymore, but are able to directly use the raw observations.</p>\n<h2 id=\"Deep-Q-Learning\"><a href=\"#Deep-Q-Learning\" class=\"headerlink\" title=\"Deep Q-Learning\"></a>Deep Q-Learning</h2><p>But how does this even work? While I donâ€™t want to explain DQN in detail here, the basic idea is to replace the Q-table by a neural network, which is trained to predict Q-values for a state. The input is a state-vector (or a batch of such) - consisting of four features in this case (which corresponds to four input neurons). The output is a vector of Q-values, one for each possible action - two in our case (corresponding to two output neurons). The training is done using <strong>experience replay</strong>. Basically, the agent begins to try some random actions and stores its â€œexperiencesâ€ into a memory. An experience is a tuple like <code>(old_state, performed_action, received_reward, new_state)</code>. At fixed intervals (e.g. after each training episode, but NOT after each step), batches are sampled from memory and used as training data for the network. Consequently, the network (hopefully) improves every episode and predicts more precise Q-values for state-action pairs. </p>\n<h2 id=\"My-implementation\"><a href=\"#My-implementation\" class=\"headerlink\" title=\"My implementation\"></a>My implementation</h2><p>My implementation is essentially based on <a href=\"https://keon.io/deep-q-learning/\" target=\"_blank\" rel=\"noopener\">this great blog post</a> by <a href=\"https://github.com/keon\" target=\"_blank\" rel=\"noopener\">Keon</a>. It uses <a href=\"http://keras.io\" target=\"_blank\" rel=\"noopener\">Keras</a> as a high-level abstraction on top of <a href=\"http://tensorflow.com\" target=\"_blank\" rel=\"noopener\">TensorFlow</a>. However, while I adopted the general structure, I made several tweaks and fixes to massively improve performance. </p>\n<h3 id=\"Tweak-1-More-hidden-neurons\"><a href=\"#Tweak-1-More-hidden-neurons\" class=\"headerlink\" title=\"Tweak #1: More hidden neurons\"></a>Tweak #1: More hidden neurons</h3><p>I slightly modified the network layout by <strong>doubling the number of hidden neurons</strong> in the second hidden layer. While randomly experimenting with some layouts I found that this one seemed to work better on average. Generally, determining a neural networkâ€™s layout is basically trial and error for the most parts. Mainly you want to master the <a href=\"https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff\" target=\"_blank\" rel=\"noopener\">bias-variance tradeoff</a>, but there is no rule on how to choose network structure in order to do so. Mine looks like this now:</p>\n<p><img src=\"images/dqn4.png\" alt=\"\"></p>\n<h3 id=\"Tweak-2-Larger-replay-memory\"><a href=\"#Tweak-2-Larger-replay-memory\" class=\"headerlink\" title=\"Tweak #2: Larger replay memory\"></a>Tweak #2: Larger replay memory</h3><p>In <a href=\"https://github.com/keon\" target=\"_blank\" rel=\"noopener\">Keon</a>â€˜s original implementation, the replay memory had a maxmimum size of 2,000. Assuming an average â€œsurvivalâ€ time of 100 steps, it would only hold experiences from 20 episodes, which is not much. I didnâ€™t see any reason why they shouldnâ€™t be a greater variety in training examples, so I increased the <strong>memory size to 100,000</strong>.</p>\n<h3 id=\"Tweak-3-Mini-batch-training\"><a href=\"#Tweak-3-Mini-batch-training\" class=\"headerlink\" title=\"Tweak #3: Mini-batch training\"></a>Tweak #3: Mini-batch training</h3><p>While originally the network trained from batches of 32 examples in each episode, the way the training was conducted was not efficient in my opinion. Instead of giving TensorFlow a <strong>32 x 4 matrix</strong>, it was given a <strong>1 x 4 matrix 32 times</strong>, so the actual training procedure effectively used a mini-batch size of 1. Without having technical knowledge on how TensorFlow works, Iâ€™m still pretty sure that training the network with one large batch instead of 32 small ones is faster - especially when using a GPU. </p>\n<h3 id=\"Tweak-4-Setting-Î³-1\"><a href=\"#Tweak-4-Setting-Î³-1\" class=\"headerlink\" title=\"Tweak #4: Setting Î³ = 1\"></a>Tweak #4: Setting Î³ = 1</h3><p>As already mentioned in my last post, Iâ€™m of the opinion that it wouldnâ€™t make sense to set the gamma parameter to less than one. Its purpose is to â€œpenalizeâ€ the agent if it takes long to reach its goal. However, in CartPole <strong>its even our goal</strong> to do as many steps as possible. </p>\n<h3 id=\"Tweak-5-Logarithmic-Îµ-decay\"><a href=\"#Tweak-5-Logarithmic-Îµ-decay\" class=\"headerlink\" title=\"Tweak #5: Logarithmic Îµ-decay\"></a>Tweak #5: Logarithmic Îµ-decay</h3><p>Since the adaptive exploration rate from <a href=\"https://medium.com/@tuzzer/cart-pole-balancing-with-q-learning-b54c6068d947\" target=\"_blank\" rel=\"noopener\">@tuzzerâ€™s solution</a> was very effective in my last implementation, I simply adopted it for this one, too. I didnâ€™t cross-validate whether itâ€™s better or worse than <a href=\"https://github.com/keon\" target=\"_blank\" rel=\"noopener\">Keon</a>â€˜s epsilon decay, but at least it doesnâ€™t seem to do bad.</p>\n<p><img src=\"images/dqn3.png\" alt=\"\"></p>\n<h3 id=\"Tweak-6-tanh-activation-function\"><a href=\"#Tweak-6-tanh-activation-function\" class=\"headerlink\" title=\"Tweak #6: tanh activation function\"></a>Tweak #6: tanh activation function</h3><p>Iâ€™m really not sure about this point, so please correct me if Iâ€™m wrong. The original implementation used the ReLU activation function, which is a linear function that maps the input to itself, but thesholded at zero.</p>\n<p><img src=\"images/dqn2.png\" alt=\"\"></p>\n<p>However, since the input features can be negative, ReLU might cause dead neurons, doesnâ€™t it? To overcome that problem, I decided to <em>tanh</em> as an activation function.</p>\n<h3 id=\"Tweak-7-Cross-validate-hyperparameters\"><a href=\"#Tweak-7-Cross-validate-hyperparameters\" class=\"headerlink\" title=\"Tweak #7: Cross-validate hyperparameters\"></a>Tweak #7: Cross-validate hyperparameters</h3><p>Eventually, I conducted a grid search (using my <a href=\"https://gist.github.com/n1try/87b442fce7f7d58606f462191c6d6033\" target=\"_blank\" rel=\"noopener\">script</a> from the last time) to find good values for <code>alpha</code> (learning rate), <code>alpha_decay</code> and <code>epsilon_min</code> (minimum exploration rate). It turned out that <code>alpha=0.01</code>, <code>alpha_decay=0.01</code> and <code>epsilon_min=0.01</code> seem to work best among all tested values on average.</p>\n<h2 id=\"Results\"><a href=\"#Results\" class=\"headerlink\" title=\"Results\"></a>Results</h2><p>After all these optimizations, I ran the algorithm several times and the best score I achieved was actually <strong>24</strong>. However, I didnâ€™t record that run, so my best score in the <a href=\"https://gym.openai.com/evaluations/eval_EIcM1ZBnQW2LBaFN6FY65g\" target=\"_blank\" rel=\"noopener\">leaderboard</a> in <strong>85</strong>, which is better then with my classical Q-Learning approach.<br>However, I found that although the DQN approach <em>can</em> converge faster, it also seems to be way more unstable at the same time. Performing two consecutive runs of the exact same algorithm and configuration often resulted in one score to be extremely good, while the second one didnâ€™t even solve the environment at all (&gt; 999 episodes). In other words, DQN has a way larger variance, than the table-based approach, as depicted in the chart below, where I performed 25 runs of each algorithm. Additionally, as expected, the neural network is slower. Running DQN 25 times took <strong>744 seconds</strong>, while running table-based Q-Learning 25 times only took <strong>24 seconds</strong> on my machineâ€™s CPU using four threads on four cores. </p>\n<p><a href=\"https://gist.github.com/n1try/2a6722407117e4d668921fce53845432\" target=\"_blank\" rel=\"noopener\">&gt;&gt; Code on GitHub (dqn_cartpole.py)</a></p>\n<p><img src=\"images/dqn1.png\" alt=\"\"></p>\n<p><strong>Q</strong>: <code>Min 120, Max 999, Mean 197.16, Std: 183.223</code><br><strong>DQN</strong>: <code>Min 56, Max 999, Mean 600.04, Std: 356.046</code></p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<p>In my <a href=\"https://ferdinand-muetsch.de/cartpole-with-qlearning-first-experiences-with-openai-gym.html\">last post</a> I developed a solution to <a href=\"https://gym.openai.com/envs/CartPole-v0\" target=\"_blank\" rel=\"noopener\">OpenAI Gymâ€™s CartPole environment</a>, based on a classical Q-Learning algorithm. <strong>The best score I achieved with it was 120</strong>, although the score I uploaded to the <a href=\"https://gym.openai.com/evaluations/eval_emRbuGdHRnWoJuMUnPwd1Q\" target=\"_blank\" rel=\"noopener\">leaderboard</a> was 188. While this is certainly not a bad result, I wondered if I could do better using more advanced techniques. Besides that I also wanted to practice the concepts I had recently learned in the <a href=\"http://www.aifb.kit.edu/web/Lehre/Vorlesung_Maschinelles_Lernen_2_%E2%80%93_Fortgeschrittene_Verfahren/en\" target=\"_blank\" rel=\"noopener\">Machine Learning 2</a> course at university. By the way, to all the students among you: I found that one of the best way to learn about new algorithms etc. is to actually <strong>try to implement them in code</strong>!</p>\n<h2 id=\"Motivation\"><a href=\"#Motivation\" class=\"headerlink\" title=\"Motivation\"></a>Motivation</h2><p>One major limitation of my classical Q-Learning approach was that the number of possible states had to be reduced from basically infinity (due to the observationsâ€™ continuous nature) to, in my case, <code>1 * 1 * 6 * 12 = 72</code> discrete states. Considering this extreme simpification, the results were astonishingly good! However, what if we could utilize more of the information, the observations give us? One solution is to combine Q-Learning with a (deep) neural network, which results in a technique called Deep Q-Learning (DQN). Neural networks are inherently efficient when handling very high dimensional problems. Thatâ€™s why they are doing so well with image-, video- and audio data. Additionally, they can easily handle continuous inputs, whereas with our classical approach we needed the Q-table to be a finite (in this case (4+1)-dimensional) matrix (or tensor). Accordingly, with DQN we donâ€™t need discrete buckets anymore, but are able to directly use the raw observations.</p>\n<h2 id=\"Deep-Q-Learning\"><a href=\"#Deep-Q-Learning\" class=\"headerlink\" title=\"Deep Q-Learning\"></a>Deep Q-Learning</h2><p>But how does this even work? While I donâ€™t want to explain DQN in detail here, the basic idea is to replace the Q-table by a neural network, which is trained to predict Q-values for a state. The input is a state-vector (or a batch of such) - consisting of four features in this case (which corresponds to four input neurons). The output is a vector of Q-values, one for each possible action - two in our case (corresponding to two output neurons). The training is done using <strong>experience replay</strong>. Basically, the agent begins to try some random actions and stores its â€œexperiencesâ€ into a memory. An experience is a tuple like <code>(old_state, performed_action, received_reward, new_state)</code>. At fixed intervals (e.g. after each training episode, but NOT after each step), batches are sampled from memory and used as training data for the network. Consequently, the network (hopefully) improves every episode and predicts more precise Q-values for state-action pairs. </p>\n<h2 id=\"My-implementation\"><a href=\"#My-implementation\" class=\"headerlink\" title=\"My implementation\"></a>My implementation</h2><p>My implementation is essentially based on <a href=\"https://keon.io/deep-q-learning/\" target=\"_blank\" rel=\"noopener\">this great blog post</a> by <a href=\"https://github.com/keon\" target=\"_blank\" rel=\"noopener\">Keon</a>. It uses <a href=\"http://keras.io\" target=\"_blank\" rel=\"noopener\">Keras</a> as a high-level abstraction on top of <a href=\"http://tensorflow.com\" target=\"_blank\" rel=\"noopener\">TensorFlow</a>. However, while I adopted the general structure, I made several tweaks and fixes to massively improve performance. </p>\n<h3 id=\"Tweak-1-More-hidden-neurons\"><a href=\"#Tweak-1-More-hidden-neurons\" class=\"headerlink\" title=\"Tweak #1: More hidden neurons\"></a>Tweak #1: More hidden neurons</h3><p>I slightly modified the network layout by <strong>doubling the number of hidden neurons</strong> in the second hidden layer. While randomly experimenting with some layouts I found that this one seemed to work better on average. Generally, determining a neural networkâ€™s layout is basically trial and error for the most parts. Mainly you want to master the <a href=\"https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff\" target=\"_blank\" rel=\"noopener\">bias-variance tradeoff</a>, but there is no rule on how to choose network structure in order to do so. Mine looks like this now:</p>\n<p><img src=\"images/dqn4.png\" alt=\"\"></p>\n<h3 id=\"Tweak-2-Larger-replay-memory\"><a href=\"#Tweak-2-Larger-replay-memory\" class=\"headerlink\" title=\"Tweak #2: Larger replay memory\"></a>Tweak #2: Larger replay memory</h3><p>In <a href=\"https://github.com/keon\" target=\"_blank\" rel=\"noopener\">Keon</a>â€˜s original implementation, the replay memory had a maxmimum size of 2,000. Assuming an average â€œsurvivalâ€ time of 100 steps, it would only hold experiences from 20 episodes, which is not much. I didnâ€™t see any reason why they shouldnâ€™t be a greater variety in training examples, so I increased the <strong>memory size to 100,000</strong>.</p>\n<h3 id=\"Tweak-3-Mini-batch-training\"><a href=\"#Tweak-3-Mini-batch-training\" class=\"headerlink\" title=\"Tweak #3: Mini-batch training\"></a>Tweak #3: Mini-batch training</h3><p>While originally the network trained from batches of 32 examples in each episode, the way the training was conducted was not efficient in my opinion. Instead of giving TensorFlow a <strong>32 x 4 matrix</strong>, it was given a <strong>1 x 4 matrix 32 times</strong>, so the actual training procedure effectively used a mini-batch size of 1. Without having technical knowledge on how TensorFlow works, Iâ€™m still pretty sure that training the network with one large batch instead of 32 small ones is faster - especially when using a GPU. </p>\n<h3 id=\"Tweak-4-Setting-Î³-1\"><a href=\"#Tweak-4-Setting-Î³-1\" class=\"headerlink\" title=\"Tweak #4: Setting Î³ = 1\"></a>Tweak #4: Setting Î³ = 1</h3><p>As already mentioned in my last post, Iâ€™m of the opinion that it wouldnâ€™t make sense to set the gamma parameter to less than one. Its purpose is to â€œpenalizeâ€ the agent if it takes long to reach its goal. However, in CartPole <strong>its even our goal</strong> to do as many steps as possible. </p>\n<h3 id=\"Tweak-5-Logarithmic-Îµ-decay\"><a href=\"#Tweak-5-Logarithmic-Îµ-decay\" class=\"headerlink\" title=\"Tweak #5: Logarithmic Îµ-decay\"></a>Tweak #5: Logarithmic Îµ-decay</h3><p>Since the adaptive exploration rate from <a href=\"https://medium.com/@tuzzer/cart-pole-balancing-with-q-learning-b54c6068d947\" target=\"_blank\" rel=\"noopener\">@tuzzerâ€™s solution</a> was very effective in my last implementation, I simply adopted it for this one, too. I didnâ€™t cross-validate whether itâ€™s better or worse than <a href=\"https://github.com/keon\" target=\"_blank\" rel=\"noopener\">Keon</a>â€˜s epsilon decay, but at least it doesnâ€™t seem to do bad.</p>\n<p><img src=\"images/dqn3.png\" alt=\"\"></p>\n<h3 id=\"Tweak-6-tanh-activation-function\"><a href=\"#Tweak-6-tanh-activation-function\" class=\"headerlink\" title=\"Tweak #6: tanh activation function\"></a>Tweak #6: tanh activation function</h3><p>Iâ€™m really not sure about this point, so please correct me if Iâ€™m wrong. The original implementation used the ReLU activation function, which is a linear function that maps the input to itself, but thesholded at zero.</p>\n<p><img src=\"images/dqn2.png\" alt=\"\"></p>\n<p>However, since the input features can be negative, ReLU might cause dead neurons, doesnâ€™t it? To overcome that problem, I decided to <em>tanh</em> as an activation function.</p>\n<h3 id=\"Tweak-7-Cross-validate-hyperparameters\"><a href=\"#Tweak-7-Cross-validate-hyperparameters\" class=\"headerlink\" title=\"Tweak #7: Cross-validate hyperparameters\"></a>Tweak #7: Cross-validate hyperparameters</h3><p>Eventually, I conducted a grid search (using my <a href=\"https://gist.github.com/n1try/87b442fce7f7d58606f462191c6d6033\" target=\"_blank\" rel=\"noopener\">script</a> from the last time) to find good values for <code>alpha</code> (learning rate), <code>alpha_decay</code> and <code>epsilon_min</code> (minimum exploration rate). It turned out that <code>alpha=0.01</code>, <code>alpha_decay=0.01</code> and <code>epsilon_min=0.01</code> seem to work best among all tested values on average.</p>\n<h2 id=\"Results\"><a href=\"#Results\" class=\"headerlink\" title=\"Results\"></a>Results</h2><p>After all these optimizations, I ran the algorithm several times and the best score I achieved was actually <strong>24</strong>. However, I didnâ€™t record that run, so my best score in the <a href=\"https://gym.openai.com/evaluations/eval_EIcM1ZBnQW2LBaFN6FY65g\" target=\"_blank\" rel=\"noopener\">leaderboard</a> in <strong>85</strong>, which is better then with my classical Q-Learning approach.<br>However, I found that although the DQN approach <em>can</em> converge faster, it also seems to be way more unstable at the same time. Performing two consecutive runs of the exact same algorithm and configuration often resulted in one score to be extremely good, while the second one didnâ€™t even solve the environment at all (&gt; 999 episodes). In other words, DQN has a way larger variance, than the table-based approach, as depicted in the chart below, where I performed 25 runs of each algorithm. Additionally, as expected, the neural network is slower. Running DQN 25 times took <strong>744 seconds</strong>, while running table-based Q-Learning 25 times only took <strong>24 seconds</strong> on my machineâ€™s CPU using four threads on four cores. </p>\n<p><a href=\"https://gist.github.com/n1try/2a6722407117e4d668921fce53845432\" target=\"_blank\" rel=\"noopener\">&gt;&gt; Code on GitHub (dqn_cartpole.py)</a></p>\n<p><img src=\"images/dqn1.png\" alt=\"\"></p>\n<p><strong>Q</strong>: <code>Min 120, Max 999, Mean 197.16, Std: 183.223</code><br><strong>DQN</strong>: <code>Min 56, Max 999, Mean 600.04, Std: 356.046</code></p>\n"},{"title":"CartPole with Q-Learning - First experiences with OpenAI Gym","date":"2017-08-24T14:50:57.000Z","_content":"## OpenAI Gym\nToday I made my first experiences with the [OpenAI gym](https://gym.openai.com), more specifically with the [CartPole](https://gym.openai.com/envs/CartPole-v0) environment. Gym is basically a Python library that includes several machine learning challenges, in which an autonomous agent should be learned to fulfill different tasks, e.g. to master a simple game itself. One of the simplest and most popular challenges is CartPole. It's basically a 2D game in which the agent has to control, i.e. move left or right, a cart to balance a pole standing perpendicularly on the cart. This is a classical reinforcement learning problem, e.g. a scenario, in which the agents starts by trying random actions as a consequence to which it gets rewarded (or not). Based on the rewards, it continuously \"learns\", which action is good in which specific situation. Doing so, it learns how to master the game without ever being told how the game even works. The main advantage of this type of learning is, that it's completely generic and not bound to a specific problem. E.g. to learn a chess agent, you don't need to \"tell\" it the rules of chess, but just let it do trial & error, whereas \"error\" means giving it a negative (or small positive) reward.\n\n## CartPole-v0\nIn machine learning terms, CartPole is basically a binary classification problem. There are four features as inputs, which include the cart position, its velocity, the pole's angle to the cart and its derivative (i.e. how fast the pole is \"falling\"). The output is binary, i.e. either 0 or 1, corresponding to \"left\" or \"right\". One challenge is the fact that all four features are continuous values (floating point numbers), which, naively, implies an infinitely large feature space.\n\n![](images/cartpole1.jpg)\n\n## Approach: Basic Q-Learning\nIn the [Machine Learning 1](https://his.anthropomatik.kit.edu/english/28_315.php) course at my university, I got to know one of the most basic, yet widely-used reinforcement learning approaches, which is [Q-Learning](http://mnemstudio.org/path-finding-q-learning-tutorial.htm). The core of Q-Learning is to estimate a value for every possible pare of a state (s) and an action (a) by getting rewarded. Imagine the following graph, which consists of three states, while your agent is currently in _s0_. It can choose between two actions, one of which results in a good state _s1_ (e.g. having won the game), the other one results in a bad state _s2_ (e.g. having lost the game). Accordingly, the transition leading to the good (bad) state gives a reward of 100 (-100). If the agent performs action _a0_, the q-value of _s0_ will probably become negative (Q(s0, a0) < 0)), while Q(s0, a1) > 0.\n\n![](images/cartpole2.png)\n\nThe update of the q-value is done according to the following equation.\n\n![](images/cartpole3.png)\n\nBasically, a (S, A)-tuple's new q-value depends on its old q-value, the immediate reward received for the action and the maximum q-value achievable in the following state. So a (S, A)-pair's q-value indirectly depends on all its successors' q-values, which is expressed in the recursive function definition. By repeatedly walking through all nodes and transistions, the agent can update any (S, A)-pairs q-value, while the results of good and bad actions are slowly \"backpropagated\" from terminal nodes to early nodes. The agent ends up with a (usually multidimensional) table mapping states and actions to q-values, so that given any state, the best action can be picked by choosing the highest respective q-value.\n\n## My implementation\nSince Q-Learning is pretty straightforward to understand and implement, I decided on picking that algorithm as a starting point for my CartPole challenge. I looked for other solutions, that also use CartPole and found [this blog post](https://medium.com/@tuzzer/cart-pole-balancing-with-q-learning-b54c6068d947) by [@tuzzer](https://medium.com/@tuzzer), which had partially inspired me during my implementation. \n\n[>> Code on GitHub (qcartpole.py)](https://gist.github.com/n1try/af0b8476ae4106ec098fea1dfe57f578)\n\n### Transforming the feature space\nActually the main challenge was to convert the continuous, 4-dimensional input space to a discrete space with a finite and preferably small, yet expressive, number of discrete states. The less states we have, the smaller the Q-table will be, the less steps the agent will need to properly learn its values. However, too few states might not hold enough information to properly represent the environment. The original domains of the input features are these.\n\n* __x__ (cart position) âˆˆ [-4.8, 4.8]\n* __x'__ (cart velocity) âˆˆ [-3.4 * 10^38, 3.4 * 10^38]\n* __theta__ (angle) âˆˆ [-0.42, 0.42]\n* __theta'__ (angle velocity) âˆˆ [-3.4 * 10^38, 3.4 * 10^38]\n\n### Finding the parameters\nAs can be seen, especially the velocities' domains are extermely large. However, from [@tuzzer](https://medium.com/@tuzzer)'s post I found that astonishingly small target intervals are sufficient. Therefore, I initially started by scaling __theta__ down to a discrete interval `theta âˆˆ [0, 6] âŠ‚ â„• ` (which is, to be precise, just a set of integers {0..6}) and __theta'__ to `theta' âˆˆ [0, 12] âŠ‚ â„• `. Inspired by [@tuzzer](https://medium.com/@tuzzer/)'s post, I dropped the __x__ and __x'__ features completely, which corresponds to mapping any of their values to a single scalar. The motivation behind this is that the probability of the cart leaving the environment at the left or right border in only 200 time steps (after 200 steps, the environment automatically resets itself) is pretty slow and the resulting reduction in dimensionality more worthy. \n\nThe implementation of the actual Q-Learning algorithm is straightfoward and consits of a function to fetch the best action for a state from the q-table and another function to update the q-table based on the last action. Nothing special here.\n\nMore interesing are the algorithm's hyperparameters, which include __alpha (= learning rate)__, __epsilon (= exploration rate)__ and __gamma (= discount factor)__.\n\nAlpha is used to \"smooth\" the updates and make them less radical, which, in the first place, prevents from errors caused by noise. Epsilon regulates between __exploitation and exploration__. Accordingly, instead of picking the _best_ action in a state, with a chance of Îµ a _random_ action is picked. This should prevent the algorithm from getting stuck in local minima. E.g. if a bad choice was made in the beginning, without Îµ the agent would continue on evaluating that suboptimal path and would never discover any other, potentially better, path. Gamma is used to penalize the agent if it takes long to reach its goal. However, in this case, gamma is set to constant 1 (no discount), since it's even our goal to \"survive\" as long as possible. \n\nFirst I tried to choose the epsilon and alpha parameters as constants and experimented with various combinations. However, I always achieved only a very poor score (~ between 20 and 50 ticks). Then, again inspired by [@tuzzer](https://medium.com/@tuzzer/) I decided to introduce an adaptive learning- and exploration rate, which starts with a high value and decreases by time (with each training episode). Astonishingly, this made a huge difference. Suddenly, my algorithm converged in about ~ 200 steps. Since I never thought that these hyperparameters made such an extreme difference (from not solving the challenge at all to doing pretty well), this was probably the most interesting finding from my CartPole project. I simply adpoted [@tuzzer](https://medium.com/@tuzzer/)'s adaptive function, which is visualized in the figure below (the minimum of _0.1_ is a hyperparameter to be optimized).\n\n![](images/cartpole4.png)\n\n### Grid search\nAs my Q-Learning implementation with adaptive learning- and exploration rates was finished, I implemented an additional grid search to do some hyperparameter tuning. Goal was to find the optimal combination of feature interval lengths and lower bounds for alpha and epsilon. The following parameters turned out to perform best: `'buckets': (1, 1, 6, 12), 'min_alpha': 0.1, 'min_epsilon': 0.1`. Additionally, I also could have evaluated different functions for calculating the adaptive rate, but I haven't, yet. \n\n[>> Code on GitHub (qcartpole_gridsearch.py)](https://gist.github.com/n1try/87b442fce7f7d58606f462191c6d6033)\n\n## Result & Future Work\nMy final score was __188__, [as can be seen in the leaderboard](https://gym.openai.com/evaluations/eval_emRbuGdHRnWoJuMUnPwd1Q). As I progress with my knowledge on machine learning, while practicing for the upcoming [Machine Learning 2](http://www.aifb.kit.edu/web/Lehre/Vorlesung_Maschinelles_Lernen_2_%E2%80%93_Fortgeschrittene_Verfahren/en) exam, I want to continue improving my CartPole algorithm. Probably the next step will be to incorporate deep Q-Learning, which basically is Q-Learning with the only difference that the q-values are estimated by a deep neural net. The main (and probably only) advantage is the ability to handle way larger feature spaces. I'll keep you guys up-to-date. I hope that I could encourage you to get started with Gym, or machine learning in general, too!","source":"_posts/cartpole-with-qlearning-first-experiences-with-openai-gym.md","raw":"---\ntitle: CartPole with Q-Learning - First experiences with OpenAI Gym\ndate: 2017-08-24 16:50:57\ntags:\n---\n## OpenAI Gym\nToday I made my first experiences with the [OpenAI gym](https://gym.openai.com), more specifically with the [CartPole](https://gym.openai.com/envs/CartPole-v0) environment. Gym is basically a Python library that includes several machine learning challenges, in which an autonomous agent should be learned to fulfill different tasks, e.g. to master a simple game itself. One of the simplest and most popular challenges is CartPole. It's basically a 2D game in which the agent has to control, i.e. move left or right, a cart to balance a pole standing perpendicularly on the cart. This is a classical reinforcement learning problem, e.g. a scenario, in which the agents starts by trying random actions as a consequence to which it gets rewarded (or not). Based on the rewards, it continuously \"learns\", which action is good in which specific situation. Doing so, it learns how to master the game without ever being told how the game even works. The main advantage of this type of learning is, that it's completely generic and not bound to a specific problem. E.g. to learn a chess agent, you don't need to \"tell\" it the rules of chess, but just let it do trial & error, whereas \"error\" means giving it a negative (or small positive) reward.\n\n## CartPole-v0\nIn machine learning terms, CartPole is basically a binary classification problem. There are four features as inputs, which include the cart position, its velocity, the pole's angle to the cart and its derivative (i.e. how fast the pole is \"falling\"). The output is binary, i.e. either 0 or 1, corresponding to \"left\" or \"right\". One challenge is the fact that all four features are continuous values (floating point numbers), which, naively, implies an infinitely large feature space.\n\n![](images/cartpole1.jpg)\n\n## Approach: Basic Q-Learning\nIn the [Machine Learning 1](https://his.anthropomatik.kit.edu/english/28_315.php) course at my university, I got to know one of the most basic, yet widely-used reinforcement learning approaches, which is [Q-Learning](http://mnemstudio.org/path-finding-q-learning-tutorial.htm). The core of Q-Learning is to estimate a value for every possible pare of a state (s) and an action (a) by getting rewarded. Imagine the following graph, which consists of three states, while your agent is currently in _s0_. It can choose between two actions, one of which results in a good state _s1_ (e.g. having won the game), the other one results in a bad state _s2_ (e.g. having lost the game). Accordingly, the transition leading to the good (bad) state gives a reward of 100 (-100). If the agent performs action _a0_, the q-value of _s0_ will probably become negative (Q(s0, a0) < 0)), while Q(s0, a1) > 0.\n\n![](images/cartpole2.png)\n\nThe update of the q-value is done according to the following equation.\n\n![](images/cartpole3.png)\n\nBasically, a (S, A)-tuple's new q-value depends on its old q-value, the immediate reward received for the action and the maximum q-value achievable in the following state. So a (S, A)-pair's q-value indirectly depends on all its successors' q-values, which is expressed in the recursive function definition. By repeatedly walking through all nodes and transistions, the agent can update any (S, A)-pairs q-value, while the results of good and bad actions are slowly \"backpropagated\" from terminal nodes to early nodes. The agent ends up with a (usually multidimensional) table mapping states and actions to q-values, so that given any state, the best action can be picked by choosing the highest respective q-value.\n\n## My implementation\nSince Q-Learning is pretty straightforward to understand and implement, I decided on picking that algorithm as a starting point for my CartPole challenge. I looked for other solutions, that also use CartPole and found [this blog post](https://medium.com/@tuzzer/cart-pole-balancing-with-q-learning-b54c6068d947) by [@tuzzer](https://medium.com/@tuzzer), which had partially inspired me during my implementation. \n\n[>> Code on GitHub (qcartpole.py)](https://gist.github.com/n1try/af0b8476ae4106ec098fea1dfe57f578)\n\n### Transforming the feature space\nActually the main challenge was to convert the continuous, 4-dimensional input space to a discrete space with a finite and preferably small, yet expressive, number of discrete states. The less states we have, the smaller the Q-table will be, the less steps the agent will need to properly learn its values. However, too few states might not hold enough information to properly represent the environment. The original domains of the input features are these.\n\n* __x__ (cart position) âˆˆ [-4.8, 4.8]\n* __x'__ (cart velocity) âˆˆ [-3.4 * 10^38, 3.4 * 10^38]\n* __theta__ (angle) âˆˆ [-0.42, 0.42]\n* __theta'__ (angle velocity) âˆˆ [-3.4 * 10^38, 3.4 * 10^38]\n\n### Finding the parameters\nAs can be seen, especially the velocities' domains are extermely large. However, from [@tuzzer](https://medium.com/@tuzzer)'s post I found that astonishingly small target intervals are sufficient. Therefore, I initially started by scaling __theta__ down to a discrete interval `theta âˆˆ [0, 6] âŠ‚ â„• ` (which is, to be precise, just a set of integers {0..6}) and __theta'__ to `theta' âˆˆ [0, 12] âŠ‚ â„• `. Inspired by [@tuzzer](https://medium.com/@tuzzer/)'s post, I dropped the __x__ and __x'__ features completely, which corresponds to mapping any of their values to a single scalar. The motivation behind this is that the probability of the cart leaving the environment at the left or right border in only 200 time steps (after 200 steps, the environment automatically resets itself) is pretty slow and the resulting reduction in dimensionality more worthy. \n\nThe implementation of the actual Q-Learning algorithm is straightfoward and consits of a function to fetch the best action for a state from the q-table and another function to update the q-table based on the last action. Nothing special here.\n\nMore interesing are the algorithm's hyperparameters, which include __alpha (= learning rate)__, __epsilon (= exploration rate)__ and __gamma (= discount factor)__.\n\nAlpha is used to \"smooth\" the updates and make them less radical, which, in the first place, prevents from errors caused by noise. Epsilon regulates between __exploitation and exploration__. Accordingly, instead of picking the _best_ action in a state, with a chance of Îµ a _random_ action is picked. This should prevent the algorithm from getting stuck in local minima. E.g. if a bad choice was made in the beginning, without Îµ the agent would continue on evaluating that suboptimal path and would never discover any other, potentially better, path. Gamma is used to penalize the agent if it takes long to reach its goal. However, in this case, gamma is set to constant 1 (no discount), since it's even our goal to \"survive\" as long as possible. \n\nFirst I tried to choose the epsilon and alpha parameters as constants and experimented with various combinations. However, I always achieved only a very poor score (~ between 20 and 50 ticks). Then, again inspired by [@tuzzer](https://medium.com/@tuzzer/) I decided to introduce an adaptive learning- and exploration rate, which starts with a high value and decreases by time (with each training episode). Astonishingly, this made a huge difference. Suddenly, my algorithm converged in about ~ 200 steps. Since I never thought that these hyperparameters made such an extreme difference (from not solving the challenge at all to doing pretty well), this was probably the most interesting finding from my CartPole project. I simply adpoted [@tuzzer](https://medium.com/@tuzzer/)'s adaptive function, which is visualized in the figure below (the minimum of _0.1_ is a hyperparameter to be optimized).\n\n![](images/cartpole4.png)\n\n### Grid search\nAs my Q-Learning implementation with adaptive learning- and exploration rates was finished, I implemented an additional grid search to do some hyperparameter tuning. Goal was to find the optimal combination of feature interval lengths and lower bounds for alpha and epsilon. The following parameters turned out to perform best: `'buckets': (1, 1, 6, 12), 'min_alpha': 0.1, 'min_epsilon': 0.1`. Additionally, I also could have evaluated different functions for calculating the adaptive rate, but I haven't, yet. \n\n[>> Code on GitHub (qcartpole_gridsearch.py)](https://gist.github.com/n1try/87b442fce7f7d58606f462191c6d6033)\n\n## Result & Future Work\nMy final score was __188__, [as can be seen in the leaderboard](https://gym.openai.com/evaluations/eval_emRbuGdHRnWoJuMUnPwd1Q). As I progress with my knowledge on machine learning, while practicing for the upcoming [Machine Learning 2](http://www.aifb.kit.edu/web/Lehre/Vorlesung_Maschinelles_Lernen_2_%E2%80%93_Fortgeschrittene_Verfahren/en) exam, I want to continue improving my CartPole algorithm. Probably the next step will be to incorporate deep Q-Learning, which basically is Q-Learning with the only difference that the q-values are estimated by a deep neural net. The main (and probably only) advantage is the ability to handle way larger feature spaces. I'll keep you guys up-to-date. I hope that I could encourage you to get started with Gym, or machine learning in general, too!","slug":"cartpole-with-qlearning-first-experiences-with-openai-gym","published":1,"updated":"2018-03-19T09:30:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2giolt0006cxrg6gla5v2i","content":"<h2 id=\"OpenAI-Gym\"><a href=\"#OpenAI-Gym\" class=\"headerlink\" title=\"OpenAI Gym\"></a>OpenAI Gym</h2><p>Today I made my first experiences with the <a href=\"https://gym.openai.com\" target=\"_blank\" rel=\"noopener\">OpenAI gym</a>, more specifically with the <a href=\"https://gym.openai.com/envs/CartPole-v0\" target=\"_blank\" rel=\"noopener\">CartPole</a> environment. Gym is basically a Python library that includes several machine learning challenges, in which an autonomous agent should be learned to fulfill different tasks, e.g. to master a simple game itself. One of the simplest and most popular challenges is CartPole. Itâ€™s basically a 2D game in which the agent has to control, i.e. move left or right, a cart to balance a pole standing perpendicularly on the cart. This is a classical reinforcement learning problem, e.g. a scenario, in which the agents starts by trying random actions as a consequence to which it gets rewarded (or not). Based on the rewards, it continuously â€œlearnsâ€, which action is good in which specific situation. Doing so, it learns how to master the game without ever being told how the game even works. The main advantage of this type of learning is, that itâ€™s completely generic and not bound to a specific problem. E.g. to learn a chess agent, you donâ€™t need to â€œtellâ€ it the rules of chess, but just let it do trial &amp; error, whereas â€œerrorâ€ means giving it a negative (or small positive) reward.</p>\n<h2 id=\"CartPole-v0\"><a href=\"#CartPole-v0\" class=\"headerlink\" title=\"CartPole-v0\"></a>CartPole-v0</h2><p>In machine learning terms, CartPole is basically a binary classification problem. There are four features as inputs, which include the cart position, its velocity, the poleâ€™s angle to the cart and its derivative (i.e. how fast the pole is â€œfallingâ€). The output is binary, i.e. either 0 or 1, corresponding to â€œleftâ€ or â€œrightâ€. One challenge is the fact that all four features are continuous values (floating point numbers), which, naively, implies an infinitely large feature space.</p>\n<p><img src=\"images/cartpole1.jpg\" alt=\"\"></p>\n<h2 id=\"Approach-Basic-Q-Learning\"><a href=\"#Approach-Basic-Q-Learning\" class=\"headerlink\" title=\"Approach: Basic Q-Learning\"></a>Approach: Basic Q-Learning</h2><p>In the <a href=\"https://his.anthropomatik.kit.edu/english/28_315.php\" target=\"_blank\" rel=\"noopener\">Machine Learning 1</a> course at my university, I got to know one of the most basic, yet widely-used reinforcement learning approaches, which is <a href=\"http://mnemstudio.org/path-finding-q-learning-tutorial.htm\" target=\"_blank\" rel=\"noopener\">Q-Learning</a>. The core of Q-Learning is to estimate a value for every possible pare of a state (s) and an action (a) by getting rewarded. Imagine the following graph, which consists of three states, while your agent is currently in _s0_. It can choose between two actions, one of which results in a good state _s1_ (e.g. having won the game), the other one results in a bad state _s2_ (e.g. having lost the game). Accordingly, the transition leading to the good (bad) state gives a reward of 100 (-100). If the agent performs action _a0_, the q-value of _s0_ will probably become negative (Q(s0, a0) &lt; 0)), while Q(s0, a1) &gt; 0.</p>\n<p><img src=\"images/cartpole2.png\" alt=\"\"></p>\n<p>The update of the q-value is done according to the following equation.</p>\n<p><img src=\"images/cartpole3.png\" alt=\"\"></p>\n<p>Basically, a (S, A)-tupleâ€™s new q-value depends on its old q-value, the immediate reward received for the action and the maximum q-value achievable in the following state. So a (S, A)-pairâ€™s q-value indirectly depends on all its successorsâ€™ q-values, which is expressed in the recursive function definition. By repeatedly walking through all nodes and transistions, the agent can update any (S, A)-pairs q-value, while the results of good and bad actions are slowly â€œbackpropagatedâ€ from terminal nodes to early nodes. The agent ends up with a (usually multidimensional) table mapping states and actions to q-values, so that given any state, the best action can be picked by choosing the highest respective q-value.</p>\n<h2 id=\"My-implementation\"><a href=\"#My-implementation\" class=\"headerlink\" title=\"My implementation\"></a>My implementation</h2><p>Since Q-Learning is pretty straightforward to understand and implement, I decided on picking that algorithm as a starting point for my CartPole challenge. I looked for other solutions, that also use CartPole and found <a href=\"https://medium.com/@tuzzer/cart-pole-balancing-with-q-learning-b54c6068d947\" target=\"_blank\" rel=\"noopener\">this blog post</a> by <a href=\"https://medium.com/@tuzzer\" target=\"_blank\" rel=\"noopener\">@tuzzer</a>, which had partially inspired me during my implementation. </p>\n<p><a href=\"https://gist.github.com/n1try/af0b8476ae4106ec098fea1dfe57f578\" target=\"_blank\" rel=\"noopener\">&gt;&gt; Code on GitHub (qcartpole.py)</a></p>\n<h3 id=\"Transforming-the-feature-space\"><a href=\"#Transforming-the-feature-space\" class=\"headerlink\" title=\"Transforming the feature space\"></a>Transforming the feature space</h3><p>Actually the main challenge was to convert the continuous, 4-dimensional input space to a discrete space with a finite and preferably small, yet expressive, number of discrete states. The less states we have, the smaller the Q-table will be, the less steps the agent will need to properly learn its values. However, too few states might not hold enough information to properly represent the environment. The original domains of the input features are these.</p>\n<ul>\n<li><strong>x</strong> (cart position) âˆˆ [-4.8, 4.8]</li>\n<li><strong>xâ€™</strong> (cart velocity) âˆˆ [-3.4 <em> 10^38, 3.4 </em> 10^38]</li>\n<li><strong>theta</strong> (angle) âˆˆ [-0.42, 0.42]</li>\n<li><strong>thetaâ€™</strong> (angle velocity) âˆˆ [-3.4 <em> 10^38, 3.4 </em> 10^38]</li>\n</ul>\n<h3 id=\"Finding-the-parameters\"><a href=\"#Finding-the-parameters\" class=\"headerlink\" title=\"Finding the parameters\"></a>Finding the parameters</h3><p>As can be seen, especially the velocitiesâ€™ domains are extermely large. However, from <a href=\"https://medium.com/@tuzzer\" target=\"_blank\" rel=\"noopener\">@tuzzer</a>â€˜s post I found that astonishingly small target intervals are sufficient. Therefore, I initially started by scaling <strong>theta</strong> down to a discrete interval <code>theta âˆˆ [0, 6] âŠ‚ â„•</code> (which is, to be precise, just a set of integers {0..6}) and <strong>thetaâ€™</strong> to <code>theta&#39; âˆˆ [0, 12] âŠ‚ â„•</code>. Inspired by <a href=\"https://medium.com/@tuzzer/\" target=\"_blank\" rel=\"noopener\">@tuzzer</a>â€˜s post, I dropped the <strong>x</strong> and <strong>xâ€™</strong> features completely, which corresponds to mapping any of their values to a single scalar. The motivation behind this is that the probability of the cart leaving the environment at the left or right border in only 200 time steps (after 200 steps, the environment automatically resets itself) is pretty slow and the resulting reduction in dimensionality more worthy. </p>\n<p>The implementation of the actual Q-Learning algorithm is straightfoward and consits of a function to fetch the best action for a state from the q-table and another function to update the q-table based on the last action. Nothing special here.</p>\n<p>More interesing are the algorithmâ€™s hyperparameters, which include <strong>alpha (= learning rate)</strong>, <strong>epsilon (= exploration rate)</strong> and <strong>gamma (= discount factor)</strong>.</p>\n<p>Alpha is used to â€œsmoothâ€ the updates and make them less radical, which, in the first place, prevents from errors caused by noise. Epsilon regulates between <strong>exploitation and exploration</strong>. Accordingly, instead of picking the <em>best</em> action in a state, with a chance of Îµ a <em>random</em> action is picked. This should prevent the algorithm from getting stuck in local minima. E.g. if a bad choice was made in the beginning, without Îµ the agent would continue on evaluating that suboptimal path and would never discover any other, potentially better, path. Gamma is used to penalize the agent if it takes long to reach its goal. However, in this case, gamma is set to constant 1 (no discount), since itâ€™s even our goal to â€œsurviveâ€ as long as possible. </p>\n<p>First I tried to choose the epsilon and alpha parameters as constants and experimented with various combinations. However, I always achieved only a very poor score (~ between 20 and 50 ticks). Then, again inspired by <a href=\"https://medium.com/@tuzzer/\" target=\"_blank\" rel=\"noopener\">@tuzzer</a> I decided to introduce an adaptive learning- and exploration rate, which starts with a high value and decreases by time (with each training episode). Astonishingly, this made a huge difference. Suddenly, my algorithm converged in about ~ 200 steps. Since I never thought that these hyperparameters made such an extreme difference (from not solving the challenge at all to doing pretty well), this was probably the most interesting finding from my CartPole project. I simply adpoted <a href=\"https://medium.com/@tuzzer/\" target=\"_blank\" rel=\"noopener\">@tuzzer</a>â€˜s adaptive function, which is visualized in the figure below (the minimum of <em>0.1</em> is a hyperparameter to be optimized).</p>\n<p><img src=\"images/cartpole4.png\" alt=\"\"></p>\n<h3 id=\"Grid-search\"><a href=\"#Grid-search\" class=\"headerlink\" title=\"Grid search\"></a>Grid search</h3><p>As my Q-Learning implementation with adaptive learning- and exploration rates was finished, I implemented an additional grid search to do some hyperparameter tuning. Goal was to find the optimal combination of feature interval lengths and lower bounds for alpha and epsilon. The following parameters turned out to perform best: <code>&#39;buckets&#39;: (1, 1, 6, 12), &#39;min_alpha&#39;: 0.1, &#39;min_epsilon&#39;: 0.1</code>. Additionally, I also could have evaluated different functions for calculating the adaptive rate, but I havenâ€™t, yet. </p>\n<p><a href=\"https://gist.github.com/n1try/87b442fce7f7d58606f462191c6d6033\" target=\"_blank\" rel=\"noopener\">&gt;&gt; Code on GitHub (qcartpole_gridsearch.py)</a></p>\n<h2 id=\"Result-amp-Future-Work\"><a href=\"#Result-amp-Future-Work\" class=\"headerlink\" title=\"Result &amp; Future Work\"></a>Result &amp; Future Work</h2><p>My final score was <strong>188</strong>, <a href=\"https://gym.openai.com/evaluations/eval_emRbuGdHRnWoJuMUnPwd1Q\" target=\"_blank\" rel=\"noopener\">as can be seen in the leaderboard</a>. As I progress with my knowledge on machine learning, while practicing for the upcoming <a href=\"http://www.aifb.kit.edu/web/Lehre/Vorlesung_Maschinelles_Lernen_2_%E2%80%93_Fortgeschrittene_Verfahren/en\" target=\"_blank\" rel=\"noopener\">Machine Learning 2</a> exam, I want to continue improving my CartPole algorithm. Probably the next step will be to incorporate deep Q-Learning, which basically is Q-Learning with the only difference that the q-values are estimated by a deep neural net. The main (and probably only) advantage is the ability to handle way larger feature spaces. Iâ€™ll keep you guys up-to-date. I hope that I could encourage you to get started with Gym, or machine learning in general, too!</p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<h2 id=\"OpenAI-Gym\"><a href=\"#OpenAI-Gym\" class=\"headerlink\" title=\"OpenAI Gym\"></a>OpenAI Gym</h2><p>Today I made my first experiences with the <a href=\"https://gym.openai.com\" target=\"_blank\" rel=\"noopener\">OpenAI gym</a>, more specifically with the <a href=\"https://gym.openai.com/envs/CartPole-v0\" target=\"_blank\" rel=\"noopener\">CartPole</a> environment. Gym is basically a Python library that includes several machine learning challenges, in which an autonomous agent should be learned to fulfill different tasks, e.g. to master a simple game itself. One of the simplest and most popular challenges is CartPole. Itâ€™s basically a 2D game in which the agent has to control, i.e. move left or right, a cart to balance a pole standing perpendicularly on the cart. This is a classical reinforcement learning problem, e.g. a scenario, in which the agents starts by trying random actions as a consequence to which it gets rewarded (or not). Based on the rewards, it continuously â€œlearnsâ€, which action is good in which specific situation. Doing so, it learns how to master the game without ever being told how the game even works. The main advantage of this type of learning is, that itâ€™s completely generic and not bound to a specific problem. E.g. to learn a chess agent, you donâ€™t need to â€œtellâ€ it the rules of chess, but just let it do trial &amp; error, whereas â€œerrorâ€ means giving it a negative (or small positive) reward.</p>\n<h2 id=\"CartPole-v0\"><a href=\"#CartPole-v0\" class=\"headerlink\" title=\"CartPole-v0\"></a>CartPole-v0</h2><p>In machine learning terms, CartPole is basically a binary classification problem. There are four features as inputs, which include the cart position, its velocity, the poleâ€™s angle to the cart and its derivative (i.e. how fast the pole is â€œfallingâ€). The output is binary, i.e. either 0 or 1, corresponding to â€œleftâ€ or â€œrightâ€. One challenge is the fact that all four features are continuous values (floating point numbers), which, naively, implies an infinitely large feature space.</p>\n<p><img src=\"images/cartpole1.jpg\" alt=\"\"></p>\n<h2 id=\"Approach-Basic-Q-Learning\"><a href=\"#Approach-Basic-Q-Learning\" class=\"headerlink\" title=\"Approach: Basic Q-Learning\"></a>Approach: Basic Q-Learning</h2><p>In the <a href=\"https://his.anthropomatik.kit.edu/english/28_315.php\" target=\"_blank\" rel=\"noopener\">Machine Learning 1</a> course at my university, I got to know one of the most basic, yet widely-used reinforcement learning approaches, which is <a href=\"http://mnemstudio.org/path-finding-q-learning-tutorial.htm\" target=\"_blank\" rel=\"noopener\">Q-Learning</a>. The core of Q-Learning is to estimate a value for every possible pare of a state (s) and an action (a) by getting rewarded. Imagine the following graph, which consists of three states, while your agent is currently in _s0_. It can choose between two actions, one of which results in a good state _s1_ (e.g. having won the game), the other one results in a bad state _s2_ (e.g. having lost the game). Accordingly, the transition leading to the good (bad) state gives a reward of 100 (-100). If the agent performs action _a0_, the q-value of _s0_ will probably become negative (Q(s0, a0) &lt; 0)), while Q(s0, a1) &gt; 0.</p>\n<p><img src=\"images/cartpole2.png\" alt=\"\"></p>\n<p>The update of the q-value is done according to the following equation.</p>\n<p><img src=\"images/cartpole3.png\" alt=\"\"></p>\n<p>Basically, a (S, A)-tupleâ€™s new q-value depends on its old q-value, the immediate reward received for the action and the maximum q-value achievable in the following state. So a (S, A)-pairâ€™s q-value indirectly depends on all its successorsâ€™ q-values, which is expressed in the recursive function definition. By repeatedly walking through all nodes and transistions, the agent can update any (S, A)-pairs q-value, while the results of good and bad actions are slowly â€œbackpropagatedâ€ from terminal nodes to early nodes. The agent ends up with a (usually multidimensional) table mapping states and actions to q-values, so that given any state, the best action can be picked by choosing the highest respective q-value.</p>\n<h2 id=\"My-implementation\"><a href=\"#My-implementation\" class=\"headerlink\" title=\"My implementation\"></a>My implementation</h2><p>Since Q-Learning is pretty straightforward to understand and implement, I decided on picking that algorithm as a starting point for my CartPole challenge. I looked for other solutions, that also use CartPole and found <a href=\"https://medium.com/@tuzzer/cart-pole-balancing-with-q-learning-b54c6068d947\" target=\"_blank\" rel=\"noopener\">this blog post</a> by <a href=\"https://medium.com/@tuzzer\" target=\"_blank\" rel=\"noopener\">@tuzzer</a>, which had partially inspired me during my implementation. </p>\n<p><a href=\"https://gist.github.com/n1try/af0b8476ae4106ec098fea1dfe57f578\" target=\"_blank\" rel=\"noopener\">&gt;&gt; Code on GitHub (qcartpole.py)</a></p>\n<h3 id=\"Transforming-the-feature-space\"><a href=\"#Transforming-the-feature-space\" class=\"headerlink\" title=\"Transforming the feature space\"></a>Transforming the feature space</h3><p>Actually the main challenge was to convert the continuous, 4-dimensional input space to a discrete space with a finite and preferably small, yet expressive, number of discrete states. The less states we have, the smaller the Q-table will be, the less steps the agent will need to properly learn its values. However, too few states might not hold enough information to properly represent the environment. The original domains of the input features are these.</p>\n<ul>\n<li><strong>x</strong> (cart position) âˆˆ [-4.8, 4.8]</li>\n<li><strong>xâ€™</strong> (cart velocity) âˆˆ [-3.4 <em> 10^38, 3.4 </em> 10^38]</li>\n<li><strong>theta</strong> (angle) âˆˆ [-0.42, 0.42]</li>\n<li><strong>thetaâ€™</strong> (angle velocity) âˆˆ [-3.4 <em> 10^38, 3.4 </em> 10^38]</li>\n</ul>\n<h3 id=\"Finding-the-parameters\"><a href=\"#Finding-the-parameters\" class=\"headerlink\" title=\"Finding the parameters\"></a>Finding the parameters</h3><p>As can be seen, especially the velocitiesâ€™ domains are extermely large. However, from <a href=\"https://medium.com/@tuzzer\" target=\"_blank\" rel=\"noopener\">@tuzzer</a>â€˜s post I found that astonishingly small target intervals are sufficient. Therefore, I initially started by scaling <strong>theta</strong> down to a discrete interval <code>theta âˆˆ [0, 6] âŠ‚ â„•</code> (which is, to be precise, just a set of integers {0..6}) and <strong>thetaâ€™</strong> to <code>theta&#39; âˆˆ [0, 12] âŠ‚ â„•</code>. Inspired by <a href=\"https://medium.com/@tuzzer/\" target=\"_blank\" rel=\"noopener\">@tuzzer</a>â€˜s post, I dropped the <strong>x</strong> and <strong>xâ€™</strong> features completely, which corresponds to mapping any of their values to a single scalar. The motivation behind this is that the probability of the cart leaving the environment at the left or right border in only 200 time steps (after 200 steps, the environment automatically resets itself) is pretty slow and the resulting reduction in dimensionality more worthy. </p>\n<p>The implementation of the actual Q-Learning algorithm is straightfoward and consits of a function to fetch the best action for a state from the q-table and another function to update the q-table based on the last action. Nothing special here.</p>\n<p>More interesing are the algorithmâ€™s hyperparameters, which include <strong>alpha (= learning rate)</strong>, <strong>epsilon (= exploration rate)</strong> and <strong>gamma (= discount factor)</strong>.</p>\n<p>Alpha is used to â€œsmoothâ€ the updates and make them less radical, which, in the first place, prevents from errors caused by noise. Epsilon regulates between <strong>exploitation and exploration</strong>. Accordingly, instead of picking the <em>best</em> action in a state, with a chance of Îµ a <em>random</em> action is picked. This should prevent the algorithm from getting stuck in local minima. E.g. if a bad choice was made in the beginning, without Îµ the agent would continue on evaluating that suboptimal path and would never discover any other, potentially better, path. Gamma is used to penalize the agent if it takes long to reach its goal. However, in this case, gamma is set to constant 1 (no discount), since itâ€™s even our goal to â€œsurviveâ€ as long as possible. </p>\n<p>First I tried to choose the epsilon and alpha parameters as constants and experimented with various combinations. However, I always achieved only a very poor score (~ between 20 and 50 ticks). Then, again inspired by <a href=\"https://medium.com/@tuzzer/\" target=\"_blank\" rel=\"noopener\">@tuzzer</a> I decided to introduce an adaptive learning- and exploration rate, which starts with a high value and decreases by time (with each training episode). Astonishingly, this made a huge difference. Suddenly, my algorithm converged in about ~ 200 steps. Since I never thought that these hyperparameters made such an extreme difference (from not solving the challenge at all to doing pretty well), this was probably the most interesting finding from my CartPole project. I simply adpoted <a href=\"https://medium.com/@tuzzer/\" target=\"_blank\" rel=\"noopener\">@tuzzer</a>â€˜s adaptive function, which is visualized in the figure below (the minimum of <em>0.1</em> is a hyperparameter to be optimized).</p>\n<p><img src=\"images/cartpole4.png\" alt=\"\"></p>\n<h3 id=\"Grid-search\"><a href=\"#Grid-search\" class=\"headerlink\" title=\"Grid search\"></a>Grid search</h3><p>As my Q-Learning implementation with adaptive learning- and exploration rates was finished, I implemented an additional grid search to do some hyperparameter tuning. Goal was to find the optimal combination of feature interval lengths and lower bounds for alpha and epsilon. The following parameters turned out to perform best: <code>&#39;buckets&#39;: (1, 1, 6, 12), &#39;min_alpha&#39;: 0.1, &#39;min_epsilon&#39;: 0.1</code>. Additionally, I also could have evaluated different functions for calculating the adaptive rate, but I havenâ€™t, yet. </p>\n<p><a href=\"https://gist.github.com/n1try/87b442fce7f7d58606f462191c6d6033\" target=\"_blank\" rel=\"noopener\">&gt;&gt; Code on GitHub (qcartpole_gridsearch.py)</a></p>\n<h2 id=\"Result-amp-Future-Work\"><a href=\"#Result-amp-Future-Work\" class=\"headerlink\" title=\"Result &amp; Future Work\"></a>Result &amp; Future Work</h2><p>My final score was <strong>188</strong>, <a href=\"https://gym.openai.com/evaluations/eval_emRbuGdHRnWoJuMUnPwd1Q\" target=\"_blank\" rel=\"noopener\">as can be seen in the leaderboard</a>. As I progress with my knowledge on machine learning, while practicing for the upcoming <a href=\"http://www.aifb.kit.edu/web/Lehre/Vorlesung_Maschinelles_Lernen_2_%E2%80%93_Fortgeschrittene_Verfahren/en\" target=\"_blank\" rel=\"noopener\">Machine Learning 2</a> exam, I want to continue improving my CartPole algorithm. Probably the next step will be to incorporate deep Q-Learning, which basically is Q-Learning with the only difference that the q-values are estimated by a deep neural net. The main (and probably only) advantage is the ability to handle way larger feature spaces. Iâ€™ll keep you guys up-to-date. I hope that I could encourage you to get started with Gym, or machine learning in general, too!</p>\n"},{"title":"Digitalocean â€“ My preferred Cloud Hosting Provider","date":"2016-04-06T20:55:18.000Z","_content":"\n![](/images/do.png)\n[DigitalOcean.com](https://digitalocean.com) is a service that offers you on-demand virtual server instances that you can use to host any server application, be it a simple webpage, a Node.js written backend, any Docker container or anything else.\n\nIt is especially useful if you have developed a web application and want to bring it to the internet without owning a root server. In this case you can go to DigitalOcean, choose any boilerplate (or Droplet, as they call it) for your new virtual, cloud-hosted machine, additionally choose a the datacenter region which is closest to you or your customers, add your SSH keys for quick access and hit the create button. Within less than a minute your machine is up and running with a dedicated IPv4 assigned where you can ssh in.\n\nAs a template / boilerplate you can either choose from the common, plain Linux distributions (even CoreOS) in almost any version or take one of the various pre-configured environments like a machine already running Docker, Node.js, ownCloud, Joomla or plenty other runtimes and applications.\n\nFor scalability you can choose between different sizes, which basically means different memory capacity, cpu cores, ssd capacity and amount of traffic.\n\nA feature which I only know from DigitalOcean by now is the ability to create a cluster of multiple machines (Droplets) with private networking, meaning they can communicate with every other node in the cluster but are kind of isolated from the internet. I havenâ€™t tried this feature too much but it is similar to what you might know from linking multiple Docker containers together.\n\nWhat I also like about the service is the ultra simple-to-use, minimalistic and intuitive web-interface that abstracts away this entire technical complexity running in the background when users do a single click on a button until a pre-installed machine comes up.\n\nDigitalOcean is my personal favorite service of this type, but I also want to mention some alternatives which are [Microsoft Azure](https://azure.microsoft.com/en-us/), [Google Compute Engine](https://cloud.google.com/compute/), [Amazon EC2](https://aws.amazon.com/de/ec2), [Linode](https://www.linode.com/) or in a wider sense also [JiffyBox.de](http://jiffybox.de).\n\nIf you want to give DigitalOcean a try (and support me), follow [this referral link](https://m.do.co/c/4abee7f659ad) where you get $10 in credits, which is enough for running the smallest container for two months. I will get $25 in credits in case you in turn spend $25 for credits. Of course I would be very pleased if you did so.\n\n![](assets/img/simple-smile.png)","source":"_posts/digitalocean-my-preferred-cloud-hosting-provider.md","raw":"---\ntitle: Digitalocean â€“ My preferred Cloud Hosting Provider\ndate: 2016-04-06 22:55:18\ntags:\n---\n\n![](/images/do.png)\n[DigitalOcean.com](https://digitalocean.com) is a service that offers you on-demand virtual server instances that you can use to host any server application, be it a simple webpage, a Node.js written backend, any Docker container or anything else.\n\nIt is especially useful if you have developed a web application and want to bring it to the internet without owning a root server. In this case you can go to DigitalOcean, choose any boilerplate (or Droplet, as they call it) for your new virtual, cloud-hosted machine, additionally choose a the datacenter region which is closest to you or your customers, add your SSH keys for quick access and hit the create button. Within less than a minute your machine is up and running with a dedicated IPv4 assigned where you can ssh in.\n\nAs a template / boilerplate you can either choose from the common, plain Linux distributions (even CoreOS) in almost any version or take one of the various pre-configured environments like a machine already running Docker, Node.js, ownCloud, Joomla or plenty other runtimes and applications.\n\nFor scalability you can choose between different sizes, which basically means different memory capacity, cpu cores, ssd capacity and amount of traffic.\n\nA feature which I only know from DigitalOcean by now is the ability to create a cluster of multiple machines (Droplets) with private networking, meaning they can communicate with every other node in the cluster but are kind of isolated from the internet. I havenâ€™t tried this feature too much but it is similar to what you might know from linking multiple Docker containers together.\n\nWhat I also like about the service is the ultra simple-to-use, minimalistic and intuitive web-interface that abstracts away this entire technical complexity running in the background when users do a single click on a button until a pre-installed machine comes up.\n\nDigitalOcean is my personal favorite service of this type, but I also want to mention some alternatives which are [Microsoft Azure](https://azure.microsoft.com/en-us/), [Google Compute Engine](https://cloud.google.com/compute/), [Amazon EC2](https://aws.amazon.com/de/ec2), [Linode](https://www.linode.com/) or in a wider sense also [JiffyBox.de](http://jiffybox.de).\n\nIf you want to give DigitalOcean a try (and support me), follow [this referral link](https://m.do.co/c/4abee7f659ad) where you get $10 in credits, which is enough for running the smallest container for two months. I will get $25 in credits in case you in turn spend $25 for credits. Of course I would be very pleased if you did so.\n\n![](assets/img/simple-smile.png)","slug":"digitalocean-my-preferred-cloud-hosting-provider","published":1,"updated":"2018-03-19T09:30:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2giolu0007cxrg2bp04ya7","content":"<p><img src=\"/images/do.png\" alt=\"\"><br><a href=\"https://digitalocean.com\" target=\"_blank\" rel=\"noopener\">DigitalOcean.com</a> is a service that offers you on-demand virtual server instances that you can use to host any server application, be it a simple webpage, a Node.js written backend, any Docker container or anything else.</p>\n<p>It is especially useful if you have developed a web application and want to bring it to the internet without owning a root server. In this case you can go to DigitalOcean, choose any boilerplate (or Droplet, as they call it) for your new virtual, cloud-hosted machine, additionally choose a the datacenter region which is closest to you or your customers, add your SSH keys for quick access and hit the create button. Within less than a minute your machine is up and running with a dedicated IPv4 assigned where you can ssh in.</p>\n<p>As a template / boilerplate you can either choose from the common, plain Linux distributions (even CoreOS) in almost any version or take one of the various pre-configured environments like a machine already running Docker, Node.js, ownCloud, Joomla or plenty other runtimes and applications.</p>\n<p>For scalability you can choose between different sizes, which basically means different memory capacity, cpu cores, ssd capacity and amount of traffic.</p>\n<p>A feature which I only know from DigitalOcean by now is the ability to create a cluster of multiple machines (Droplets) with private networking, meaning they can communicate with every other node in the cluster but are kind of isolated from the internet. I havenâ€™t tried this feature too much but it is similar to what you might know from linking multiple Docker containers together.</p>\n<p>What I also like about the service is the ultra simple-to-use, minimalistic and intuitive web-interface that abstracts away this entire technical complexity running in the background when users do a single click on a button until a pre-installed machine comes up.</p>\n<p>DigitalOcean is my personal favorite service of this type, but I also want to mention some alternatives which are <a href=\"https://azure.microsoft.com/en-us/\" target=\"_blank\" rel=\"noopener\">Microsoft Azure</a>, <a href=\"https://cloud.google.com/compute/\" target=\"_blank\" rel=\"noopener\">Google Compute Engine</a>, <a href=\"https://aws.amazon.com/de/ec2\" target=\"_blank\" rel=\"noopener\">Amazon EC2</a>, <a href=\"https://www.linode.com/\" target=\"_blank\" rel=\"noopener\">Linode</a> or in a wider sense also <a href=\"http://jiffybox.de\" target=\"_blank\" rel=\"noopener\">JiffyBox.de</a>.</p>\n<p>If you want to give DigitalOcean a try (and support me), follow <a href=\"https://m.do.co/c/4abee7f659ad\" target=\"_blank\" rel=\"noopener\">this referral link</a> where you get $10 in credits, which is enough for running the smallest container for two months. I will get $25 in credits in case you in turn spend $25 for credits. Of course I would be very pleased if you did so.</p>\n<p><img src=\"assets/img/simple-smile.png\" alt=\"\"></p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<p><img src=\"/images/do.png\" alt=\"\"><br><a href=\"https://digitalocean.com\" target=\"_blank\" rel=\"noopener\">DigitalOcean.com</a> is a service that offers you on-demand virtual server instances that you can use to host any server application, be it a simple webpage, a Node.js written backend, any Docker container or anything else.</p>\n<p>It is especially useful if you have developed a web application and want to bring it to the internet without owning a root server. In this case you can go to DigitalOcean, choose any boilerplate (or Droplet, as they call it) for your new virtual, cloud-hosted machine, additionally choose a the datacenter region which is closest to you or your customers, add your SSH keys for quick access and hit the create button. Within less than a minute your machine is up and running with a dedicated IPv4 assigned where you can ssh in.</p>\n<p>As a template / boilerplate you can either choose from the common, plain Linux distributions (even CoreOS) in almost any version or take one of the various pre-configured environments like a machine already running Docker, Node.js, ownCloud, Joomla or plenty other runtimes and applications.</p>\n<p>For scalability you can choose between different sizes, which basically means different memory capacity, cpu cores, ssd capacity and amount of traffic.</p>\n<p>A feature which I only know from DigitalOcean by now is the ability to create a cluster of multiple machines (Droplets) with private networking, meaning they can communicate with every other node in the cluster but are kind of isolated from the internet. I havenâ€™t tried this feature too much but it is similar to what you might know from linking multiple Docker containers together.</p>\n<p>What I also like about the service is the ultra simple-to-use, minimalistic and intuitive web-interface that abstracts away this entire technical complexity running in the background when users do a single click on a button until a pre-installed machine comes up.</p>\n<p>DigitalOcean is my personal favorite service of this type, but I also want to mention some alternatives which are <a href=\"https://azure.microsoft.com/en-us/\" target=\"_blank\" rel=\"noopener\">Microsoft Azure</a>, <a href=\"https://cloud.google.com/compute/\" target=\"_blank\" rel=\"noopener\">Google Compute Engine</a>, <a href=\"https://aws.amazon.com/de/ec2\" target=\"_blank\" rel=\"noopener\">Amazon EC2</a>, <a href=\"https://www.linode.com/\" target=\"_blank\" rel=\"noopener\">Linode</a> or in a wider sense also <a href=\"http://jiffybox.de\" target=\"_blank\" rel=\"noopener\">JiffyBox.de</a>.</p>\n<p>If you want to give DigitalOcean a try (and support me), follow <a href=\"https://m.do.co/c/4abee7f659ad\" target=\"_blank\" rel=\"noopener\">this referral link</a> where you get $10 in credits, which is enough for running the smallest container for two months. I will get $25 in credits in case you in turn spend $25 for credits. Of course I would be very pleased if you did so.</p>\n<p><img src=\"assets/img/simple-smile.png\" alt=\"\"></p>\n"},{"title":"Design of a Linked Data-enabled Microservice Platform for the Industrial Internet of Things","date":"2016-10-19T21:03:07.000Z","_content":"\nAs the topic of my bachelor's thesis at the [TECO](http://teco.edu) and part of the [ScaleIT](https://scale-it.org) research project I've designed and developed an IoT software platform with focus on uniformity, openess and ease of adoption to tackle to problem of bringing flexible IT infrastructures to the industrial shopfloor.\nHere's my thesis' abstract to get an idea of the topic.\n\n![](/images/thesis_mockup.png)\n\n### Abstract\n\nWhile recent trends towards highly digitized, smart factories entail substantial chances for manufacturing companies to boost their performance, flexibility and productivity, the industry commonly struggles to adopt suitable technology. One major problem is a lack of uniform, standardized solutions, which could be integrated to the shopfloor without the necessity of highly specialized technical expert knowledge and a large amount of planning and restructuring.\\par \nAddressing that problem, this work proposes an architecture design as well as a concrete implementation of a Internet Of Things software platform, which mainly focuses on technological uniformity and ease of adoption and usage. As a guideline, a real-world use case elaborated in cooperation with industry partners is presented. Further on, it is shown, how general purpose web technology can be combined advantageously with recent architectural-, operational- and cultural trends in software design, powerful machine-to-machine interaction techniques and common user experience concepts. In-depth thoughts on software structure, real-time communication, machine-to-machine interaction, uniform data integration and user experience are conducted to finally obtain a working proof-of-concept software alongside recommendations and best practices for adopting smart technology on the shopfloor. An eventual evaluation investigates the designed platform regarding both performance and suitability for particular real-world scenarios and recommends further endeavor to be conducted towards achieving an actual product. \n\n### Tech stack\n\nWe've used general-purpose web technology, Linked Data techniques, semantic hypermedia APIs with Hydra and state-of-the-art software development practices and cloud technology to fulfil our goal. We also picked up on the commonly understood UX concept of apps to abstract underlying technical details away from the end-user and created kind of an app store for on-shoploor purposes. \n\n![](/images/thesis_stack.png)\n\nMy work is published at the [KITopen repository](https://publikationen.bibliothek.kit.edu/1000061764).\nIf you got curious and are interested in more details or in case you have questions or criticism, please feel free to contact me!\n","source":"_posts/design-of-a-linked-dataenabled-microservice-platform-for-the-industrial-internet-of-things.md","raw":"---\ntitle: >-\n  Design of a Linked Data-enabled Microservice Platform for the Industrial\n  Internet of Things\ndate: 2016-10-19 23:03:07\ntags:\n---\n\nAs the topic of my bachelor's thesis at the [TECO](http://teco.edu) and part of the [ScaleIT](https://scale-it.org) research project I've designed and developed an IoT software platform with focus on uniformity, openess and ease of adoption to tackle to problem of bringing flexible IT infrastructures to the industrial shopfloor.\nHere's my thesis' abstract to get an idea of the topic.\n\n![](/images/thesis_mockup.png)\n\n### Abstract\n\nWhile recent trends towards highly digitized, smart factories entail substantial chances for manufacturing companies to boost their performance, flexibility and productivity, the industry commonly struggles to adopt suitable technology. One major problem is a lack of uniform, standardized solutions, which could be integrated to the shopfloor without the necessity of highly specialized technical expert knowledge and a large amount of planning and restructuring.\\par \nAddressing that problem, this work proposes an architecture design as well as a concrete implementation of a Internet Of Things software platform, which mainly focuses on technological uniformity and ease of adoption and usage. As a guideline, a real-world use case elaborated in cooperation with industry partners is presented. Further on, it is shown, how general purpose web technology can be combined advantageously with recent architectural-, operational- and cultural trends in software design, powerful machine-to-machine interaction techniques and common user experience concepts. In-depth thoughts on software structure, real-time communication, machine-to-machine interaction, uniform data integration and user experience are conducted to finally obtain a working proof-of-concept software alongside recommendations and best practices for adopting smart technology on the shopfloor. An eventual evaluation investigates the designed platform regarding both performance and suitability for particular real-world scenarios and recommends further endeavor to be conducted towards achieving an actual product. \n\n### Tech stack\n\nWe've used general-purpose web technology, Linked Data techniques, semantic hypermedia APIs with Hydra and state-of-the-art software development practices and cloud technology to fulfil our goal. We also picked up on the commonly understood UX concept of apps to abstract underlying technical details away from the end-user and created kind of an app store for on-shoploor purposes. \n\n![](/images/thesis_stack.png)\n\nMy work is published at the [KITopen repository](https://publikationen.bibliothek.kit.edu/1000061764).\nIf you got curious and are interested in more details or in case you have questions or criticism, please feel free to contact me!\n","slug":"design-of-a-linked-dataenabled-microservice-platform-for-the-industrial-internet-of-things","published":1,"updated":"2018-03-19T09:30:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2giolv0008cxrge85kln4g","content":"<p>As the topic of my bachelorâ€™s thesis at the <a href=\"http://teco.edu\" target=\"_blank\" rel=\"noopener\">TECO</a> and part of the <a href=\"https://scale-it.org\" target=\"_blank\" rel=\"noopener\">ScaleIT</a> research project Iâ€™ve designed and developed an IoT software platform with focus on uniformity, openess and ease of adoption to tackle to problem of bringing flexible IT infrastructures to the industrial shopfloor.<br>Hereâ€™s my thesisâ€™ abstract to get an idea of the topic.</p>\n<p><img src=\"/images/thesis_mockup.png\" alt=\"\"></p>\n<h3 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h3><p>While recent trends towards highly digitized, smart factories entail substantial chances for manufacturing companies to boost their performance, flexibility and productivity, the industry commonly struggles to adopt suitable technology. One major problem is a lack of uniform, standardized solutions, which could be integrated to the shopfloor without the necessity of highly specialized technical expert knowledge and a large amount of planning and restructuring.\\par<br>Addressing that problem, this work proposes an architecture design as well as a concrete implementation of a Internet Of Things software platform, which mainly focuses on technological uniformity and ease of adoption and usage. As a guideline, a real-world use case elaborated in cooperation with industry partners is presented. Further on, it is shown, how general purpose web technology can be combined advantageously with recent architectural-, operational- and cultural trends in software design, powerful machine-to-machine interaction techniques and common user experience concepts. In-depth thoughts on software structure, real-time communication, machine-to-machine interaction, uniform data integration and user experience are conducted to finally obtain a working proof-of-concept software alongside recommendations and best practices for adopting smart technology on the shopfloor. An eventual evaluation investigates the designed platform regarding both performance and suitability for particular real-world scenarios and recommends further endeavor to be conducted towards achieving an actual product. </p>\n<h3 id=\"Tech-stack\"><a href=\"#Tech-stack\" class=\"headerlink\" title=\"Tech stack\"></a>Tech stack</h3><p>Weâ€™ve used general-purpose web technology, Linked Data techniques, semantic hypermedia APIs with Hydra and state-of-the-art software development practices and cloud technology to fulfil our goal. We also picked up on the commonly understood UX concept of apps to abstract underlying technical details away from the end-user and created kind of an app store for on-shoploor purposes. </p>\n<p><img src=\"/images/thesis_stack.png\" alt=\"\"></p>\n<p>My work is published at the <a href=\"https://publikationen.bibliothek.kit.edu/1000061764\" target=\"_blank\" rel=\"noopener\">KITopen repository</a>.<br>If you got curious and are interested in more details or in case you have questions or criticism, please feel free to contact me!</p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<p>As the topic of my bachelorâ€™s thesis at the <a href=\"http://teco.edu\" target=\"_blank\" rel=\"noopener\">TECO</a> and part of the <a href=\"https://scale-it.org\" target=\"_blank\" rel=\"noopener\">ScaleIT</a> research project Iâ€™ve designed and developed an IoT software platform with focus on uniformity, openess and ease of adoption to tackle to problem of bringing flexible IT infrastructures to the industrial shopfloor.<br>Hereâ€™s my thesisâ€™ abstract to get an idea of the topic.</p>\n<p><img src=\"/images/thesis_mockup.png\" alt=\"\"></p>\n<h3 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h3><p>While recent trends towards highly digitized, smart factories entail substantial chances for manufacturing companies to boost their performance, flexibility and productivity, the industry commonly struggles to adopt suitable technology. One major problem is a lack of uniform, standardized solutions, which could be integrated to the shopfloor without the necessity of highly specialized technical expert knowledge and a large amount of planning and restructuring.\\par<br>Addressing that problem, this work proposes an architecture design as well as a concrete implementation of a Internet Of Things software platform, which mainly focuses on technological uniformity and ease of adoption and usage. As a guideline, a real-world use case elaborated in cooperation with industry partners is presented. Further on, it is shown, how general purpose web technology can be combined advantageously with recent architectural-, operational- and cultural trends in software design, powerful machine-to-machine interaction techniques and common user experience concepts. In-depth thoughts on software structure, real-time communication, machine-to-machine interaction, uniform data integration and user experience are conducted to finally obtain a working proof-of-concept software alongside recommendations and best practices for adopting smart technology on the shopfloor. An eventual evaluation investigates the designed platform regarding both performance and suitability for particular real-world scenarios and recommends further endeavor to be conducted towards achieving an actual product. </p>\n<h3 id=\"Tech-stack\"><a href=\"#Tech-stack\" class=\"headerlink\" title=\"Tech stack\"></a>Tech stack</h3><p>Weâ€™ve used general-purpose web technology, Linked Data techniques, semantic hypermedia APIs with Hydra and state-of-the-art software development practices and cloud technology to fulfil our goal. We also picked up on the commonly understood UX concept of apps to abstract underlying technical details away from the end-user and created kind of an app store for on-shoploor purposes. </p>\n<p><img src=\"/images/thesis_stack.png\" alt=\"\"></p>\n<p>My work is published at the <a href=\"https://publikationen.bibliothek.kit.edu/1000061764\" target=\"_blank\" rel=\"noopener\">KITopen repository</a>.<br>If you got curious and are interested in more details or in case you have questions or criticism, please feel free to contact me!</p>\n"},{"title":"Halite - A rule-based AI bot","date":"2018-01-03T07:04:08.000Z","_content":"\nAfter having spent a considerable amount of time with it last weekend, I wanted to make a short comment on [Halite.io](https://halite.io). Halite is a programming- and AI competition where people can write programs or train algorithms to control a bot that plays in a virtual 2D game environment. There is a leaderboard to track how your bot competes with other players' bots and you can watch a replay of every game your bot has played, which helps _debugging_ your bot as well as figuring out other people's strategies. Originally, I got aware of this challenge through a video by [one of my favorite](https://www.youtube.com/channel/UCfzlCWGWYyIQ0aLC5w48gBQ) YouTube channels and became slightly addicted from that moment on. \n\n## The Game\n![](images/halite_game.png)\n\nWhile the complete rule set of Halite can be viewed in [their documentation](https://halite.io/learn-programming-challenge/), I only want to explain very basics here. In Halite you play in a space scenario comprising _ships_ and _planets_, while you (= your bot) controls your ships. A ship can do three actions: _move_, _dock_ to or _undock_ from a planet. The more ships you have docked at a planet, the faster you are _mining_ the planet, which means to produce new ships. When two ships get close enough, they can fight and only the winner's ship survives. The game is turn-based, so each of the up to four players' programs are queried (by the game environment) for a list of moves for each of their ships in every turn. Input is the current game state (player- & planet positions, ships' health, ships' current status, ...) and output is a move for each ship. The final goal is to either completely dominate (= destroy every other players' ships) or own the strongest ship fleet and the most planets after 300 turns. \n\nAt the time of writing this article, the leaderboard comprises __~ 4700 players__ from __98 countries__. Most of them are either university students or professionals, who have, in total, played __10.9 million__ games. More interesting statistics can be found at the [stats](http://stats.halite.io:3000/public/dashboard/545ebc3c-4cdb-4940-acf1-e4d1332defac) page. \n\n## My bot\nFirst of all, what I found especially cool is the fact that players are completely free in their choice of how to realize their bot (hard-coding, machine learning, ...) and what programming language to use. Halite offers community-created starter templates for C++, C#, Dart, Elixir, Go, Haskell, JavaScript, Julia, Kotlin, PHP, Ruby, Rust, Scala, Swift and more. You can choose whatever language you like - which was __Java__ for me - and eventually submit a ZIP file with your code or binary, as well as a script for executing it, to their website. The interface between your program and the game environment is _stdin_ / _stdout_. \n\n![](images/halite_langs.png)\n\nI decided to build my bot based on rather simple rules first, which I figured out by watching some other players' replays. Probably applying machine learning to solve Halite would be even more challenging, but at the time I got aware of this competition, it was about to last only three more weeks (until January, 22nd), so I picked up on a rather simple approach.\n\n## Strategies\nI developed three different strategies for playing Halite, while my bot could dynamically switch between them during the game. The first one is called the __BalancedStrategy__. It's a fair mixture of conquering new planets, raising ship production and destroying enemy ships. In this strategy, a ship's most preferable goal is to take empty planets. However, if the next empty planet is unavailable ot too far away, it may also dock at a planet my bot already owns in order to increase production. However, no more than three of my own ships will ever dock at the same planet. If both the next empty planet as well as the next own planet are unavailable or too far away, the ship starts chasing the nearest enemy ship. \n\nIn addition to this compromise-like strategy, I found that more extreme ones can be successful, too. For instance, in a 1 vs. 1 match, my opponents usually won because they almost instantly destroyed all of my ships in the very beginning. So I decided to further introduce the __AggressiveStrategy__, which is only applied in matched of two players. Following this strategy, all of my three initial ships immediately start chasing the enemy's three ships. If they're successful, the game is usually over after only a few turns. \n\nFinally I built the __MiningStrategy__. Goal is to maxmimize mining rate right in the beginning. My three ships are immediately docking at the nearest and largest (in terms of how many ships can dock at it) free planet and dock at it. New ships will dock at the same planet until it's full. Doing so, I can quickly produce new ships which then, after the first planet is full, switch over to applying the __BalancedStrategy__. \n\n## Results\nUsing the bot described above, the best rank I achieved in the leaderboard was __250 of ~ 4500__ (top 6 %) and I'm still ambitious to get even better ðŸ˜ƒ. My bot is playing as [n1try](https://halite.io/user/?user_id=7481).\n\n\\>> [Source code on GitHub](https://github.com/n1try/halite-bot-java). ","source":"_posts/halite-a-rule-based-ai-bot.md","raw":"---\ntitle: Halite - A rule-based AI bot\ndate: 2018-01-03 08:04:08\ntags:\n---\n\nAfter having spent a considerable amount of time with it last weekend, I wanted to make a short comment on [Halite.io](https://halite.io). Halite is a programming- and AI competition where people can write programs or train algorithms to control a bot that plays in a virtual 2D game environment. There is a leaderboard to track how your bot competes with other players' bots and you can watch a replay of every game your bot has played, which helps _debugging_ your bot as well as figuring out other people's strategies. Originally, I got aware of this challenge through a video by [one of my favorite](https://www.youtube.com/channel/UCfzlCWGWYyIQ0aLC5w48gBQ) YouTube channels and became slightly addicted from that moment on. \n\n## The Game\n![](images/halite_game.png)\n\nWhile the complete rule set of Halite can be viewed in [their documentation](https://halite.io/learn-programming-challenge/), I only want to explain very basics here. In Halite you play in a space scenario comprising _ships_ and _planets_, while you (= your bot) controls your ships. A ship can do three actions: _move_, _dock_ to or _undock_ from a planet. The more ships you have docked at a planet, the faster you are _mining_ the planet, which means to produce new ships. When two ships get close enough, they can fight and only the winner's ship survives. The game is turn-based, so each of the up to four players' programs are queried (by the game environment) for a list of moves for each of their ships in every turn. Input is the current game state (player- & planet positions, ships' health, ships' current status, ...) and output is a move for each ship. The final goal is to either completely dominate (= destroy every other players' ships) or own the strongest ship fleet and the most planets after 300 turns. \n\nAt the time of writing this article, the leaderboard comprises __~ 4700 players__ from __98 countries__. Most of them are either university students or professionals, who have, in total, played __10.9 million__ games. More interesting statistics can be found at the [stats](http://stats.halite.io:3000/public/dashboard/545ebc3c-4cdb-4940-acf1-e4d1332defac) page. \n\n## My bot\nFirst of all, what I found especially cool is the fact that players are completely free in their choice of how to realize their bot (hard-coding, machine learning, ...) and what programming language to use. Halite offers community-created starter templates for C++, C#, Dart, Elixir, Go, Haskell, JavaScript, Julia, Kotlin, PHP, Ruby, Rust, Scala, Swift and more. You can choose whatever language you like - which was __Java__ for me - and eventually submit a ZIP file with your code or binary, as well as a script for executing it, to their website. The interface between your program and the game environment is _stdin_ / _stdout_. \n\n![](images/halite_langs.png)\n\nI decided to build my bot based on rather simple rules first, which I figured out by watching some other players' replays. Probably applying machine learning to solve Halite would be even more challenging, but at the time I got aware of this competition, it was about to last only three more weeks (until January, 22nd), so I picked up on a rather simple approach.\n\n## Strategies\nI developed three different strategies for playing Halite, while my bot could dynamically switch between them during the game. The first one is called the __BalancedStrategy__. It's a fair mixture of conquering new planets, raising ship production and destroying enemy ships. In this strategy, a ship's most preferable goal is to take empty planets. However, if the next empty planet is unavailable ot too far away, it may also dock at a planet my bot already owns in order to increase production. However, no more than three of my own ships will ever dock at the same planet. If both the next empty planet as well as the next own planet are unavailable or too far away, the ship starts chasing the nearest enemy ship. \n\nIn addition to this compromise-like strategy, I found that more extreme ones can be successful, too. For instance, in a 1 vs. 1 match, my opponents usually won because they almost instantly destroyed all of my ships in the very beginning. So I decided to further introduce the __AggressiveStrategy__, which is only applied in matched of two players. Following this strategy, all of my three initial ships immediately start chasing the enemy's three ships. If they're successful, the game is usually over after only a few turns. \n\nFinally I built the __MiningStrategy__. Goal is to maxmimize mining rate right in the beginning. My three ships are immediately docking at the nearest and largest (in terms of how many ships can dock at it) free planet and dock at it. New ships will dock at the same planet until it's full. Doing so, I can quickly produce new ships which then, after the first planet is full, switch over to applying the __BalancedStrategy__. \n\n## Results\nUsing the bot described above, the best rank I achieved in the leaderboard was __250 of ~ 4500__ (top 6 %) and I'm still ambitious to get even better ðŸ˜ƒ. My bot is playing as [n1try](https://halite.io/user/?user_id=7481).\n\n\\>> [Source code on GitHub](https://github.com/n1try/halite-bot-java). ","slug":"halite-a-rule-based-ai-bot","published":1,"updated":"2018-03-19T09:30:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2giolw0009cxrglrl3fssw","content":"<p>After having spent a considerable amount of time with it last weekend, I wanted to make a short comment on <a href=\"https://halite.io\" target=\"_blank\" rel=\"noopener\">Halite.io</a>. Halite is a programming- and AI competition where people can write programs or train algorithms to control a bot that plays in a virtual 2D game environment. There is a leaderboard to track how your bot competes with other playersâ€™ bots and you can watch a replay of every game your bot has played, which helps <em>debugging</em> your bot as well as figuring out other peopleâ€™s strategies. Originally, I got aware of this challenge through a video by <a href=\"https://www.youtube.com/channel/UCfzlCWGWYyIQ0aLC5w48gBQ\" target=\"_blank\" rel=\"noopener\">one of my favorite</a> YouTube channels and became slightly addicted from that moment on. </p>\n<h2 id=\"The-Game\"><a href=\"#The-Game\" class=\"headerlink\" title=\"The Game\"></a>The Game</h2><p><img src=\"images/halite_game.png\" alt=\"\"></p>\n<p>While the complete rule set of Halite can be viewed in <a href=\"https://halite.io/learn-programming-challenge/\" target=\"_blank\" rel=\"noopener\">their documentation</a>, I only want to explain very basics here. In Halite you play in a space scenario comprising <em>ships</em> and <em>planets</em>, while you (= your bot) controls your ships. A ship can do three actions: <em>move</em>, <em>dock</em> to or <em>undock</em> from a planet. The more ships you have docked at a planet, the faster you are <em>mining</em> the planet, which means to produce new ships. When two ships get close enough, they can fight and only the winnerâ€™s ship survives. The game is turn-based, so each of the up to four playersâ€™ programs are queried (by the game environment) for a list of moves for each of their ships in every turn. Input is the current game state (player- &amp; planet positions, shipsâ€™ health, shipsâ€™ current status, â€¦) and output is a move for each ship. The final goal is to either completely dominate (= destroy every other playersâ€™ ships) or own the strongest ship fleet and the most planets after 300 turns. </p>\n<p>At the time of writing this article, the leaderboard comprises <strong>~ 4700 players</strong> from <strong>98 countries</strong>. Most of them are either university students or professionals, who have, in total, played <strong>10.9 million</strong> games. More interesting statistics can be found at the <a href=\"http://stats.halite.io:3000/public/dashboard/545ebc3c-4cdb-4940-acf1-e4d1332defac\" target=\"_blank\" rel=\"noopener\">stats</a> page. </p>\n<h2 id=\"My-bot\"><a href=\"#My-bot\" class=\"headerlink\" title=\"My bot\"></a>My bot</h2><p>First of all, what I found especially cool is the fact that players are completely free in their choice of how to realize their bot (hard-coding, machine learning, â€¦) and what programming language to use. Halite offers community-created starter templates for C++, C#, Dart, Elixir, Go, Haskell, JavaScript, Julia, Kotlin, PHP, Ruby, Rust, Scala, Swift and more. You can choose whatever language you like - which was <strong>Java</strong> for me - and eventually submit a ZIP file with your code or binary, as well as a script for executing it, to their website. The interface between your program and the game environment is <em>stdin</em> / <em>stdout</em>. </p>\n<p><img src=\"images/halite_langs.png\" alt=\"\"></p>\n<p>I decided to build my bot based on rather simple rules first, which I figured out by watching some other playersâ€™ replays. Probably applying machine learning to solve Halite would be even more challenging, but at the time I got aware of this competition, it was about to last only three more weeks (until January, 22nd), so I picked up on a rather simple approach.</p>\n<h2 id=\"Strategies\"><a href=\"#Strategies\" class=\"headerlink\" title=\"Strategies\"></a>Strategies</h2><p>I developed three different strategies for playing Halite, while my bot could dynamically switch between them during the game. The first one is called the <strong>BalancedStrategy</strong>. Itâ€™s a fair mixture of conquering new planets, raising ship production and destroying enemy ships. In this strategy, a shipâ€™s most preferable goal is to take empty planets. However, if the next empty planet is unavailable ot too far away, it may also dock at a planet my bot already owns in order to increase production. However, no more than three of my own ships will ever dock at the same planet. If both the next empty planet as well as the next own planet are unavailable or too far away, the ship starts chasing the nearest enemy ship. </p>\n<p>In addition to this compromise-like strategy, I found that more extreme ones can be successful, too. For instance, in a 1 vs. 1 match, my opponents usually won because they almost instantly destroyed all of my ships in the very beginning. So I decided to further introduce the <strong>AggressiveStrategy</strong>, which is only applied in matched of two players. Following this strategy, all of my three initial ships immediately start chasing the enemyâ€™s three ships. If theyâ€™re successful, the game is usually over after only a few turns. </p>\n<p>Finally I built the <strong>MiningStrategy</strong>. Goal is to maxmimize mining rate right in the beginning. My three ships are immediately docking at the nearest and largest (in terms of how many ships can dock at it) free planet and dock at it. New ships will dock at the same planet until itâ€™s full. Doing so, I can quickly produce new ships which then, after the first planet is full, switch over to applying the <strong>BalancedStrategy</strong>. </p>\n<h2 id=\"Results\"><a href=\"#Results\" class=\"headerlink\" title=\"Results\"></a>Results</h2><p>Using the bot described above, the best rank I achieved in the leaderboard was <strong>250 of ~ 4500</strong> (top 6 %) and Iâ€™m still ambitious to get even better ðŸ˜ƒ. My bot is playing as <a href=\"https://halite.io/user/?user_id=7481\" target=\"_blank\" rel=\"noopener\">n1try</a>.</p>\n<p>>&gt; <a href=\"https://github.com/n1try/halite-bot-java\" target=\"_blank\" rel=\"noopener\">Source code on GitHub</a>. </p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<p>After having spent a considerable amount of time with it last weekend, I wanted to make a short comment on <a href=\"https://halite.io\" target=\"_blank\" rel=\"noopener\">Halite.io</a>. Halite is a programming- and AI competition where people can write programs or train algorithms to control a bot that plays in a virtual 2D game environment. There is a leaderboard to track how your bot competes with other playersâ€™ bots and you can watch a replay of every game your bot has played, which helps <em>debugging</em> your bot as well as figuring out other peopleâ€™s strategies. Originally, I got aware of this challenge through a video by <a href=\"https://www.youtube.com/channel/UCfzlCWGWYyIQ0aLC5w48gBQ\" target=\"_blank\" rel=\"noopener\">one of my favorite</a> YouTube channels and became slightly addicted from that moment on. </p>\n<h2 id=\"The-Game\"><a href=\"#The-Game\" class=\"headerlink\" title=\"The Game\"></a>The Game</h2><p><img src=\"images/halite_game.png\" alt=\"\"></p>\n<p>While the complete rule set of Halite can be viewed in <a href=\"https://halite.io/learn-programming-challenge/\" target=\"_blank\" rel=\"noopener\">their documentation</a>, I only want to explain very basics here. In Halite you play in a space scenario comprising <em>ships</em> and <em>planets</em>, while you (= your bot) controls your ships. A ship can do three actions: <em>move</em>, <em>dock</em> to or <em>undock</em> from a planet. The more ships you have docked at a planet, the faster you are <em>mining</em> the planet, which means to produce new ships. When two ships get close enough, they can fight and only the winnerâ€™s ship survives. The game is turn-based, so each of the up to four playersâ€™ programs are queried (by the game environment) for a list of moves for each of their ships in every turn. Input is the current game state (player- &amp; planet positions, shipsâ€™ health, shipsâ€™ current status, â€¦) and output is a move for each ship. The final goal is to either completely dominate (= destroy every other playersâ€™ ships) or own the strongest ship fleet and the most planets after 300 turns. </p>\n<p>At the time of writing this article, the leaderboard comprises <strong>~ 4700 players</strong> from <strong>98 countries</strong>. Most of them are either university students or professionals, who have, in total, played <strong>10.9 million</strong> games. More interesting statistics can be found at the <a href=\"http://stats.halite.io:3000/public/dashboard/545ebc3c-4cdb-4940-acf1-e4d1332defac\" target=\"_blank\" rel=\"noopener\">stats</a> page. </p>\n<h2 id=\"My-bot\"><a href=\"#My-bot\" class=\"headerlink\" title=\"My bot\"></a>My bot</h2><p>First of all, what I found especially cool is the fact that players are completely free in their choice of how to realize their bot (hard-coding, machine learning, â€¦) and what programming language to use. Halite offers community-created starter templates for C++, C#, Dart, Elixir, Go, Haskell, JavaScript, Julia, Kotlin, PHP, Ruby, Rust, Scala, Swift and more. You can choose whatever language you like - which was <strong>Java</strong> for me - and eventually submit a ZIP file with your code or binary, as well as a script for executing it, to their website. The interface between your program and the game environment is <em>stdin</em> / <em>stdout</em>. </p>\n<p><img src=\"images/halite_langs.png\" alt=\"\"></p>\n<p>I decided to build my bot based on rather simple rules first, which I figured out by watching some other playersâ€™ replays. Probably applying machine learning to solve Halite would be even more challenging, but at the time I got aware of this competition, it was about to last only three more weeks (until January, 22nd), so I picked up on a rather simple approach.</p>\n<h2 id=\"Strategies\"><a href=\"#Strategies\" class=\"headerlink\" title=\"Strategies\"></a>Strategies</h2><p>I developed three different strategies for playing Halite, while my bot could dynamically switch between them during the game. The first one is called the <strong>BalancedStrategy</strong>. Itâ€™s a fair mixture of conquering new planets, raising ship production and destroying enemy ships. In this strategy, a shipâ€™s most preferable goal is to take empty planets. However, if the next empty planet is unavailable ot too far away, it may also dock at a planet my bot already owns in order to increase production. However, no more than three of my own ships will ever dock at the same planet. If both the next empty planet as well as the next own planet are unavailable or too far away, the ship starts chasing the nearest enemy ship. </p>\n<p>In addition to this compromise-like strategy, I found that more extreme ones can be successful, too. For instance, in a 1 vs. 1 match, my opponents usually won because they almost instantly destroyed all of my ships in the very beginning. So I decided to further introduce the <strong>AggressiveStrategy</strong>, which is only applied in matched of two players. Following this strategy, all of my three initial ships immediately start chasing the enemyâ€™s three ships. If theyâ€™re successful, the game is usually over after only a few turns. </p>\n<p>Finally I built the <strong>MiningStrategy</strong>. Goal is to maxmimize mining rate right in the beginning. My three ships are immediately docking at the nearest and largest (in terms of how many ships can dock at it) free planet and dock at it. New ships will dock at the same planet until itâ€™s full. Doing so, I can quickly produce new ships which then, after the first planet is full, switch over to applying the <strong>BalancedStrategy</strong>. </p>\n<h2 id=\"Results\"><a href=\"#Results\" class=\"headerlink\" title=\"Results\"></a>Results</h2><p>Using the bot described above, the best rank I achieved in the leaderboard was <strong>250 of ~ 4500</strong> (top 6 %) and Iâ€™m still ambitious to get even better ðŸ˜ƒ. My bot is playing as <a href=\"https://halite.io/user/?user_id=7481\" target=\"_blank\" rel=\"noopener\">n1try</a>.</p>\n<p>>&gt; <a href=\"https://github.com/n1try/halite-bot-java\" target=\"_blank\" rel=\"noopener\">Source code on GitHub</a>. </p>\n"},{"title":"How do WhatsAppâ€™s end-to-end encrypted group chats work?","date":"2016-04-07T20:56:43.000Z","_content":"\n![WhatsApp_Logo](/images/whatsapp_logo.png)\n\nA few days ago WhatsApp has announced end-to-end encryption for all chats, which basically means, that messages are encrypted in a way that nobody except for the recipient can read a message. Previously only the communication channels between you and the server and between the server and your chat partner were encrypted, but the messages lay in clear text form on the server (though in case of WhatsApp not persistently stored).  \nEvery end-to-end encryption is based on asymmetric cryptography methods, where a private and a public key exist. Messages encrypted with the public key can only be decrypted using the respective private key and the other way round. The private key is always kept private (as the name implies) and should never ever leave the userâ€™s device, while the public key is sent to every chat partner, who will use it for messages addressed to you. No one without your private key will every be able to read them. In turn you are in posession of your chat partnersâ€™ public keys to send secure messages to them. So far so good, but thereâ€™s a problem with group chats.  \nAssume a group with three members, you (A), B and C. B (C) can only read messages signed with pubkey_B (pubkey_C). This would mean you had to encrypt the message twice, once with each public key. As a consequence you would also have to send it twice, which make your traffic for group messaging increase linearly with the amount of group members. Traditionally you only had to send the exact same message to the server once, who then did a fanout to all group members. Now you would have to send x (number of group members) different (since differently encrypted) messages, which isnâ€™t a too good solution, since it will increase your mobile data traffic amount. [Threema does it that way anyway](https://threema.ch/press-files/cryptography_whitepaper.pdf). WhatApp takes another approach that I will explained a little simplified.\n\nAccording to their [Whitepaper of crypthography](https://www.whatsapp.com/security/WhatsApp-Security-Whitepaper.pdf) it works roughly as follows:  \n1\\. When joining a group you generate a group-specific key-pair, which we call myGroupPubkey and myGroupPrivkey from now on.  \n2\\. You encrypt it individually with every other group memberâ€™s public key (similar as you would do with a normal message) and send it to them. This is a client-side fanout where you actually send as many messages as there are members in the group, but itâ€™s acceptable since it only happens once when joining a new group, not every time sending a message.  \n3\\. The partners encrypt this key-message using their respective private keys and get your myGroupPubkey out.  \n4\\. You encrypt every subsequent message using myGroupPrivkey (note that traditionally you encrypt messages using the partnerâ€™s public key while now you encrypt them using your private key) and send it to the server (who canâ€™t read it) to fan it out to the group.  \n5\\. Every group members uses your myGroupPubkey to decrypt is.\n\nIt is important to note that you encrypt with your private key, which it is usually not intended for (biut technically perfectly capable of), since it is unsecure in the way that everyone with your public key could read the message payload. The sticking point is that since this public key is transferred in asymmetrically encrypted form it is safe that only group members are in possession of it. If a group changes, those keys are re-generated.\n\nTo be precise, this is only a simplified description but it explains the fundamental concept. For instance, besides other technical details the messages are actually first encrypted symmetrically and then signed asymmetrically.\n\nDisclaimer: There is no guarantee for correctness of this explanation at all. This is how I have understood the process, but that doesnâ€™t mean it is actually true. Do not rely on this. If youâ€™re from a cryptographical background, have read the official Whitepaper and are of the opinion that I understood anything from please let me know.","source":"_posts/how-do-whatsapps-end-to-end-encrypted-group-chats-work.md","raw":"---\ntitle: How do WhatsAppâ€™s end-to-end encrypted group chats work?\ndate: 2016-04-07 22:56:43\ntags:\n---\n\n![WhatsApp_Logo](/images/whatsapp_logo.png)\n\nA few days ago WhatsApp has announced end-to-end encryption for all chats, which basically means, that messages are encrypted in a way that nobody except for the recipient can read a message. Previously only the communication channels between you and the server and between the server and your chat partner were encrypted, but the messages lay in clear text form on the server (though in case of WhatsApp not persistently stored).  \nEvery end-to-end encryption is based on asymmetric cryptography methods, where a private and a public key exist. Messages encrypted with the public key can only be decrypted using the respective private key and the other way round. The private key is always kept private (as the name implies) and should never ever leave the userâ€™s device, while the public key is sent to every chat partner, who will use it for messages addressed to you. No one without your private key will every be able to read them. In turn you are in posession of your chat partnersâ€™ public keys to send secure messages to them. So far so good, but thereâ€™s a problem with group chats.  \nAssume a group with three members, you (A), B and C. B (C) can only read messages signed with pubkey_B (pubkey_C). This would mean you had to encrypt the message twice, once with each public key. As a consequence you would also have to send it twice, which make your traffic for group messaging increase linearly with the amount of group members. Traditionally you only had to send the exact same message to the server once, who then did a fanout to all group members. Now you would have to send x (number of group members) different (since differently encrypted) messages, which isnâ€™t a too good solution, since it will increase your mobile data traffic amount. [Threema does it that way anyway](https://threema.ch/press-files/cryptography_whitepaper.pdf). WhatApp takes another approach that I will explained a little simplified.\n\nAccording to their [Whitepaper of crypthography](https://www.whatsapp.com/security/WhatsApp-Security-Whitepaper.pdf) it works roughly as follows:  \n1\\. When joining a group you generate a group-specific key-pair, which we call myGroupPubkey and myGroupPrivkey from now on.  \n2\\. You encrypt it individually with every other group memberâ€™s public key (similar as you would do with a normal message) and send it to them. This is a client-side fanout where you actually send as many messages as there are members in the group, but itâ€™s acceptable since it only happens once when joining a new group, not every time sending a message.  \n3\\. The partners encrypt this key-message using their respective private keys and get your myGroupPubkey out.  \n4\\. You encrypt every subsequent message using myGroupPrivkey (note that traditionally you encrypt messages using the partnerâ€™s public key while now you encrypt them using your private key) and send it to the server (who canâ€™t read it) to fan it out to the group.  \n5\\. Every group members uses your myGroupPubkey to decrypt is.\n\nIt is important to note that you encrypt with your private key, which it is usually not intended for (biut technically perfectly capable of), since it is unsecure in the way that everyone with your public key could read the message payload. The sticking point is that since this public key is transferred in asymmetrically encrypted form it is safe that only group members are in possession of it. If a group changes, those keys are re-generated.\n\nTo be precise, this is only a simplified description but it explains the fundamental concept. For instance, besides other technical details the messages are actually first encrypted symmetrically and then signed asymmetrically.\n\nDisclaimer: There is no guarantee for correctness of this explanation at all. This is how I have understood the process, but that doesnâ€™t mean it is actually true. Do not rely on this. If youâ€™re from a cryptographical background, have read the official Whitepaper and are of the opinion that I understood anything from please let me know.","slug":"how-do-whatsapps-end-to-end-encrypted-group-chats-work","published":1,"updated":"2018-03-19T09:30:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2gioly000acxrgs8gcswim","content":"<p><img src=\"/images/whatsapp_logo.png\" alt=\"WhatsApp_Logo\"></p>\n<p>A few days ago WhatsApp has announced end-to-end encryption for all chats, which basically means, that messages are encrypted in a way that nobody except for the recipient can read a message. Previously only the communication channels between you and the server and between the server and your chat partner were encrypted, but the messages lay in clear text form on the server (though in case of WhatsApp not persistently stored).<br>Every end-to-end encryption is based on asymmetric cryptography methods, where a private and a public key exist. Messages encrypted with the public key can only be decrypted using the respective private key and the other way round. The private key is always kept private (as the name implies) and should never ever leave the userâ€™s device, while the public key is sent to every chat partner, who will use it for messages addressed to you. No one without your private key will every be able to read them. In turn you are in posession of your chat partnersâ€™ public keys to send secure messages to them. So far so good, but thereâ€™s a problem with group chats.<br>Assume a group with three members, you (A), B and C. B (C) can only read messages signed with pubkey_B (pubkey_C). This would mean you had to encrypt the message twice, once with each public key. As a consequence you would also have to send it twice, which make your traffic for group messaging increase linearly with the amount of group members. Traditionally you only had to send the exact same message to the server once, who then did a fanout to all group members. Now you would have to send x (number of group members) different (since differently encrypted) messages, which isnâ€™t a too good solution, since it will increase your mobile data traffic amount. <a href=\"https://threema.ch/press-files/cryptography_whitepaper.pdf\" target=\"_blank\" rel=\"noopener\">Threema does it that way anyway</a>. WhatApp takes another approach that I will explained a little simplified.</p>\n<p>According to their <a href=\"https://www.whatsapp.com/security/WhatsApp-Security-Whitepaper.pdf\" target=\"_blank\" rel=\"noopener\">Whitepaper of crypthography</a> it works roughly as follows:<br>1. When joining a group you generate a group-specific key-pair, which we call myGroupPubkey and myGroupPrivkey from now on.<br>2. You encrypt it individually with every other group memberâ€™s public key (similar as you would do with a normal message) and send it to them. This is a client-side fanout where you actually send as many messages as there are members in the group, but itâ€™s acceptable since it only happens once when joining a new group, not every time sending a message.<br>3. The partners encrypt this key-message using their respective private keys and get your myGroupPubkey out.<br>4. You encrypt every subsequent message using myGroupPrivkey (note that traditionally you encrypt messages using the partnerâ€™s public key while now you encrypt them using your private key) and send it to the server (who canâ€™t read it) to fan it out to the group.<br>5. Every group members uses your myGroupPubkey to decrypt is.</p>\n<p>It is important to note that you encrypt with your private key, which it is usually not intended for (biut technically perfectly capable of), since it is unsecure in the way that everyone with your public key could read the message payload. The sticking point is that since this public key is transferred in asymmetrically encrypted form it is safe that only group members are in possession of it. If a group changes, those keys are re-generated.</p>\n<p>To be precise, this is only a simplified description but it explains the fundamental concept. For instance, besides other technical details the messages are actually first encrypted symmetrically and then signed asymmetrically.</p>\n<p>Disclaimer: There is no guarantee for correctness of this explanation at all. This is how I have understood the process, but that doesnâ€™t mean it is actually true. Do not rely on this. If youâ€™re from a cryptographical background, have read the official Whitepaper and are of the opinion that I understood anything from please let me know.</p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<p><img src=\"/images/whatsapp_logo.png\" alt=\"WhatsApp_Logo\"></p>\n<p>A few days ago WhatsApp has announced end-to-end encryption for all chats, which basically means, that messages are encrypted in a way that nobody except for the recipient can read a message. Previously only the communication channels between you and the server and between the server and your chat partner were encrypted, but the messages lay in clear text form on the server (though in case of WhatsApp not persistently stored).<br>Every end-to-end encryption is based on asymmetric cryptography methods, where a private and a public key exist. Messages encrypted with the public key can only be decrypted using the respective private key and the other way round. The private key is always kept private (as the name implies) and should never ever leave the userâ€™s device, while the public key is sent to every chat partner, who will use it for messages addressed to you. No one without your private key will every be able to read them. In turn you are in posession of your chat partnersâ€™ public keys to send secure messages to them. So far so good, but thereâ€™s a problem with group chats.<br>Assume a group with three members, you (A), B and C. B (C) can only read messages signed with pubkey_B (pubkey_C). This would mean you had to encrypt the message twice, once with each public key. As a consequence you would also have to send it twice, which make your traffic for group messaging increase linearly with the amount of group members. Traditionally you only had to send the exact same message to the server once, who then did a fanout to all group members. Now you would have to send x (number of group members) different (since differently encrypted) messages, which isnâ€™t a too good solution, since it will increase your mobile data traffic amount. <a href=\"https://threema.ch/press-files/cryptography_whitepaper.pdf\" target=\"_blank\" rel=\"noopener\">Threema does it that way anyway</a>. WhatApp takes another approach that I will explained a little simplified.</p>\n<p>According to their <a href=\"https://www.whatsapp.com/security/WhatsApp-Security-Whitepaper.pdf\" target=\"_blank\" rel=\"noopener\">Whitepaper of crypthography</a> it works roughly as follows:<br>1. When joining a group you generate a group-specific key-pair, which we call myGroupPubkey and myGroupPrivkey from now on.<br>2. You encrypt it individually with every other group memberâ€™s public key (similar as you would do with a normal message) and send it to them. This is a client-side fanout where you actually send as many messages as there are members in the group, but itâ€™s acceptable since it only happens once when joining a new group, not every time sending a message.<br>3. The partners encrypt this key-message using their respective private keys and get your myGroupPubkey out.<br>4. You encrypt every subsequent message using myGroupPrivkey (note that traditionally you encrypt messages using the partnerâ€™s public key while now you encrypt them using your private key) and send it to the server (who canâ€™t read it) to fan it out to the group.<br>5. Every group members uses your myGroupPubkey to decrypt is.</p>\n<p>It is important to note that you encrypt with your private key, which it is usually not intended for (biut technically perfectly capable of), since it is unsecure in the way that everyone with your public key could read the message payload. The sticking point is that since this public key is transferred in asymmetrically encrypted form it is safe that only group members are in possession of it. If a group changes, those keys are re-generated.</p>\n<p>To be precise, this is only a simplified description but it explains the fundamental concept. For instance, besides other technical details the messages are actually first encrypted symmetrically and then signed asymmetrically.</p>\n<p>Disclaimer: There is no guarantee for correctness of this explanation at all. This is how I have understood the process, but that doesnâ€™t mean it is actually true. Do not rely on this. If youâ€™re from a cryptographical background, have read the official Whitepaper and are of the opinion that I understood anything from please let me know.</p>\n"},{"title":"How to load Yago into Apache Jena / Fuseki","date":"2016-11-11T22:04:09.000Z","_content":"\nThis article describes how to load the [Yago](http://yago-knowledge.org) Linked Data knowledge collection into an [Apache Jena](https://jena.apache.org/) triple store database on Windows 10 as well as on Linux.\n\n1. At very first, please make sure you have Java 8 Runtime Environment installed on your system.\n\n2. Download all Yago graphs you need from the [downloads section](http://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/yago-naga/yago/downloads/) as .ttl files. In my case I took all graphs from _TAXONOMY_, _CORE_ and additonally the _yagoDBpediaInstances_ and _yagoDBpediaClasses_ collections to have relations from Yago entities to DBpedia ones. Download the files to a folder on your system, let's say `/home/ferdinand/yago/` on Linux or `C:\\Users\\Ferdinand\\yago` on Windows and extract them using 7zip.\n\n3. Delete all `.7z` files.\n\n4. Download `apache-jena-3.1.1.zip` (or newer version) and `apache-jena-fuseki-2.4.1.zip` from [here](https://jena.apache.org/download/index.cgi) and extract them to, let's say `/home/ferdinand/jena/` and `/home/ferdinand/fuseki/` (or the analogue directories on Windows).\n\n5. Now the .ttl files needs to get some kind of preprocessed, where non-unicode characters are replaced in order for Jena to accept the data. On Linux run `sed -i 's/|/-/g' ./* && sed -i 's/\\\\\\\\/-/g' ./* && sed -i 's/â€“/-/g' ./*` from within the directory where your .ttl files are. On Windows, start the Ubuntu Bash, navigate to the respective directory (e.g. `/mnt/c/Users/Ferdinand/yago`) and do the same command. It will take several minutes. I mean, really several...\n\n6. Create a folder to be used for the database later, e.g. `/home/ferdinand/yago/data`.\n\n7. Add the Fuseki root directory (e.g. `/home/ferdinand/fuseki`) and the Jena _bin_ (or _bat_ on Win) (e.g. `/home/ferdinand/jena/bin`) to your `PATH` environment variable. On Linux you would do this by editing your `~/.bash_profile`, on Windows you can search for _\"envionment variables\"_ and then use the Windows system settings dialog.\n\n7. Load the graphs using _tdbloader_: `tdbloader.bat --loc data ./*` from the directory where your .ttl files are located. This may take several hours. Not joking...\n\n8. Start Fuseki typing `java -jar fuseki-server.jar --update --loc /home/ferdinand/yago/data /myGraph` to run fuseki with your entire Yago graph available under the _myGraph_ alias.\n\n9. Open [http://localhost:3030](http://localhost:3030) in your browser and start making queries.\n\nIf you're about to run really expensive queries, consider the following.\n\n1. Set the `JVM_ARGS` environment variable to `-Xms512m -Xmx2048M -XX:-UseGCOverheadLimit -XX:+UseParallelGC`. This will basically prevent you from getting _OutOfMemory_ errors.\n\n2. Use _tdbquery_ since it might be a little more performant than the web SPARQL endpoint. An example _tdbquery_ command might look like this, assuming you have a file `q.txt` that contains your SPARQL query: `tdbquery --loc=/home/ferdinand/yago/data --time --results=CSV --query=q.txt > output.txt`","source":"_posts/how-to-load-yago-into-apache-jena-fuseki.md","raw":"---\ntitle: How to load Yago into Apache Jena / Fuseki\ndate: 2016-11-11 23:04:09\ntags:\n---\n\nThis article describes how to load the [Yago](http://yago-knowledge.org) Linked Data knowledge collection into an [Apache Jena](https://jena.apache.org/) triple store database on Windows 10 as well as on Linux.\n\n1. At very first, please make sure you have Java 8 Runtime Environment installed on your system.\n\n2. Download all Yago graphs you need from the [downloads section](http://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/yago-naga/yago/downloads/) as .ttl files. In my case I took all graphs from _TAXONOMY_, _CORE_ and additonally the _yagoDBpediaInstances_ and _yagoDBpediaClasses_ collections to have relations from Yago entities to DBpedia ones. Download the files to a folder on your system, let's say `/home/ferdinand/yago/` on Linux or `C:\\Users\\Ferdinand\\yago` on Windows and extract them using 7zip.\n\n3. Delete all `.7z` files.\n\n4. Download `apache-jena-3.1.1.zip` (or newer version) and `apache-jena-fuseki-2.4.1.zip` from [here](https://jena.apache.org/download/index.cgi) and extract them to, let's say `/home/ferdinand/jena/` and `/home/ferdinand/fuseki/` (or the analogue directories on Windows).\n\n5. Now the .ttl files needs to get some kind of preprocessed, where non-unicode characters are replaced in order for Jena to accept the data. On Linux run `sed -i 's/|/-/g' ./* && sed -i 's/\\\\\\\\/-/g' ./* && sed -i 's/â€“/-/g' ./*` from within the directory where your .ttl files are. On Windows, start the Ubuntu Bash, navigate to the respective directory (e.g. `/mnt/c/Users/Ferdinand/yago`) and do the same command. It will take several minutes. I mean, really several...\n\n6. Create a folder to be used for the database later, e.g. `/home/ferdinand/yago/data`.\n\n7. Add the Fuseki root directory (e.g. `/home/ferdinand/fuseki`) and the Jena _bin_ (or _bat_ on Win) (e.g. `/home/ferdinand/jena/bin`) to your `PATH` environment variable. On Linux you would do this by editing your `~/.bash_profile`, on Windows you can search for _\"envionment variables\"_ and then use the Windows system settings dialog.\n\n7. Load the graphs using _tdbloader_: `tdbloader.bat --loc data ./*` from the directory where your .ttl files are located. This may take several hours. Not joking...\n\n8. Start Fuseki typing `java -jar fuseki-server.jar --update --loc /home/ferdinand/yago/data /myGraph` to run fuseki with your entire Yago graph available under the _myGraph_ alias.\n\n9. Open [http://localhost:3030](http://localhost:3030) in your browser and start making queries.\n\nIf you're about to run really expensive queries, consider the following.\n\n1. Set the `JVM_ARGS` environment variable to `-Xms512m -Xmx2048M -XX:-UseGCOverheadLimit -XX:+UseParallelGC`. This will basically prevent you from getting _OutOfMemory_ errors.\n\n2. Use _tdbquery_ since it might be a little more performant than the web SPARQL endpoint. An example _tdbquery_ command might look like this, assuming you have a file `q.txt` that contains your SPARQL query: `tdbquery --loc=/home/ferdinand/yago/data --time --results=CSV --query=q.txt > output.txt`","slug":"how-to-load-yago-into-apache-jena-fuseki","published":1,"updated":"2018-03-19T09:30:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2giom0000bcxrg88o56xy2","content":"<p>This article describes how to load the <a href=\"http://yago-knowledge.org\" target=\"_blank\" rel=\"noopener\">Yago</a> Linked Data knowledge collection into an <a href=\"https://jena.apache.org/\" target=\"_blank\" rel=\"noopener\">Apache Jena</a> triple store database on Windows 10 as well as on Linux.</p>\n<ol>\n<li><p>At very first, please make sure you have Java 8 Runtime Environment installed on your system.</p>\n</li>\n<li><p>Download all Yago graphs you need from the <a href=\"http://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/yago-naga/yago/downloads/\" target=\"_blank\" rel=\"noopener\">downloads section</a> as .ttl files. In my case I took all graphs from <em>TAXONOMY</em>, <em>CORE</em> and additonally the <em>yagoDBpediaInstances</em> and <em>yagoDBpediaClasses</em> collections to have relations from Yago entities to DBpedia ones. Download the files to a folder on your system, letâ€™s say <code>/home/ferdinand/yago/</code> on Linux or <code>C:\\Users\\Ferdinand\\yago</code> on Windows and extract them using 7zip.</p>\n</li>\n<li><p>Delete all <code>.7z</code> files.</p>\n</li>\n<li><p>Download <code>apache-jena-3.1.1.zip</code> (or newer version) and <code>apache-jena-fuseki-2.4.1.zip</code> from <a href=\"https://jena.apache.org/download/index.cgi\" target=\"_blank\" rel=\"noopener\">here</a> and extract them to, letâ€™s say <code>/home/ferdinand/jena/</code> and <code>/home/ferdinand/fuseki/</code> (or the analogue directories on Windows).</p>\n</li>\n<li><p>Now the .ttl files needs to get some kind of preprocessed, where non-unicode characters are replaced in order for Jena to accept the data. On Linux run <code>sed -i &#39;s/|/-/g&#39; ./* &amp;&amp; sed -i &#39;s/\\\\\\\\/-/g&#39; ./* &amp;&amp; sed -i &#39;s/â€“/-/g&#39; ./*</code> from within the directory where your .ttl files are. On Windows, start the Ubuntu Bash, navigate to the respective directory (e.g. <code>/mnt/c/Users/Ferdinand/yago</code>) and do the same command. It will take several minutes. I mean, really severalâ€¦</p>\n</li>\n<li><p>Create a folder to be used for the database later, e.g. <code>/home/ferdinand/yago/data</code>.</p>\n</li>\n<li><p>Add the Fuseki root directory (e.g. <code>/home/ferdinand/fuseki</code>) and the Jena <em>bin</em> (or <em>bat</em> on Win) (e.g. <code>/home/ferdinand/jena/bin</code>) to your <code>PATH</code> environment variable. On Linux you would do this by editing your <code>~/.bash_profile</code>, on Windows you can search for <em>â€œenvionment variablesâ€</em> and then use the Windows system settings dialog.</p>\n</li>\n<li><p>Load the graphs using <em>tdbloader</em>: <code>tdbloader.bat --loc data ./*</code> from the directory where your .ttl files are located. This may take several hours. Not jokingâ€¦</p>\n</li>\n<li><p>Start Fuseki typing <code>java -jar fuseki-server.jar --update --loc /home/ferdinand/yago/data /myGraph</code> to run fuseki with your entire Yago graph available under the <em>myGraph</em> alias.</p>\n</li>\n<li><p>Open <a href=\"http://localhost:3030\" target=\"_blank\" rel=\"noopener\">http://localhost:3030</a> in your browser and start making queries.</p>\n</li>\n</ol>\n<p>If youâ€™re about to run really expensive queries, consider the following.</p>\n<ol>\n<li><p>Set the <code>JVM_ARGS</code> environment variable to <code>-Xms512m -Xmx2048M -XX:-UseGCOverheadLimit -XX:+UseParallelGC</code>. This will basically prevent you from getting <em>OutOfMemory</em> errors.</p>\n</li>\n<li><p>Use <em>tdbquery</em> since it might be a little more performant than the web SPARQL endpoint. An example <em>tdbquery</em> command might look like this, assuming you have a file <code>q.txt</code> that contains your SPARQL query: <code>tdbquery --loc=/home/ferdinand/yago/data --time --results=CSV --query=q.txt &gt; output.txt</code></p>\n</li>\n</ol>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<p>This article describes how to load the <a href=\"http://yago-knowledge.org\" target=\"_blank\" rel=\"noopener\">Yago</a> Linked Data knowledge collection into an <a href=\"https://jena.apache.org/\" target=\"_blank\" rel=\"noopener\">Apache Jena</a> triple store database on Windows 10 as well as on Linux.</p>\n<ol>\n<li><p>At very first, please make sure you have Java 8 Runtime Environment installed on your system.</p>\n</li>\n<li><p>Download all Yago graphs you need from the <a href=\"http://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/yago-naga/yago/downloads/\" target=\"_blank\" rel=\"noopener\">downloads section</a> as .ttl files. In my case I took all graphs from <em>TAXONOMY</em>, <em>CORE</em> and additonally the <em>yagoDBpediaInstances</em> and <em>yagoDBpediaClasses</em> collections to have relations from Yago entities to DBpedia ones. Download the files to a folder on your system, letâ€™s say <code>/home/ferdinand/yago/</code> on Linux or <code>C:\\Users\\Ferdinand\\yago</code> on Windows and extract them using 7zip.</p>\n</li>\n<li><p>Delete all <code>.7z</code> files.</p>\n</li>\n<li><p>Download <code>apache-jena-3.1.1.zip</code> (or newer version) and <code>apache-jena-fuseki-2.4.1.zip</code> from <a href=\"https://jena.apache.org/download/index.cgi\" target=\"_blank\" rel=\"noopener\">here</a> and extract them to, letâ€™s say <code>/home/ferdinand/jena/</code> and <code>/home/ferdinand/fuseki/</code> (or the analogue directories on Windows).</p>\n</li>\n<li><p>Now the .ttl files needs to get some kind of preprocessed, where non-unicode characters are replaced in order for Jena to accept the data. On Linux run <code>sed -i &#39;s/|/-/g&#39; ./* &amp;&amp; sed -i &#39;s/\\\\\\\\/-/g&#39; ./* &amp;&amp; sed -i &#39;s/â€“/-/g&#39; ./*</code> from within the directory where your .ttl files are. On Windows, start the Ubuntu Bash, navigate to the respective directory (e.g. <code>/mnt/c/Users/Ferdinand/yago</code>) and do the same command. It will take several minutes. I mean, really severalâ€¦</p>\n</li>\n<li><p>Create a folder to be used for the database later, e.g. <code>/home/ferdinand/yago/data</code>.</p>\n</li>\n<li><p>Add the Fuseki root directory (e.g. <code>/home/ferdinand/fuseki</code>) and the Jena <em>bin</em> (or <em>bat</em> on Win) (e.g. <code>/home/ferdinand/jena/bin</code>) to your <code>PATH</code> environment variable. On Linux you would do this by editing your <code>~/.bash_profile</code>, on Windows you can search for <em>â€œenvionment variablesâ€</em> and then use the Windows system settings dialog.</p>\n</li>\n<li><p>Load the graphs using <em>tdbloader</em>: <code>tdbloader.bat --loc data ./*</code> from the directory where your .ttl files are located. This may take several hours. Not jokingâ€¦</p>\n</li>\n<li><p>Start Fuseki typing <code>java -jar fuseki-server.jar --update --loc /home/ferdinand/yago/data /myGraph</code> to run fuseki with your entire Yago graph available under the <em>myGraph</em> alias.</p>\n</li>\n<li><p>Open <a href=\"http://localhost:3030\" target=\"_blank\" rel=\"noopener\">http://localhost:3030</a> in your browser and start making queries.</p>\n</li>\n</ol>\n<p>If youâ€™re about to run really expensive queries, consider the following.</p>\n<ol>\n<li><p>Set the <code>JVM_ARGS</code> environment variable to <code>-Xms512m -Xmx2048M -XX:-UseGCOverheadLimit -XX:+UseParallelGC</code>. This will basically prevent you from getting <em>OutOfMemory</em> errors.</p>\n</li>\n<li><p>Use <em>tdbquery</em> since it might be a little more performant than the web SPARQL endpoint. An example <em>tdbquery</em> command might look like this, assuming you have a file <code>q.txt</code> that contains your SPARQL query: <code>tdbquery --loc=/home/ferdinand/yago/data --time --results=CSV --query=q.txt &gt; output.txt</code></p>\n</li>\n</ol>\n"},{"title":"Http performance Java (Jersey) vs. Go vs. NodeJS","date":"2016-11-19T22:06:49.000Z","_content":"\nI developed a very basic benchmark suite to compare different HTTP server's performance. It is inspired by [arcadius/java-rest-api-web-container-benchmark](https://github.com/arcadius/java-rest-api-web-container-benchmark), but uses [h2load](https://github.com/nghttp2/nghttp2#benchmarking-tool) instead of [ab](http://httpd.apache.org/docs/2.4/programs/ab.html).\n\nI implemented four very basic REST APIs with exactly one route each, which exposes a small, static todo list as JSON.\n\n## Server Implementations\n* __Java:__ [Jersey](http://jersey.java.net/) with embedded [Grizzly](https://grizzly.java.net/)\n* __Go:__ Using plain `net/http` package\n* __NodeJS:__ Using plain `http` package\n* __NodeJS:__ Using de-facto standard [Express 4](http://expressjs.com/) framework\n\n## Setup\nMy machine, where the benchmark suite was executed on, has the following specifications.\n\n```\n===CPU:\nmodel name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores\t: 2\nmodel name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores\t: 2\nmodel name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores\t: 2\nmodel name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores\t: 2\n \n===RAM: \n             total       used       free     shared    buffers     cached\nMem:          7.7G       6.3G       1.4G       412M       527M       2.4G\n-/+ buffers/cache:       3.3G       4.3G\nSwap:         5.6G         0B       5.6G\n\n===Java version: \njava version \"1.8.0_101\"\nJava(TM) SE Runtime Environment (build 1.8.0_101-b13)\nJava HotSpot(TM) 64-Bit Server VM (build 25.101-b13, mixed mode)\n \n===OS: \nLinux ferdinand-notebook 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u2 (2016-10-19) x86_64 GNU/Linux\n\n===Node: \nv6.5.0\n\n=== Go:\ngo version go1.7.3 linux/amd64\n```\n\n## Test parameters\nBasically there are three parameters to be varied for the benchmark.\n* The __number of total reqests__ to be performed against the API. I chose to set this to __100,000__\n* The __number of concurrent__ client to make those requests. I chose to have __32__ concurrent clients, each of them making 3,125 requests.\n* The __number of threads__ to be used by _h2load_. I set this parameter to four, corresponding to the number of logical CPU cores of my machine.\n\n## Results\nRunning my [benchmark script](https://github.com/n1try/http-server-benchmarks/blob/master/run-load.sh) delivered the following results.\n\n![](images/benchmarks.svg)\n\n## Discussion\nFirst of all, please notice that this is definitely not a 100 % correct, scientifical evaluation. Rather it should give basic insights on the order of magnitute of the performance differences between different language's HTTP servers.\nAs we can clearly see, Go is the fastest candidate among my test subjects. However, my implementation only utilized the plain, built-in http package without any custom ServeMux or any router or middleware on top of it. In a real-world application, one would most likely not operate on such a low level, but use frameworks like [Iris](http://iris-go.com/) on top, which add additional overhead.\n\nSecond place is Java using Grizzly as an embedded server inside a Jersey application. The reason for me picking Grizzly was that it pointed out to be the fastest among the common servers in [this benchmark](http://menelic.com/2016/01/06/java-rest-api-benchmark-tomcat-vs-jetty-vs-grizzly-vs-undertow/).\n\nBoth of my Node implementations perform worst in this benchmark, whereas Express is even only as half as good as the plain http package. Evidently, it introduces quite an amount of overhead. However, one would most likely not implement an actual REST API without a higher-level framework like Express. Consequently, the Express benchmark is probably more representative. \n\nConclusing I can say that I was pretty surprised about how large the differences between various servers are. Go is almost six times as fast as Node with Express, even though [Express still has a very great performance](https://raygun.com/blog/2016/06/node-performance/).\n\nThe full benchmark results as well as the suite's source code can be found at my [GitHub project](https://github.com/n1try/http-server-benchmarks).\n\n## EDIT\nAt January 1st 2017 I did some minor adjustments to my benchmark suite. A thoughtful reader has drawn my attention to the fact that my comparison was a little unfair in the way that Go's net/http as well as Grizzly use as many threads as the host system provides CPU core by default, while Node doesn't. Using Node's `cluster` module I made both Node-based webservers use four listener threads, too and actually the results have improved by around 45 %. Furthermore I did an adjustment to the Jersey + Grizzly server by changing the `IOStrategy` from the default `WorkerThreadIOStrategy` to `SameThreadIOStrategy`, which brought around 10 % in this specific case, where we don't have any blocking computations but only spit out static JSON. If you're interested in leaarning more about different io strategies, refer to [this official documentation page](https://grizzly.java.net/iostrategies.html). Here is my updated benchmark chart.\n\n![](images/benchmarks2.svg)","source":"_posts/http-performance-java-jersey-vs-go-vs-nodejs.md","raw":"---\ntitle: Http performance Java (Jersey) vs. Go vs. NodeJS\ndate: 2016-11-19 23:06:49\ntags:\n---\n\nI developed a very basic benchmark suite to compare different HTTP server's performance. It is inspired by [arcadius/java-rest-api-web-container-benchmark](https://github.com/arcadius/java-rest-api-web-container-benchmark), but uses [h2load](https://github.com/nghttp2/nghttp2#benchmarking-tool) instead of [ab](http://httpd.apache.org/docs/2.4/programs/ab.html).\n\nI implemented four very basic REST APIs with exactly one route each, which exposes a small, static todo list as JSON.\n\n## Server Implementations\n* __Java:__ [Jersey](http://jersey.java.net/) with embedded [Grizzly](https://grizzly.java.net/)\n* __Go:__ Using plain `net/http` package\n* __NodeJS:__ Using plain `http` package\n* __NodeJS:__ Using de-facto standard [Express 4](http://expressjs.com/) framework\n\n## Setup\nMy machine, where the benchmark suite was executed on, has the following specifications.\n\n```\n===CPU:\nmodel name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores\t: 2\nmodel name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores\t: 2\nmodel name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores\t: 2\nmodel name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores\t: 2\n \n===RAM: \n             total       used       free     shared    buffers     cached\nMem:          7.7G       6.3G       1.4G       412M       527M       2.4G\n-/+ buffers/cache:       3.3G       4.3G\nSwap:         5.6G         0B       5.6G\n\n===Java version: \njava version \"1.8.0_101\"\nJava(TM) SE Runtime Environment (build 1.8.0_101-b13)\nJava HotSpot(TM) 64-Bit Server VM (build 25.101-b13, mixed mode)\n \n===OS: \nLinux ferdinand-notebook 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u2 (2016-10-19) x86_64 GNU/Linux\n\n===Node: \nv6.5.0\n\n=== Go:\ngo version go1.7.3 linux/amd64\n```\n\n## Test parameters\nBasically there are three parameters to be varied for the benchmark.\n* The __number of total reqests__ to be performed against the API. I chose to set this to __100,000__\n* The __number of concurrent__ client to make those requests. I chose to have __32__ concurrent clients, each of them making 3,125 requests.\n* The __number of threads__ to be used by _h2load_. I set this parameter to four, corresponding to the number of logical CPU cores of my machine.\n\n## Results\nRunning my [benchmark script](https://github.com/n1try/http-server-benchmarks/blob/master/run-load.sh) delivered the following results.\n\n![](images/benchmarks.svg)\n\n## Discussion\nFirst of all, please notice that this is definitely not a 100 % correct, scientifical evaluation. Rather it should give basic insights on the order of magnitute of the performance differences between different language's HTTP servers.\nAs we can clearly see, Go is the fastest candidate among my test subjects. However, my implementation only utilized the plain, built-in http package without any custom ServeMux or any router or middleware on top of it. In a real-world application, one would most likely not operate on such a low level, but use frameworks like [Iris](http://iris-go.com/) on top, which add additional overhead.\n\nSecond place is Java using Grizzly as an embedded server inside a Jersey application. The reason for me picking Grizzly was that it pointed out to be the fastest among the common servers in [this benchmark](http://menelic.com/2016/01/06/java-rest-api-benchmark-tomcat-vs-jetty-vs-grizzly-vs-undertow/).\n\nBoth of my Node implementations perform worst in this benchmark, whereas Express is even only as half as good as the plain http package. Evidently, it introduces quite an amount of overhead. However, one would most likely not implement an actual REST API without a higher-level framework like Express. Consequently, the Express benchmark is probably more representative. \n\nConclusing I can say that I was pretty surprised about how large the differences between various servers are. Go is almost six times as fast as Node with Express, even though [Express still has a very great performance](https://raygun.com/blog/2016/06/node-performance/).\n\nThe full benchmark results as well as the suite's source code can be found at my [GitHub project](https://github.com/n1try/http-server-benchmarks).\n\n## EDIT\nAt January 1st 2017 I did some minor adjustments to my benchmark suite. A thoughtful reader has drawn my attention to the fact that my comparison was a little unfair in the way that Go's net/http as well as Grizzly use as many threads as the host system provides CPU core by default, while Node doesn't. Using Node's `cluster` module I made both Node-based webservers use four listener threads, too and actually the results have improved by around 45 %. Furthermore I did an adjustment to the Jersey + Grizzly server by changing the `IOStrategy` from the default `WorkerThreadIOStrategy` to `SameThreadIOStrategy`, which brought around 10 % in this specific case, where we don't have any blocking computations but only spit out static JSON. If you're interested in leaarning more about different io strategies, refer to [this official documentation page](https://grizzly.java.net/iostrategies.html). Here is my updated benchmark chart.\n\n![](images/benchmarks2.svg)","slug":"http-performance-java-jersey-vs-go-vs-nodejs","published":1,"updated":"2018-03-19T09:30:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2giom1000ccxrgba16mgct","content":"<p>I developed a very basic benchmark suite to compare different HTTP serverâ€™s performance. It is inspired by <a href=\"https://github.com/arcadius/java-rest-api-web-container-benchmark\" target=\"_blank\" rel=\"noopener\">arcadius/java-rest-api-web-container-benchmark</a>, but uses <a href=\"https://github.com/nghttp2/nghttp2#benchmarking-tool\" target=\"_blank\" rel=\"noopener\">h2load</a> instead of <a href=\"http://httpd.apache.org/docs/2.4/programs/ab.html\" target=\"_blank\" rel=\"noopener\">ab</a>.</p>\n<p>I implemented four very basic REST APIs with exactly one route each, which exposes a small, static todo list as JSON.</p>\n<h2 id=\"Server-Implementations\"><a href=\"#Server-Implementations\" class=\"headerlink\" title=\"Server Implementations\"></a>Server Implementations</h2><ul>\n<li><strong>Java:</strong> <a href=\"http://jersey.java.net/\" target=\"_blank\" rel=\"noopener\">Jersey</a> with embedded <a href=\"https://grizzly.java.net/\" target=\"_blank\" rel=\"noopener\">Grizzly</a></li>\n<li><strong>Go:</strong> Using plain <code>net/http</code> package</li>\n<li><strong>NodeJS:</strong> Using plain <code>http</code> package</li>\n<li><strong>NodeJS:</strong> Using de-facto standard <a href=\"http://expressjs.com/\" target=\"_blank\" rel=\"noopener\">Express 4</a> framework</li>\n</ul>\n<h2 id=\"Setup\"><a href=\"#Setup\" class=\"headerlink\" title=\"Setup\"></a>Setup</h2><p>My machine, where the benchmark suite was executed on, has the following specifications.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">===CPU:</span><br><span class=\"line\">model name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</span><br><span class=\"line\">cpu cores\t: 2</span><br><span class=\"line\">model name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</span><br><span class=\"line\">cpu cores\t: 2</span><br><span class=\"line\">model name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</span><br><span class=\"line\">cpu cores\t: 2</span><br><span class=\"line\">model name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</span><br><span class=\"line\">cpu cores\t: 2</span><br><span class=\"line\"> </span><br><span class=\"line\">===RAM: </span><br><span class=\"line\">             total       used       free     shared    buffers     cached</span><br><span class=\"line\">Mem:          7.7G       6.3G       1.4G       412M       527M       2.4G</span><br><span class=\"line\">-/+ buffers/cache:       3.3G       4.3G</span><br><span class=\"line\">Swap:         5.6G         0B       5.6G</span><br><span class=\"line\"></span><br><span class=\"line\">===Java version: </span><br><span class=\"line\">java version &quot;1.8.0_101&quot;</span><br><span class=\"line\">Java(TM) SE Runtime Environment (build 1.8.0_101-b13)</span><br><span class=\"line\">Java HotSpot(TM) 64-Bit Server VM (build 25.101-b13, mixed mode)</span><br><span class=\"line\"> </span><br><span class=\"line\">===OS: </span><br><span class=\"line\">Linux ferdinand-notebook 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u2 (2016-10-19) x86_64 GNU/Linux</span><br><span class=\"line\"></span><br><span class=\"line\">===Node: </span><br><span class=\"line\">v6.5.0</span><br><span class=\"line\"></span><br><span class=\"line\">=== Go:</span><br><span class=\"line\">go version go1.7.3 linux/amd64</span><br></pre></td></tr></table></figure>\n<h2 id=\"Test-parameters\"><a href=\"#Test-parameters\" class=\"headerlink\" title=\"Test parameters\"></a>Test parameters</h2><p>Basically there are three parameters to be varied for the benchmark.</p>\n<ul>\n<li>The <strong>number of total reqests</strong> to be performed against the API. I chose to set this to <strong>100,000</strong></li>\n<li>The <strong>number of concurrent</strong> client to make those requests. I chose to have <strong>32</strong> concurrent clients, each of them making 3,125 requests.</li>\n<li>The <strong>number of threads</strong> to be used by <em>h2load</em>. I set this parameter to four, corresponding to the number of logical CPU cores of my machine.</li>\n</ul>\n<h2 id=\"Results\"><a href=\"#Results\" class=\"headerlink\" title=\"Results\"></a>Results</h2><p>Running my <a href=\"https://github.com/n1try/http-server-benchmarks/blob/master/run-load.sh\" target=\"_blank\" rel=\"noopener\">benchmark script</a> delivered the following results.</p>\n<p><img src=\"images/benchmarks.svg\" alt=\"\"></p>\n<h2 id=\"Discussion\"><a href=\"#Discussion\" class=\"headerlink\" title=\"Discussion\"></a>Discussion</h2><p>First of all, please notice that this is definitely not a 100 % correct, scientifical evaluation. Rather it should give basic insights on the order of magnitute of the performance differences between different languageâ€™s HTTP servers.<br>As we can clearly see, Go is the fastest candidate among my test subjects. However, my implementation only utilized the plain, built-in http package without any custom ServeMux or any router or middleware on top of it. In a real-world application, one would most likely not operate on such a low level, but use frameworks like <a href=\"http://iris-go.com/\" target=\"_blank\" rel=\"noopener\">Iris</a> on top, which add additional overhead.</p>\n<p>Second place is Java using Grizzly as an embedded server inside a Jersey application. The reason for me picking Grizzly was that it pointed out to be the fastest among the common servers in <a href=\"http://menelic.com/2016/01/06/java-rest-api-benchmark-tomcat-vs-jetty-vs-grizzly-vs-undertow/\" target=\"_blank\" rel=\"noopener\">this benchmark</a>.</p>\n<p>Both of my Node implementations perform worst in this benchmark, whereas Express is even only as half as good as the plain http package. Evidently, it introduces quite an amount of overhead. However, one would most likely not implement an actual REST API without a higher-level framework like Express. Consequently, the Express benchmark is probably more representative. </p>\n<p>Conclusing I can say that I was pretty surprised about how large the differences between various servers are. Go is almost six times as fast as Node with Express, even though <a href=\"https://raygun.com/blog/2016/06/node-performance/\" target=\"_blank\" rel=\"noopener\">Express still has a very great performance</a>.</p>\n<p>The full benchmark results as well as the suiteâ€™s source code can be found at my <a href=\"https://github.com/n1try/http-server-benchmarks\" target=\"_blank\" rel=\"noopener\">GitHub project</a>.</p>\n<h2 id=\"EDIT\"><a href=\"#EDIT\" class=\"headerlink\" title=\"EDIT\"></a>EDIT</h2><p>At January 1st 2017 I did some minor adjustments to my benchmark suite. A thoughtful reader has drawn my attention to the fact that my comparison was a little unfair in the way that Goâ€™s net/http as well as Grizzly use as many threads as the host system provides CPU core by default, while Node doesnâ€™t. Using Nodeâ€™s <code>cluster</code> module I made both Node-based webservers use four listener threads, too and actually the results have improved by around 45 %. Furthermore I did an adjustment to the Jersey + Grizzly server by changing the <code>IOStrategy</code> from the default <code>WorkerThreadIOStrategy</code> to <code>SameThreadIOStrategy</code>, which brought around 10 % in this specific case, where we donâ€™t have any blocking computations but only spit out static JSON. If youâ€™re interested in leaarning more about different io strategies, refer to <a href=\"https://grizzly.java.net/iostrategies.html\" target=\"_blank\" rel=\"noopener\">this official documentation page</a>. Here is my updated benchmark chart.</p>\n<p><img src=\"images/benchmarks2.svg\" alt=\"\"></p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<p>I developed a very basic benchmark suite to compare different HTTP serverâ€™s performance. It is inspired by <a href=\"https://github.com/arcadius/java-rest-api-web-container-benchmark\" target=\"_blank\" rel=\"noopener\">arcadius/java-rest-api-web-container-benchmark</a>, but uses <a href=\"https://github.com/nghttp2/nghttp2#benchmarking-tool\" target=\"_blank\" rel=\"noopener\">h2load</a> instead of <a href=\"http://httpd.apache.org/docs/2.4/programs/ab.html\" target=\"_blank\" rel=\"noopener\">ab</a>.</p>\n<p>I implemented four very basic REST APIs with exactly one route each, which exposes a small, static todo list as JSON.</p>\n<h2 id=\"Server-Implementations\"><a href=\"#Server-Implementations\" class=\"headerlink\" title=\"Server Implementations\"></a>Server Implementations</h2><ul>\n<li><strong>Java:</strong> <a href=\"http://jersey.java.net/\" target=\"_blank\" rel=\"noopener\">Jersey</a> with embedded <a href=\"https://grizzly.java.net/\" target=\"_blank\" rel=\"noopener\">Grizzly</a></li>\n<li><strong>Go:</strong> Using plain <code>net/http</code> package</li>\n<li><strong>NodeJS:</strong> Using plain <code>http</code> package</li>\n<li><strong>NodeJS:</strong> Using de-facto standard <a href=\"http://expressjs.com/\" target=\"_blank\" rel=\"noopener\">Express 4</a> framework</li>\n</ul>\n<h2 id=\"Setup\"><a href=\"#Setup\" class=\"headerlink\" title=\"Setup\"></a>Setup</h2><p>My machine, where the benchmark suite was executed on, has the following specifications.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">===CPU:</span><br><span class=\"line\">model name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</span><br><span class=\"line\">cpu cores\t: 2</span><br><span class=\"line\">model name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</span><br><span class=\"line\">cpu cores\t: 2</span><br><span class=\"line\">model name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</span><br><span class=\"line\">cpu cores\t: 2</span><br><span class=\"line\">model name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</span><br><span class=\"line\">cpu cores\t: 2</span><br><span class=\"line\"> </span><br><span class=\"line\">===RAM: </span><br><span class=\"line\">             total       used       free     shared    buffers     cached</span><br><span class=\"line\">Mem:          7.7G       6.3G       1.4G       412M       527M       2.4G</span><br><span class=\"line\">-/+ buffers/cache:       3.3G       4.3G</span><br><span class=\"line\">Swap:         5.6G         0B       5.6G</span><br><span class=\"line\"></span><br><span class=\"line\">===Java version: </span><br><span class=\"line\">java version &quot;1.8.0_101&quot;</span><br><span class=\"line\">Java(TM) SE Runtime Environment (build 1.8.0_101-b13)</span><br><span class=\"line\">Java HotSpot(TM) 64-Bit Server VM (build 25.101-b13, mixed mode)</span><br><span class=\"line\"> </span><br><span class=\"line\">===OS: </span><br><span class=\"line\">Linux ferdinand-notebook 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u2 (2016-10-19) x86_64 GNU/Linux</span><br><span class=\"line\"></span><br><span class=\"line\">===Node: </span><br><span class=\"line\">v6.5.0</span><br><span class=\"line\"></span><br><span class=\"line\">=== Go:</span><br><span class=\"line\">go version go1.7.3 linux/amd64</span><br></pre></td></tr></table></figure>\n<h2 id=\"Test-parameters\"><a href=\"#Test-parameters\" class=\"headerlink\" title=\"Test parameters\"></a>Test parameters</h2><p>Basically there are three parameters to be varied for the benchmark.</p>\n<ul>\n<li>The <strong>number of total reqests</strong> to be performed against the API. I chose to set this to <strong>100,000</strong></li>\n<li>The <strong>number of concurrent</strong> client to make those requests. I chose to have <strong>32</strong> concurrent clients, each of them making 3,125 requests.</li>\n<li>The <strong>number of threads</strong> to be used by <em>h2load</em>. I set this parameter to four, corresponding to the number of logical CPU cores of my machine.</li>\n</ul>\n<h2 id=\"Results\"><a href=\"#Results\" class=\"headerlink\" title=\"Results\"></a>Results</h2><p>Running my <a href=\"https://github.com/n1try/http-server-benchmarks/blob/master/run-load.sh\" target=\"_blank\" rel=\"noopener\">benchmark script</a> delivered the following results.</p>\n<p><img src=\"images/benchmarks.svg\" alt=\"\"></p>\n<h2 id=\"Discussion\"><a href=\"#Discussion\" class=\"headerlink\" title=\"Discussion\"></a>Discussion</h2><p>First of all, please notice that this is definitely not a 100 % correct, scientifical evaluation. Rather it should give basic insights on the order of magnitute of the performance differences between different languageâ€™s HTTP servers.<br>As we can clearly see, Go is the fastest candidate among my test subjects. However, my implementation only utilized the plain, built-in http package without any custom ServeMux or any router or middleware on top of it. In a real-world application, one would most likely not operate on such a low level, but use frameworks like <a href=\"http://iris-go.com/\" target=\"_blank\" rel=\"noopener\">Iris</a> on top, which add additional overhead.</p>\n<p>Second place is Java using Grizzly as an embedded server inside a Jersey application. The reason for me picking Grizzly was that it pointed out to be the fastest among the common servers in <a href=\"http://menelic.com/2016/01/06/java-rest-api-benchmark-tomcat-vs-jetty-vs-grizzly-vs-undertow/\" target=\"_blank\" rel=\"noopener\">this benchmark</a>.</p>\n<p>Both of my Node implementations perform worst in this benchmark, whereas Express is even only as half as good as the plain http package. Evidently, it introduces quite an amount of overhead. However, one would most likely not implement an actual REST API without a higher-level framework like Express. Consequently, the Express benchmark is probably more representative. </p>\n<p>Conclusing I can say that I was pretty surprised about how large the differences between various servers are. Go is almost six times as fast as Node with Express, even though <a href=\"https://raygun.com/blog/2016/06/node-performance/\" target=\"_blank\" rel=\"noopener\">Express still has a very great performance</a>.</p>\n<p>The full benchmark results as well as the suiteâ€™s source code can be found at my <a href=\"https://github.com/n1try/http-server-benchmarks\" target=\"_blank\" rel=\"noopener\">GitHub project</a>.</p>\n<h2 id=\"EDIT\"><a href=\"#EDIT\" class=\"headerlink\" title=\"EDIT\"></a>EDIT</h2><p>At January 1st 2017 I did some minor adjustments to my benchmark suite. A thoughtful reader has drawn my attention to the fact that my comparison was a little unfair in the way that Goâ€™s net/http as well as Grizzly use as many threads as the host system provides CPU core by default, while Node doesnâ€™t. Using Nodeâ€™s <code>cluster</code> module I made both Node-based webservers use four listener threads, too and actually the results have improved by around 45 %. Furthermore I did an adjustment to the Jersey + Grizzly server by changing the <code>IOStrategy</code> from the default <code>WorkerThreadIOStrategy</code> to <code>SameThreadIOStrategy</code>, which brought around 10 % in this specific case, where we donâ€™t have any blocking computations but only spit out static JSON. If youâ€™re interested in leaarning more about different io strategies, refer to <a href=\"https://grizzly.java.net/iostrategies.html\" target=\"_blank\" rel=\"noopener\">this official documentation page</a>. Here is my updated benchmark chart.</p>\n<p><img src=\"images/benchmarks2.svg\" alt=\"\"></p>\n"},{"title":"How to make Telegram Bots","date":"2015-06-28T20:39:44.000Z","_content":"\nRecently [Telegram](http://telegram.org \"Telegram\") has introduced a new feature, the bots. Basically the bots enable human Telegram users to talk to machines, i.e. customly written little programs. A bot could be a daily helper, be it a bot that you can ask for the current temperature, one that googles something for you, one to manage your todoâ€™s or even a little text based game â€“ everything within the Telegram chat. The nice thing about them is that theyâ€™re really simple to create. You can read more about the bots in general here: [https://telegram.org/blog/bot-revolution](https://telegram.org/blog/bot-revolution)\n\nThis article shouldnâ€™t cover how to create and publish a bot (which actually is the same step), but how to write its actual functionality â€“ its backend. On how to initially set up one, please refer to this little guide: [https://core.telegram.org/bots](https://core.telegram.org/bots). Itâ€™s very easy, trust me. Everything you need for that is your Telegram app.\n\nWhat you need further to program your bot basically is a favorite programming language, an IDE or at least a text editor, [this](https://core.telegram.org/bots/api \"this\") page to be open and again your app. In this tutorial we will use Node.js as programming language (or more precisely as programming platform), but you really could use any other language, as well. Probably Python or PHP would do the job well, but you could even write a Java application.\n\nFirst some basic things to understand. For the most parts your bot is your own application which we will try to create here, running on your own local PC or server. Telegram wonâ€™t host any code. All functionality and data storage is kept in your program on your machine. Basically Telegram doesnâ€™t provide more than kind of an interface between your usersâ€™ Telegram client (app) and your bot application. The flow would be like:\n\n1.  You create a new bot with @BotFather and set its description and commands (the commands you set there are â€“ strictly speaking â€“ completely independent of which commands your program will actually accept â€“ they are just strings which the user gets suggested in a chat with your bot) so that the bot gets publicly accessible as any other (human) Telegram user is via her @ nickname.\n\n2.  You write the backend and run it to be listening.\n\n3.  A user sends a message to your bot.\n\n4.  The (JSON formatted) Telegram message object gets passed to your backend via HTTPS by Telegram.\n\n5.  Your backend parses the message text, extract the commands and arguments, processes some logic, possibly does some database actions and so on.\n\n6.  Your backend passes a response message object to the Telegram API via HTTPS (the other way round now).\n\n7.  Telegram shows the message to your userâ€™s chat window.\n\nAlright, now letâ€™s get into the code. I require you to already have set up a bot and got its authentication token (all using @BotFather). As I said, we will make a little Node.js program here, but for those who donâ€™t understand JavaScript too well, Iâ€™ll try to explain everything as clear as you need to re-do this in your programming language.\n\nFirst, you need any library that can do HTTP requests, because basically your backend will be busy doing POSTs and GETs for the most time. For Node.js weâ€™ll use the [Unirest](http://unirest.io/nodejs.html \"Unirest\") library, which probably is a little bit overkill, but very simple for our purpose. The library is available for Python, PHP, Ruby, Java and many others as well.\n\nSo first step is setting up a Node application and requiring Unirest (i assume you know how to set up a Node application and youâ€™re familiar with npm).\n\n```javascript\n/* app.js */\n\nvar unirest = require('unirest');\n```\n\nNext is to receive messages from your users. Telegram offers two ways to do this. The first way would be to use Webhooks, which basically means that youâ€™re backend runs on a webserver (or for Node it actually is one itself), Telegram knows your HTTPS endpoint and does a request to your backend every time a message is sent by a user. I would consider this the more elegant way. But the minus about this is that you would need to have a valid SSL certificate (which costs monthly charge) to provide a secure HTTPS connection. Telegram wonâ€™t send any data to an unsecure or unverified endpoint. This is why we will take the other approach, which works kind of the other way round. Your backend will continuously request the Telegram API if there are new messages available. In detail your backend wonâ€™t do request after request after request (because this would be so inefficient!) but use [long polling](http://www.pubnub.com/blog/http-long-polling/ \"long polling\"). To put it simple long polling means that a request wonâ€™t be answered instantly, but kept open until there is some data available.\n\nWe need to specify some constants. As i said, everything between your backend and Telegram happens via their HTTPS interface. We set up constants for the base API url, containing your bot token, the URL for the [getUpdates](https://core.telegram.org/bots/api#getupdates \"getUpdates\") method endpoint and the URL for the [sendMessage](https://core.telegram.org/bots/api#sendmessage \"sendMessage\") method endpoint. The *:offset:* within the URL string will get replaced by a number, specifying, which new messages to fetch from Telegram later.\n\n```javascript\n/* app.js */\n\n/* ... */\n\nvar BASE_URL = \"https://api.telegram.org/botYOUR_TOKEN_HERE/\";\nvar POLLING_URL = BASE_URL + \"getUpdates?offset=:offset:&timeout=60\";\nvar SEND_MESSAGE_URL = BASE_URL + \"sendMessage\";\n```\n\nNow weâ€™ll introduce a function called *poll* (you can choose any other name), which basically is kind of the main loop of our program. Hereâ€™s the code for this method, explanation follows.\n\n```javascript\n/* ... */\nfunction poll(offset) {\n    var url = POLLING_URL.replace(\":offset:\", offset);\n\n    unirest.get(url)\n        .end(function(response) {\n            var body = response.raw_body;\n            if (response.status == 200) {\n                var jsonData = JSON.parse(body);\n                var result = jsonData.result;\n\n                if (result.length > 0) {\n                    for (i in result) {\n                        if (runCommand(result[i].message)) continue;\n                    }\n\n                    max_offset = parseInt(result[result.length - 1].update_id) + 1; // update max offset\n                }\n                poll(max_offset);\n            }\n        });\n};\n```\n\nAlright. The function is recursive, meaning it will call itself â€“ namely each time, a request was answered (which is, when a new message was fetched). The http request to Telegram API to get updates will be pending until a message arrives. Then it gets answered, but has to be re-opened again instantly now to continue listening for message updates again. As a parameter it takes an offset number, which replaces the *:offset:* placeholder in the url string. To read more about this parameter, go to [https://core.telegram.org/bots/api#getupdates](https://core.telegram.org/bots/api#getupdates). Unirest opens an http request to the specified url and executes the callback function given to end(), if the request was answered. First, we extract the response body. Afterwards, we check if our request was successful. If this is the case, we parse the body (which is a JSON object, consisting of an *ok* field and a *result* array. The result array contains one or more message objects. These are the ones that are relevant for us. For each message object, we try to parse it as a command (iâ€™ll give you the runCommand() function is a secondâ€¦) and depending on which command we got, execute the respective method. Afterwards the offset gets updates to the id of the latest message plus one (to not receive it again next time) and a new request gets opened.\n\n```javascript\n/* ... */\n\nvar dosth = function(message) {\n    // to be implemented....\n}\n\nvar COMMANDS = {\n    \"dosth\" : dosth\n};\n```\n\nNow we specify a map, which maps strings (representing the usersâ€™ command input â€“ in this case */dosth* to actual functions.\n\n```javascript\n    var msgtext = message.text;\n\n    if (msgtext.indexOf(\"/\") != 0) return false; // no slash at beginning?\n    var command = msgtext.substring(1, msgtext.indexOf(\" \"));\n    if (COMMANDS[command] == null) return false; // not a valid command?\n    COMMANDS[command](message);\n    return true;\n}\n```\n\nAnd this is the runCommand method. It takes the entire Telegram message object, which we got as a response from the Telegram API above and tries to parse its text as a command. A command string always starts with a slash. So if there is not slash in the beginning, we can be sure that we didnâ€™t get a valid command. We simply return here, but we also could send a message to the user telling him â€œHey, please enter a valid command.â€. But letâ€™s keep it simple. In the following line we extract everything after the slash and before the first blank space (assuming a command mustnâ€™t contain a blank space) as the command. Afterwards we look into our map if the command actually is a key for a method and if so, we just run this method, passing it the message object as a parameter as the function will need information out of it.\n\nWhat have we done so far? We wrote a program that requests the Telegram API for new messages, parses potentially contained commands and runs functions depending on these commands.\n\nAll we still need is to implement the method belonging to the */dosth* command.\n\n```javascript\n    var caps = message.text.toUpperCase();\n    var answer = {\n        chat_id : message.chat.id,\n        text : \"You told be to do something, so I took your input and made it all caps. Look: \" + caps\n    };\n\n    unirest.post(SEND_MESSAGE_URL)\n        .send(answer)\n        .end(function (response) {\n            if (response.status == 200) console.log(\"Successfully sent message to \" + message.chat.id);\n        });\n}\n```\n\nMost times youâ€™ll want to send a message as response to your user. You could also send an image, an audio, a location, â€¦ (see [https://core.telegram.org/bots/api#available-methods](https://core.telegram.org/bots/api#available-methods)). Every message object needs a *chat_id* field, containing a Telegram user id, so that Telegram knows which user to deliver your message to. We simply extract this id out of the message objectâ€™s chat object we received from the user. The second mandatory field in a message object is the *text*. This is up to you. After having set up the new message object (you could add other fields, e.g. to show bot-buttons to the user â€“ see [https://core.telegram.org/bots/api#message](https://core.telegram.org/bots/api#message) for this), we just need to HTTP POST it to Telegram using Unirest again. Finished.\n\nThis example was kept veeeery simple. Of course you could implement your bot to do really fancy things. You could process media, do location-specific operations, include a database (MongoDB suits really well!) and many, many other things. You could write any complex application you can imagine â€“ with a Telegram chat as the text i/o interface. Please tell be your ideas â€“ what would be a great bot?\n\nIf you like to try by bot, simply write a message to **@FavoriteBot** and share it to your friends, if you like it.\n\nIf you have any questions, contact me via mail to *mail(at)ferdinand-muetsch.de.*","source":"_posts/how-to-make-telegram-bots.md","raw":"---\ntitle: How to make Telegram Bots\ndate: 2015-06-28 22:39:44\ntags:\n---\n\nRecently [Telegram](http://telegram.org \"Telegram\") has introduced a new feature, the bots. Basically the bots enable human Telegram users to talk to machines, i.e. customly written little programs. A bot could be a daily helper, be it a bot that you can ask for the current temperature, one that googles something for you, one to manage your todoâ€™s or even a little text based game â€“ everything within the Telegram chat. The nice thing about them is that theyâ€™re really simple to create. You can read more about the bots in general here: [https://telegram.org/blog/bot-revolution](https://telegram.org/blog/bot-revolution)\n\nThis article shouldnâ€™t cover how to create and publish a bot (which actually is the same step), but how to write its actual functionality â€“ its backend. On how to initially set up one, please refer to this little guide: [https://core.telegram.org/bots](https://core.telegram.org/bots). Itâ€™s very easy, trust me. Everything you need for that is your Telegram app.\n\nWhat you need further to program your bot basically is a favorite programming language, an IDE or at least a text editor, [this](https://core.telegram.org/bots/api \"this\") page to be open and again your app. In this tutorial we will use Node.js as programming language (or more precisely as programming platform), but you really could use any other language, as well. Probably Python or PHP would do the job well, but you could even write a Java application.\n\nFirst some basic things to understand. For the most parts your bot is your own application which we will try to create here, running on your own local PC or server. Telegram wonâ€™t host any code. All functionality and data storage is kept in your program on your machine. Basically Telegram doesnâ€™t provide more than kind of an interface between your usersâ€™ Telegram client (app) and your bot application. The flow would be like:\n\n1.  You create a new bot with @BotFather and set its description and commands (the commands you set there are â€“ strictly speaking â€“ completely independent of which commands your program will actually accept â€“ they are just strings which the user gets suggested in a chat with your bot) so that the bot gets publicly accessible as any other (human) Telegram user is via her @ nickname.\n\n2.  You write the backend and run it to be listening.\n\n3.  A user sends a message to your bot.\n\n4.  The (JSON formatted) Telegram message object gets passed to your backend via HTTPS by Telegram.\n\n5.  Your backend parses the message text, extract the commands and arguments, processes some logic, possibly does some database actions and so on.\n\n6.  Your backend passes a response message object to the Telegram API via HTTPS (the other way round now).\n\n7.  Telegram shows the message to your userâ€™s chat window.\n\nAlright, now letâ€™s get into the code. I require you to already have set up a bot and got its authentication token (all using @BotFather). As I said, we will make a little Node.js program here, but for those who donâ€™t understand JavaScript too well, Iâ€™ll try to explain everything as clear as you need to re-do this in your programming language.\n\nFirst, you need any library that can do HTTP requests, because basically your backend will be busy doing POSTs and GETs for the most time. For Node.js weâ€™ll use the [Unirest](http://unirest.io/nodejs.html \"Unirest\") library, which probably is a little bit overkill, but very simple for our purpose. The library is available for Python, PHP, Ruby, Java and many others as well.\n\nSo first step is setting up a Node application and requiring Unirest (i assume you know how to set up a Node application and youâ€™re familiar with npm).\n\n```javascript\n/* app.js */\n\nvar unirest = require('unirest');\n```\n\nNext is to receive messages from your users. Telegram offers two ways to do this. The first way would be to use Webhooks, which basically means that youâ€™re backend runs on a webserver (or for Node it actually is one itself), Telegram knows your HTTPS endpoint and does a request to your backend every time a message is sent by a user. I would consider this the more elegant way. But the minus about this is that you would need to have a valid SSL certificate (which costs monthly charge) to provide a secure HTTPS connection. Telegram wonâ€™t send any data to an unsecure or unverified endpoint. This is why we will take the other approach, which works kind of the other way round. Your backend will continuously request the Telegram API if there are new messages available. In detail your backend wonâ€™t do request after request after request (because this would be so inefficient!) but use [long polling](http://www.pubnub.com/blog/http-long-polling/ \"long polling\"). To put it simple long polling means that a request wonâ€™t be answered instantly, but kept open until there is some data available.\n\nWe need to specify some constants. As i said, everything between your backend and Telegram happens via their HTTPS interface. We set up constants for the base API url, containing your bot token, the URL for the [getUpdates](https://core.telegram.org/bots/api#getupdates \"getUpdates\") method endpoint and the URL for the [sendMessage](https://core.telegram.org/bots/api#sendmessage \"sendMessage\") method endpoint. The *:offset:* within the URL string will get replaced by a number, specifying, which new messages to fetch from Telegram later.\n\n```javascript\n/* app.js */\n\n/* ... */\n\nvar BASE_URL = \"https://api.telegram.org/botYOUR_TOKEN_HERE/\";\nvar POLLING_URL = BASE_URL + \"getUpdates?offset=:offset:&timeout=60\";\nvar SEND_MESSAGE_URL = BASE_URL + \"sendMessage\";\n```\n\nNow weâ€™ll introduce a function called *poll* (you can choose any other name), which basically is kind of the main loop of our program. Hereâ€™s the code for this method, explanation follows.\n\n```javascript\n/* ... */\nfunction poll(offset) {\n    var url = POLLING_URL.replace(\":offset:\", offset);\n\n    unirest.get(url)\n        .end(function(response) {\n            var body = response.raw_body;\n            if (response.status == 200) {\n                var jsonData = JSON.parse(body);\n                var result = jsonData.result;\n\n                if (result.length > 0) {\n                    for (i in result) {\n                        if (runCommand(result[i].message)) continue;\n                    }\n\n                    max_offset = parseInt(result[result.length - 1].update_id) + 1; // update max offset\n                }\n                poll(max_offset);\n            }\n        });\n};\n```\n\nAlright. The function is recursive, meaning it will call itself â€“ namely each time, a request was answered (which is, when a new message was fetched). The http request to Telegram API to get updates will be pending until a message arrives. Then it gets answered, but has to be re-opened again instantly now to continue listening for message updates again. As a parameter it takes an offset number, which replaces the *:offset:* placeholder in the url string. To read more about this parameter, go to [https://core.telegram.org/bots/api#getupdates](https://core.telegram.org/bots/api#getupdates). Unirest opens an http request to the specified url and executes the callback function given to end(), if the request was answered. First, we extract the response body. Afterwards, we check if our request was successful. If this is the case, we parse the body (which is a JSON object, consisting of an *ok* field and a *result* array. The result array contains one or more message objects. These are the ones that are relevant for us. For each message object, we try to parse it as a command (iâ€™ll give you the runCommand() function is a secondâ€¦) and depending on which command we got, execute the respective method. Afterwards the offset gets updates to the id of the latest message plus one (to not receive it again next time) and a new request gets opened.\n\n```javascript\n/* ... */\n\nvar dosth = function(message) {\n    // to be implemented....\n}\n\nvar COMMANDS = {\n    \"dosth\" : dosth\n};\n```\n\nNow we specify a map, which maps strings (representing the usersâ€™ command input â€“ in this case */dosth* to actual functions.\n\n```javascript\n    var msgtext = message.text;\n\n    if (msgtext.indexOf(\"/\") != 0) return false; // no slash at beginning?\n    var command = msgtext.substring(1, msgtext.indexOf(\" \"));\n    if (COMMANDS[command] == null) return false; // not a valid command?\n    COMMANDS[command](message);\n    return true;\n}\n```\n\nAnd this is the runCommand method. It takes the entire Telegram message object, which we got as a response from the Telegram API above and tries to parse its text as a command. A command string always starts with a slash. So if there is not slash in the beginning, we can be sure that we didnâ€™t get a valid command. We simply return here, but we also could send a message to the user telling him â€œHey, please enter a valid command.â€. But letâ€™s keep it simple. In the following line we extract everything after the slash and before the first blank space (assuming a command mustnâ€™t contain a blank space) as the command. Afterwards we look into our map if the command actually is a key for a method and if so, we just run this method, passing it the message object as a parameter as the function will need information out of it.\n\nWhat have we done so far? We wrote a program that requests the Telegram API for new messages, parses potentially contained commands and runs functions depending on these commands.\n\nAll we still need is to implement the method belonging to the */dosth* command.\n\n```javascript\n    var caps = message.text.toUpperCase();\n    var answer = {\n        chat_id : message.chat.id,\n        text : \"You told be to do something, so I took your input and made it all caps. Look: \" + caps\n    };\n\n    unirest.post(SEND_MESSAGE_URL)\n        .send(answer)\n        .end(function (response) {\n            if (response.status == 200) console.log(\"Successfully sent message to \" + message.chat.id);\n        });\n}\n```\n\nMost times youâ€™ll want to send a message as response to your user. You could also send an image, an audio, a location, â€¦ (see [https://core.telegram.org/bots/api#available-methods](https://core.telegram.org/bots/api#available-methods)). Every message object needs a *chat_id* field, containing a Telegram user id, so that Telegram knows which user to deliver your message to. We simply extract this id out of the message objectâ€™s chat object we received from the user. The second mandatory field in a message object is the *text*. This is up to you. After having set up the new message object (you could add other fields, e.g. to show bot-buttons to the user â€“ see [https://core.telegram.org/bots/api#message](https://core.telegram.org/bots/api#message) for this), we just need to HTTP POST it to Telegram using Unirest again. Finished.\n\nThis example was kept veeeery simple. Of course you could implement your bot to do really fancy things. You could process media, do location-specific operations, include a database (MongoDB suits really well!) and many, many other things. You could write any complex application you can imagine â€“ with a Telegram chat as the text i/o interface. Please tell be your ideas â€“ what would be a great bot?\n\nIf you like to try by bot, simply write a message to **@FavoriteBot** and share it to your friends, if you like it.\n\nIf you have any questions, contact me via mail to *mail(at)ferdinand-muetsch.de.*","slug":"how-to-make-telegram-bots","published":1,"updated":"2018-03-19T09:30:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2giom2000dcxrgkg1z6kqq","content":"<p>Recently <a href=\"http://telegram.org\" title=\"Telegram\" target=\"_blank\" rel=\"noopener\">Telegram</a> has introduced a new feature, the bots. Basically the bots enable human Telegram users to talk to machines, i.e. customly written little programs. A bot could be a daily helper, be it a bot that you can ask for the current temperature, one that googles something for you, one to manage your todoâ€™s or even a little text based game â€“ everything within the Telegram chat. The nice thing about them is that theyâ€™re really simple to create. You can read more about the bots in general here: <a href=\"https://telegram.org/blog/bot-revolution\" target=\"_blank\" rel=\"noopener\">https://telegram.org/blog/bot-revolution</a></p>\n<p>This article shouldnâ€™t cover how to create and publish a bot (which actually is the same step), but how to write its actual functionality â€“ its backend. On how to initially set up one, please refer to this little guide: <a href=\"https://core.telegram.org/bots\" target=\"_blank\" rel=\"noopener\">https://core.telegram.org/bots</a>. Itâ€™s very easy, trust me. Everything you need for that is your Telegram app.</p>\n<p>What you need further to program your bot basically is a favorite programming language, an IDE or at least a text editor, <a href=\"https://core.telegram.org/bots/api\" title=\"this\" target=\"_blank\" rel=\"noopener\">this</a> page to be open and again your app. In this tutorial we will use Node.js as programming language (or more precisely as programming platform), but you really could use any other language, as well. Probably Python or PHP would do the job well, but you could even write a Java application.</p>\n<p>First some basic things to understand. For the most parts your bot is your own application which we will try to create here, running on your own local PC or server. Telegram wonâ€™t host any code. All functionality and data storage is kept in your program on your machine. Basically Telegram doesnâ€™t provide more than kind of an interface between your usersâ€™ Telegram client (app) and your bot application. The flow would be like:</p>\n<ol>\n<li><p>You create a new bot with @BotFather and set its description and commands (the commands you set there are â€“ strictly speaking â€“ completely independent of which commands your program will actually accept â€“ they are just strings which the user gets suggested in a chat with your bot) so that the bot gets publicly accessible as any other (human) Telegram user is via her @ nickname.</p>\n</li>\n<li><p>You write the backend and run it to be listening.</p>\n</li>\n<li><p>A user sends a message to your bot.</p>\n</li>\n<li><p>The (JSON formatted) Telegram message object gets passed to your backend via HTTPS by Telegram.</p>\n</li>\n<li><p>Your backend parses the message text, extract the commands and arguments, processes some logic, possibly does some database actions and so on.</p>\n</li>\n<li><p>Your backend passes a response message object to the Telegram API via HTTPS (the other way round now).</p>\n</li>\n<li><p>Telegram shows the message to your userâ€™s chat window.</p>\n</li>\n</ol>\n<p>Alright, now letâ€™s get into the code. I require you to already have set up a bot and got its authentication token (all using @BotFather). As I said, we will make a little Node.js program here, but for those who donâ€™t understand JavaScript too well, Iâ€™ll try to explain everything as clear as you need to re-do this in your programming language.</p>\n<p>First, you need any library that can do HTTP requests, because basically your backend will be busy doing POSTs and GETs for the most time. For Node.js weâ€™ll use the <a href=\"http://unirest.io/nodejs.html\" title=\"Unirest\" target=\"_blank\" rel=\"noopener\">Unirest</a> library, which probably is a little bit overkill, but very simple for our purpose. The library is available for Python, PHP, Ruby, Java and many others as well.</p>\n<p>So first step is setting up a Node application and requiring Unirest (i assume you know how to set up a Node application and youâ€™re familiar with npm).</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* app.js */</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> unirest = <span class=\"built_in\">require</span>(<span class=\"string\">'unirest'</span>);</span><br></pre></td></tr></table></figure>\n<p>Next is to receive messages from your users. Telegram offers two ways to do this. The first way would be to use Webhooks, which basically means that youâ€™re backend runs on a webserver (or for Node it actually is one itself), Telegram knows your HTTPS endpoint and does a request to your backend every time a message is sent by a user. I would consider this the more elegant way. But the minus about this is that you would need to have a valid SSL certificate (which costs monthly charge) to provide a secure HTTPS connection. Telegram wonâ€™t send any data to an unsecure or unverified endpoint. This is why we will take the other approach, which works kind of the other way round. Your backend will continuously request the Telegram API if there are new messages available. In detail your backend wonâ€™t do request after request after request (because this would be so inefficient!) but use <a href=\"http://www.pubnub.com/blog/http-long-polling/\" title=\"long polling\" target=\"_blank\" rel=\"noopener\">long polling</a>. To put it simple long polling means that a request wonâ€™t be answered instantly, but kept open until there is some data available.</p>\n<p>We need to specify some constants. As i said, everything between your backend and Telegram happens via their HTTPS interface. We set up constants for the base API url, containing your bot token, the URL for the <a href=\"https://core.telegram.org/bots/api#getupdates\" title=\"getUpdates\" target=\"_blank\" rel=\"noopener\">getUpdates</a> method endpoint and the URL for the <a href=\"https://core.telegram.org/bots/api#sendmessage\" title=\"sendMessage\" target=\"_blank\" rel=\"noopener\">sendMessage</a> method endpoint. The <em>:offset:</em> within the URL string will get replaced by a number, specifying, which new messages to fetch from Telegram later.</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* app.js */</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* ... */</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> BASE_URL = <span class=\"string\">\"https://api.telegram.org/botYOUR_TOKEN_HERE/\"</span>;</span><br><span class=\"line\"><span class=\"keyword\">var</span> POLLING_URL = BASE_URL + <span class=\"string\">\"getUpdates?offset=:offset:&amp;timeout=60\"</span>;</span><br><span class=\"line\"><span class=\"keyword\">var</span> SEND_MESSAGE_URL = BASE_URL + <span class=\"string\">\"sendMessage\"</span>;</span><br></pre></td></tr></table></figure>\n<p>Now weâ€™ll introduce a function called <em>poll</em> (you can choose any other name), which basically is kind of the main loop of our program. Hereâ€™s the code for this method, explanation follows.</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* ... */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">poll</span>(<span class=\"params\">offset</span>) </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">var</span> url = POLLING_URL.replace(<span class=\"string\">\":offset:\"</span>, offset);</span><br><span class=\"line\"></span><br><span class=\"line\">    unirest.get(url)</span><br><span class=\"line\">        .end(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">response</span>) </span>&#123;</span><br><span class=\"line\">            <span class=\"keyword\">var</span> body = response.raw_body;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (response.status == <span class=\"number\">200</span>) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">var</span> jsonData = <span class=\"built_in\">JSON</span>.parse(body);</span><br><span class=\"line\">                <span class=\"keyword\">var</span> result = jsonData.result;</span><br><span class=\"line\"></span><br><span class=\"line\">                <span class=\"keyword\">if</span> (result.length &gt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">for</span> (i <span class=\"keyword\">in</span> result) &#123;</span><br><span class=\"line\">                        <span class=\"keyword\">if</span> (runCommand(result[i].message)) <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                    max_offset = <span class=\"built_in\">parseInt</span>(result[result.length - <span class=\"number\">1</span>].update_id) + <span class=\"number\">1</span>; <span class=\"comment\">// update max offset</span></span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                poll(max_offset);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;);</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>Alright. The function is recursive, meaning it will call itself â€“ namely each time, a request was answered (which is, when a new message was fetched). The http request to Telegram API to get updates will be pending until a message arrives. Then it gets answered, but has to be re-opened again instantly now to continue listening for message updates again. As a parameter it takes an offset number, which replaces the <em>:offset:</em> placeholder in the url string. To read more about this parameter, go to <a href=\"https://core.telegram.org/bots/api#getupdates\" target=\"_blank\" rel=\"noopener\">https://core.telegram.org/bots/api#getupdates</a>. Unirest opens an http request to the specified url and executes the callback function given to end(), if the request was answered. First, we extract the response body. Afterwards, we check if our request was successful. If this is the case, we parse the body (which is a JSON object, consisting of an <em>ok</em> field and a <em>result</em> array. The result array contains one or more message objects. These are the ones that are relevant for us. For each message object, we try to parse it as a command (iâ€™ll give you the runCommand() function is a secondâ€¦) and depending on which command we got, execute the respective method. Afterwards the offset gets updates to the id of the latest message plus one (to not receive it again next time) and a new request gets opened.</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* ... */</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> dosth = <span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">message</span>) </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// to be implemented....</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> COMMANDS = &#123;</span><br><span class=\"line\">    <span class=\"string\">\"dosth\"</span> : dosth</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>Now we specify a map, which maps strings (representing the usersâ€™ command input â€“ in this case <em>/dosth</em> to actual functions.</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"keyword\">var</span> msgtext = message.text;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (msgtext.indexOf(<span class=\"string\">\"/\"</span>) != <span class=\"number\">0</span>) <span class=\"keyword\">return</span> <span class=\"literal\">false</span>; <span class=\"comment\">// no slash at beginning?</span></span><br><span class=\"line\">    <span class=\"keyword\">var</span> command = msgtext.substring(<span class=\"number\">1</span>, msgtext.indexOf(<span class=\"string\">\" \"</span>));</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (COMMANDS[command] == <span class=\"literal\">null</span>) <span class=\"keyword\">return</span> <span class=\"literal\">false</span>; <span class=\"comment\">// not a valid command?</span></span><br><span class=\"line\">    COMMANDS[command](message);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>And this is the runCommand method. It takes the entire Telegram message object, which we got as a response from the Telegram API above and tries to parse its text as a command. A command string always starts with a slash. So if there is not slash in the beginning, we can be sure that we didnâ€™t get a valid command. We simply return here, but we also could send a message to the user telling him â€œHey, please enter a valid command.â€. But letâ€™s keep it simple. In the following line we extract everything after the slash and before the first blank space (assuming a command mustnâ€™t contain a blank space) as the command. Afterwards we look into our map if the command actually is a key for a method and if so, we just run this method, passing it the message object as a parameter as the function will need information out of it.</p>\n<p>What have we done so far? We wrote a program that requests the Telegram API for new messages, parses potentially contained commands and runs functions depending on these commands.</p>\n<p>All we still need is to implement the method belonging to the <em>/dosth</em> command.</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"keyword\">var</span> caps = message.text.toUpperCase();</span><br><span class=\"line\">    <span class=\"keyword\">var</span> answer = &#123;</span><br><span class=\"line\">        chat_id : message.chat.id,</span><br><span class=\"line\">        text : <span class=\"string\">\"You told be to do something, so I took your input and made it all caps. Look: \"</span> + caps</span><br><span class=\"line\">    &#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">    unirest.post(SEND_MESSAGE_URL)</span><br><span class=\"line\">        .send(answer)</span><br><span class=\"line\">        .end(<span class=\"function\"><span class=\"keyword\">function</span> (<span class=\"params\">response</span>) </span>&#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (response.status == <span class=\"number\">200</span>) <span class=\"built_in\">console</span>.log(<span class=\"string\">\"Successfully sent message to \"</span> + message.chat.id);</span><br><span class=\"line\">        &#125;);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Most times youâ€™ll want to send a message as response to your user. You could also send an image, an audio, a location, â€¦ (see <a href=\"https://core.telegram.org/bots/api#available-methods\" target=\"_blank\" rel=\"noopener\">https://core.telegram.org/bots/api#available-methods</a>). Every message object needs a <em>chat_id</em> field, containing a Telegram user id, so that Telegram knows which user to deliver your message to. We simply extract this id out of the message objectâ€™s chat object we received from the user. The second mandatory field in a message object is the <em>text</em>. This is up to you. After having set up the new message object (you could add other fields, e.g. to show bot-buttons to the user â€“ see <a href=\"https://core.telegram.org/bots/api#message\" target=\"_blank\" rel=\"noopener\">https://core.telegram.org/bots/api#message</a> for this), we just need to HTTP POST it to Telegram using Unirest again. Finished.</p>\n<p>This example was kept veeeery simple. Of course you could implement your bot to do really fancy things. You could process media, do location-specific operations, include a database (MongoDB suits really well!) and many, many other things. You could write any complex application you can imagine â€“ with a Telegram chat as the text i/o interface. Please tell be your ideas â€“ what would be a great bot?</p>\n<p>If you like to try by bot, simply write a message to <strong>@FavoriteBot</strong> and share it to your friends, if you like it.</p>\n<p>If you have any questions, contact me via mail to <em>mail(at)ferdinand-muetsch.de.</em></p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<p>Recently <a href=\"http://telegram.org\" title=\"Telegram\" target=\"_blank\" rel=\"noopener\">Telegram</a> has introduced a new feature, the bots. Basically the bots enable human Telegram users to talk to machines, i.e. customly written little programs. A bot could be a daily helper, be it a bot that you can ask for the current temperature, one that googles something for you, one to manage your todoâ€™s or even a little text based game â€“ everything within the Telegram chat. The nice thing about them is that theyâ€™re really simple to create. You can read more about the bots in general here: <a href=\"https://telegram.org/blog/bot-revolution\" target=\"_blank\" rel=\"noopener\">https://telegram.org/blog/bot-revolution</a></p>\n<p>This article shouldnâ€™t cover how to create and publish a bot (which actually is the same step), but how to write its actual functionality â€“ its backend. On how to initially set up one, please refer to this little guide: <a href=\"https://core.telegram.org/bots\" target=\"_blank\" rel=\"noopener\">https://core.telegram.org/bots</a>. Itâ€™s very easy, trust me. Everything you need for that is your Telegram app.</p>\n<p>What you need further to program your bot basically is a favorite programming language, an IDE or at least a text editor, <a href=\"https://core.telegram.org/bots/api\" title=\"this\" target=\"_blank\" rel=\"noopener\">this</a> page to be open and again your app. In this tutorial we will use Node.js as programming language (or more precisely as programming platform), but you really could use any other language, as well. Probably Python or PHP would do the job well, but you could even write a Java application.</p>\n<p>First some basic things to understand. For the most parts your bot is your own application which we will try to create here, running on your own local PC or server. Telegram wonâ€™t host any code. All functionality and data storage is kept in your program on your machine. Basically Telegram doesnâ€™t provide more than kind of an interface between your usersâ€™ Telegram client (app) and your bot application. The flow would be like:</p>\n<ol>\n<li><p>You create a new bot with @BotFather and set its description and commands (the commands you set there are â€“ strictly speaking â€“ completely independent of which commands your program will actually accept â€“ they are just strings which the user gets suggested in a chat with your bot) so that the bot gets publicly accessible as any other (human) Telegram user is via her @ nickname.</p>\n</li>\n<li><p>You write the backend and run it to be listening.</p>\n</li>\n<li><p>A user sends a message to your bot.</p>\n</li>\n<li><p>The (JSON formatted) Telegram message object gets passed to your backend via HTTPS by Telegram.</p>\n</li>\n<li><p>Your backend parses the message text, extract the commands and arguments, processes some logic, possibly does some database actions and so on.</p>\n</li>\n<li><p>Your backend passes a response message object to the Telegram API via HTTPS (the other way round now).</p>\n</li>\n<li><p>Telegram shows the message to your userâ€™s chat window.</p>\n</li>\n</ol>\n<p>Alright, now letâ€™s get into the code. I require you to already have set up a bot and got its authentication token (all using @BotFather). As I said, we will make a little Node.js program here, but for those who donâ€™t understand JavaScript too well, Iâ€™ll try to explain everything as clear as you need to re-do this in your programming language.</p>\n<p>First, you need any library that can do HTTP requests, because basically your backend will be busy doing POSTs and GETs for the most time. For Node.js weâ€™ll use the <a href=\"http://unirest.io/nodejs.html\" title=\"Unirest\" target=\"_blank\" rel=\"noopener\">Unirest</a> library, which probably is a little bit overkill, but very simple for our purpose. The library is available for Python, PHP, Ruby, Java and many others as well.</p>\n<p>So first step is setting up a Node application and requiring Unirest (i assume you know how to set up a Node application and youâ€™re familiar with npm).</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* app.js */</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> unirest = <span class=\"built_in\">require</span>(<span class=\"string\">'unirest'</span>);</span><br></pre></td></tr></table></figure>\n<p>Next is to receive messages from your users. Telegram offers two ways to do this. The first way would be to use Webhooks, which basically means that youâ€™re backend runs on a webserver (or for Node it actually is one itself), Telegram knows your HTTPS endpoint and does a request to your backend every time a message is sent by a user. I would consider this the more elegant way. But the minus about this is that you would need to have a valid SSL certificate (which costs monthly charge) to provide a secure HTTPS connection. Telegram wonâ€™t send any data to an unsecure or unverified endpoint. This is why we will take the other approach, which works kind of the other way round. Your backend will continuously request the Telegram API if there are new messages available. In detail your backend wonâ€™t do request after request after request (because this would be so inefficient!) but use <a href=\"http://www.pubnub.com/blog/http-long-polling/\" title=\"long polling\" target=\"_blank\" rel=\"noopener\">long polling</a>. To put it simple long polling means that a request wonâ€™t be answered instantly, but kept open until there is some data available.</p>\n<p>We need to specify some constants. As i said, everything between your backend and Telegram happens via their HTTPS interface. We set up constants for the base API url, containing your bot token, the URL for the <a href=\"https://core.telegram.org/bots/api#getupdates\" title=\"getUpdates\" target=\"_blank\" rel=\"noopener\">getUpdates</a> method endpoint and the URL for the <a href=\"https://core.telegram.org/bots/api#sendmessage\" title=\"sendMessage\" target=\"_blank\" rel=\"noopener\">sendMessage</a> method endpoint. The <em>:offset:</em> within the URL string will get replaced by a number, specifying, which new messages to fetch from Telegram later.</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* app.js */</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* ... */</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> BASE_URL = <span class=\"string\">\"https://api.telegram.org/botYOUR_TOKEN_HERE/\"</span>;</span><br><span class=\"line\"><span class=\"keyword\">var</span> POLLING_URL = BASE_URL + <span class=\"string\">\"getUpdates?offset=:offset:&amp;timeout=60\"</span>;</span><br><span class=\"line\"><span class=\"keyword\">var</span> SEND_MESSAGE_URL = BASE_URL + <span class=\"string\">\"sendMessage\"</span>;</span><br></pre></td></tr></table></figure>\n<p>Now weâ€™ll introduce a function called <em>poll</em> (you can choose any other name), which basically is kind of the main loop of our program. Hereâ€™s the code for this method, explanation follows.</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* ... */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">poll</span>(<span class=\"params\">offset</span>) </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">var</span> url = POLLING_URL.replace(<span class=\"string\">\":offset:\"</span>, offset);</span><br><span class=\"line\"></span><br><span class=\"line\">    unirest.get(url)</span><br><span class=\"line\">        .end(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">response</span>) </span>&#123;</span><br><span class=\"line\">            <span class=\"keyword\">var</span> body = response.raw_body;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (response.status == <span class=\"number\">200</span>) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">var</span> jsonData = <span class=\"built_in\">JSON</span>.parse(body);</span><br><span class=\"line\">                <span class=\"keyword\">var</span> result = jsonData.result;</span><br><span class=\"line\"></span><br><span class=\"line\">                <span class=\"keyword\">if</span> (result.length &gt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">for</span> (i <span class=\"keyword\">in</span> result) &#123;</span><br><span class=\"line\">                        <span class=\"keyword\">if</span> (runCommand(result[i].message)) <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                    max_offset = <span class=\"built_in\">parseInt</span>(result[result.length - <span class=\"number\">1</span>].update_id) + <span class=\"number\">1</span>; <span class=\"comment\">// update max offset</span></span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                poll(max_offset);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;);</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>Alright. The function is recursive, meaning it will call itself â€“ namely each time, a request was answered (which is, when a new message was fetched). The http request to Telegram API to get updates will be pending until a message arrives. Then it gets answered, but has to be re-opened again instantly now to continue listening for message updates again. As a parameter it takes an offset number, which replaces the <em>:offset:</em> placeholder in the url string. To read more about this parameter, go to <a href=\"https://core.telegram.org/bots/api#getupdates\" target=\"_blank\" rel=\"noopener\">https://core.telegram.org/bots/api#getupdates</a>. Unirest opens an http request to the specified url and executes the callback function given to end(), if the request was answered. First, we extract the response body. Afterwards, we check if our request was successful. If this is the case, we parse the body (which is a JSON object, consisting of an <em>ok</em> field and a <em>result</em> array. The result array contains one or more message objects. These are the ones that are relevant for us. For each message object, we try to parse it as a command (iâ€™ll give you the runCommand() function is a secondâ€¦) and depending on which command we got, execute the respective method. Afterwards the offset gets updates to the id of the latest message plus one (to not receive it again next time) and a new request gets opened.</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* ... */</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> dosth = <span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">message</span>) </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// to be implemented....</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> COMMANDS = &#123;</span><br><span class=\"line\">    <span class=\"string\">\"dosth\"</span> : dosth</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>Now we specify a map, which maps strings (representing the usersâ€™ command input â€“ in this case <em>/dosth</em> to actual functions.</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"keyword\">var</span> msgtext = message.text;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (msgtext.indexOf(<span class=\"string\">\"/\"</span>) != <span class=\"number\">0</span>) <span class=\"keyword\">return</span> <span class=\"literal\">false</span>; <span class=\"comment\">// no slash at beginning?</span></span><br><span class=\"line\">    <span class=\"keyword\">var</span> command = msgtext.substring(<span class=\"number\">1</span>, msgtext.indexOf(<span class=\"string\">\" \"</span>));</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (COMMANDS[command] == <span class=\"literal\">null</span>) <span class=\"keyword\">return</span> <span class=\"literal\">false</span>; <span class=\"comment\">// not a valid command?</span></span><br><span class=\"line\">    COMMANDS[command](message);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>And this is the runCommand method. It takes the entire Telegram message object, which we got as a response from the Telegram API above and tries to parse its text as a command. A command string always starts with a slash. So if there is not slash in the beginning, we can be sure that we didnâ€™t get a valid command. We simply return here, but we also could send a message to the user telling him â€œHey, please enter a valid command.â€. But letâ€™s keep it simple. In the following line we extract everything after the slash and before the first blank space (assuming a command mustnâ€™t contain a blank space) as the command. Afterwards we look into our map if the command actually is a key for a method and if so, we just run this method, passing it the message object as a parameter as the function will need information out of it.</p>\n<p>What have we done so far? We wrote a program that requests the Telegram API for new messages, parses potentially contained commands and runs functions depending on these commands.</p>\n<p>All we still need is to implement the method belonging to the <em>/dosth</em> command.</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"keyword\">var</span> caps = message.text.toUpperCase();</span><br><span class=\"line\">    <span class=\"keyword\">var</span> answer = &#123;</span><br><span class=\"line\">        chat_id : message.chat.id,</span><br><span class=\"line\">        text : <span class=\"string\">\"You told be to do something, so I took your input and made it all caps. Look: \"</span> + caps</span><br><span class=\"line\">    &#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">    unirest.post(SEND_MESSAGE_URL)</span><br><span class=\"line\">        .send(answer)</span><br><span class=\"line\">        .end(<span class=\"function\"><span class=\"keyword\">function</span> (<span class=\"params\">response</span>) </span>&#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (response.status == <span class=\"number\">200</span>) <span class=\"built_in\">console</span>.log(<span class=\"string\">\"Successfully sent message to \"</span> + message.chat.id);</span><br><span class=\"line\">        &#125;);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Most times youâ€™ll want to send a message as response to your user. You could also send an image, an audio, a location, â€¦ (see <a href=\"https://core.telegram.org/bots/api#available-methods\" target=\"_blank\" rel=\"noopener\">https://core.telegram.org/bots/api#available-methods</a>). Every message object needs a <em>chat_id</em> field, containing a Telegram user id, so that Telegram knows which user to deliver your message to. We simply extract this id out of the message objectâ€™s chat object we received from the user. The second mandatory field in a message object is the <em>text</em>. This is up to you. After having set up the new message object (you could add other fields, e.g. to show bot-buttons to the user â€“ see <a href=\"https://core.telegram.org/bots/api#message\" target=\"_blank\" rel=\"noopener\">https://core.telegram.org/bots/api#message</a> for this), we just need to HTTP POST it to Telegram using Unirest again. Finished.</p>\n<p>This example was kept veeeery simple. Of course you could implement your bot to do really fancy things. You could process media, do location-specific operations, include a database (MongoDB suits really well!) and many, many other things. You could write any complex application you can imagine â€“ with a Telegram chat as the text i/o interface. Please tell be your ideas â€“ what would be a great bot?</p>\n<p>If you like to try by bot, simply write a message to <strong>@FavoriteBot</strong> and share it to your friends, if you like it.</p>\n<p>If you have any questions, contact me via mail to <em>mail(at)ferdinand-muetsch.de.</em></p>\n"},{"title":"HTTP/2.0 server push proxy","date":"2016-11-14T22:05:45.000Z","_content":"\nI just released a new, little Node project on GitHub and NPM, which is called [http2-serverpush-proxy](https://www.npmjs.com/package/http2-serverpush-proxy) and does exactly what the name suggests. It spawns a reverse proxy between a web application and its clients, that serves via HTTP/2 and automatically server-pushes assets contained in the HTML. It can be used as either standalone server or as _connect_ middleware for ExpressJS.\n\n### How it works\nUsually, websites consist of multiple assets, like CSS and JS files as well as images like PNGs, JPGs and SVGs. Traditionally, a user's browser fetches the HTML first, parses it and then downloads all linked assets. However, this is slow, since the assets can't be loaded before the HTML is completely fetched and parsed. With server push, your webserver can actively send those assets to the client browser even before it requested them. To prevent you from having to implement this functionality, _http2-serverpush-proxy_ sits as a proxy between your actual webserver and the user. In contrast to some other approaches like [http2-push-manifest](https://github.com/GoogleChrome/http2-push-manifest), where the assets to be pushed are declared statically, this library __dynamically parses the HTML__ files and extracts contained assets that should be pushed.\n\n\n![](/images/push_screenshot1.png)\nWithout server push\n![](/images/push_screenshot2.png)\nWith server push\n\nDetails on how to use this library are to be found on the [project site](https://github.com/n1try/http2-serverpush-proxy). Please feel free to give me feedback!\n","source":"_posts/http20-server-push-proxy.md","raw":"---\ntitle: HTTP/2.0 server push proxy\ndate: 2016-11-14 23:05:45\ntags:\n---\n\nI just released a new, little Node project on GitHub and NPM, which is called [http2-serverpush-proxy](https://www.npmjs.com/package/http2-serverpush-proxy) and does exactly what the name suggests. It spawns a reverse proxy between a web application and its clients, that serves via HTTP/2 and automatically server-pushes assets contained in the HTML. It can be used as either standalone server or as _connect_ middleware for ExpressJS.\n\n### How it works\nUsually, websites consist of multiple assets, like CSS and JS files as well as images like PNGs, JPGs and SVGs. Traditionally, a user's browser fetches the HTML first, parses it and then downloads all linked assets. However, this is slow, since the assets can't be loaded before the HTML is completely fetched and parsed. With server push, your webserver can actively send those assets to the client browser even before it requested them. To prevent you from having to implement this functionality, _http2-serverpush-proxy_ sits as a proxy between your actual webserver and the user. In contrast to some other approaches like [http2-push-manifest](https://github.com/GoogleChrome/http2-push-manifest), where the assets to be pushed are declared statically, this library __dynamically parses the HTML__ files and extracts contained assets that should be pushed.\n\n\n![](/images/push_screenshot1.png)\nWithout server push\n![](/images/push_screenshot2.png)\nWith server push\n\nDetails on how to use this library are to be found on the [project site](https://github.com/n1try/http2-serverpush-proxy). Please feel free to give me feedback!\n","slug":"http20-server-push-proxy","published":1,"updated":"2018-03-19T09:30:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2giom4000ecxrgvdioa9hy","content":"<p>I just released a new, little Node project on GitHub and NPM, which is called <a href=\"https://www.npmjs.com/package/http2-serverpush-proxy\" target=\"_blank\" rel=\"noopener\">http2-serverpush-proxy</a> and does exactly what the name suggests. It spawns a reverse proxy between a web application and its clients, that serves via HTTP/2 and automatically server-pushes assets contained in the HTML. It can be used as either standalone server or as <em>connect</em> middleware for ExpressJS.</p>\n<h3 id=\"How-it-works\"><a href=\"#How-it-works\" class=\"headerlink\" title=\"How it works\"></a>How it works</h3><p>Usually, websites consist of multiple assets, like CSS and JS files as well as images like PNGs, JPGs and SVGs. Traditionally, a userâ€™s browser fetches the HTML first, parses it and then downloads all linked assets. However, this is slow, since the assets canâ€™t be loaded before the HTML is completely fetched and parsed. With server push, your webserver can actively send those assets to the client browser even before it requested them. To prevent you from having to implement this functionality, <em>http2-serverpush-proxy</em> sits as a proxy between your actual webserver and the user. In contrast to some other approaches like <a href=\"https://github.com/GoogleChrome/http2-push-manifest\" target=\"_blank\" rel=\"noopener\">http2-push-manifest</a>, where the assets to be pushed are declared statically, this library <strong>dynamically parses the HTML</strong> files and extracts contained assets that should be pushed.</p>\n<p><img src=\"/images/push_screenshot1.png\" alt=\"\"><br>Without server push<br><img src=\"/images/push_screenshot2.png\" alt=\"\"><br>With server push</p>\n<p>Details on how to use this library are to be found on the <a href=\"https://github.com/n1try/http2-serverpush-proxy\" target=\"_blank\" rel=\"noopener\">project site</a>. Please feel free to give me feedback!</p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<p>I just released a new, little Node project on GitHub and NPM, which is called <a href=\"https://www.npmjs.com/package/http2-serverpush-proxy\" target=\"_blank\" rel=\"noopener\">http2-serverpush-proxy</a> and does exactly what the name suggests. It spawns a reverse proxy between a web application and its clients, that serves via HTTP/2 and automatically server-pushes assets contained in the HTML. It can be used as either standalone server or as <em>connect</em> middleware for ExpressJS.</p>\n<h3 id=\"How-it-works\"><a href=\"#How-it-works\" class=\"headerlink\" title=\"How it works\"></a>How it works</h3><p>Usually, websites consist of multiple assets, like CSS and JS files as well as images like PNGs, JPGs and SVGs. Traditionally, a userâ€™s browser fetches the HTML first, parses it and then downloads all linked assets. However, this is slow, since the assets canâ€™t be loaded before the HTML is completely fetched and parsed. With server push, your webserver can actively send those assets to the client browser even before it requested them. To prevent you from having to implement this functionality, <em>http2-serverpush-proxy</em> sits as a proxy between your actual webserver and the user. In contrast to some other approaches like <a href=\"https://github.com/GoogleChrome/http2-push-manifest\" target=\"_blank\" rel=\"noopener\">http2-push-manifest</a>, where the assets to be pushed are declared statically, this library <strong>dynamically parses the HTML</strong> files and extracts contained assets that should be pushed.</p>\n<p><img src=\"/images/push_screenshot1.png\" alt=\"\"><br>Without server push<br><img src=\"/images/push_screenshot2.png\" alt=\"\"><br>With server push</p>\n<p>Details on how to use this library are to be found on the <a href=\"https://github.com/n1try/http2-serverpush-proxy\" target=\"_blank\" rel=\"noopener\">project site</a>. Please feel free to give me feedback!</p>\n"},{"title":"Innovation in Germany - not","date":"2016-05-19T21:00:53.000Z","_content":"\nOver last last while I got confronted with this topic quite frequently. Eventually [this german article](http://t3n.de/news/hotspots-unitymedia-abgemahnt-707512/) â€“ or more precisely the comments below it â€“ caused me to write my own little post on my personal perception of how innovation takes place in Germany. For the non-german readers among us I want to give a brief summary of that article. Recently the german internet provider â€œUnitymediaâ€ came up with the idea to provide free WiFi-Hotspots for everyone, since internet connection in public places is pretty much a negative report in Germany. The key point with that is their intention of how to implement those so called â€œWifiSpotsâ€. Every Unitymedia customer who has a Wifi-capable router in her home should become such a hotspot, while they promise that the hotspot network is completely isolated from the customerâ€™s own network â€“ in terms of both security and bandwidth. Personally I like the idea, because I consider it quite efficient. Why put effort in distributing routers in public places if there already is full Wifi coverage? Most peopleâ€™s routers are nowhere near working at capacity anyway. And if itâ€™s guaranteed that the public internet traffic doesnâ€™t influence you at all, why not? The article tells that the consumer protection center of North Rhine-Westphalia had admonished Unitymedia for their plans recently. One of the top comments below the article says about the following:\n\n*\"Thatâ€™s exactly the reason why innovation isnâ€™t possible in Germany. As soon as a company tries to solve peopleâ€™s problems, everybody goes to the barricades. One gets punished for experiments â€“ not surprisingly nobody wants to found a company.\"*\n\nEven though the comment received a lot of bad write-up, that boils it down for me quite well. In my opinion Germany is ways too sluggish and conservative when it comes to adapting something new. Even though most representatives of the german manufacture consider themselves progressive, I actually donâ€™t think they are â€“ at least not as much as they once were. I went to a conference on [Industry 4.0](https://en.wikipedia.org/wiki/Industry_4.0) last week where one speaker claimed that Germany was at least one to two years ahead of other countries at Industry 4.0 topics, but what I picked out between the lines is that quite the opposite is true. While the Germany are continuously trying to define standards, develop well-defined business-processes, clarify legal aspects and the like other countries are just doing it. They simply try it out, taking not too much risk, and if it fails, it fails. But if it succeeds â€“ and I claim that if not applied totally wrong, new technology is likely to â€“ they are given a competitive advantage, while the current big playersâ€™ lead is melting. Of course, with this attitude you are more likely to fail as if you examine every little aspect fussily. But youâ€™re also so much more likely to win big. As a professor at university had repeatedly said: â€œthink big!â€.\n\n***\"If your dreams do not scare you, they are not big enough! â€“ Ellen Johnson Sirleaf\"***\n\nThatâ€™s what often is referred to as the Silicon valley mindset. In fact, as the diagram below shows, most startups are founded in the U.S.A. and I guess if there was a ranking of really big and successful startups (like Uber, WhatsApp, Tesla, â€¦) the contrast would be even more dramatic. Take Elon Musk â€“ the founder of Tesla Motors and SpaceX â€“ (I really recommend his biography) as an instance. He thought big and he obviously won (admittedly he took a really high risk). I donâ€™t think they evaluate and plan new technology (like VR and stuff) that much at SpaceX â€“ they just do it.\n\n[![](/images/statista.png)](http://www.statista.com/statistics/268786/start-ups-in-leading-economic-nations/)\nSource: Statista.com\n\nAnother example for Germanyâ€™s innovation power is the following. Iâ€™ve worked for two different companies as a working student â€“ both were software manufacturers. One was a typical german medium-sized company and the other was an american corporation. In one of them, the second-latest version of Internet Explorer was the only browser installed on every employeeâ€™s computer and if you desired another, you had to open a ticket to make the software distribution department install an outdated version of Firefox a few hours later. I donâ€™t want to blame that company â€“ they did a great job at what they did. But the overall way of thinking there was old-fashioned, strict and not open-minded at all. Primarily itâ€™s the peopleâ€™s mindset that differentiates those two companies completely. I canâ€™t really imagine that this first company is a workplace where you really feel comfortable and where youâ€™re looking forward to a workday. At the time I worked there, they were about to release a little mobile app, whose development effort I estimate to only few weeks of intensive work of a small group of developers. The appâ€™s purpose was great, but unfortunately, it was modern and innovative. Therefore there were only too few people to insistently support it. And thereâ€™s also the fact that processes were ways too sluggish to do a rapid development. As a result the app is still not released, but instead, two american countries each released an app with pretty much the exact same purpose. So much for that mindset in german companies â€“ of course and as always, there definitely are exceptions (a really big global player originated in Germany at which one department prints out document to hand it over to the other department, at which a trainee typewrites it to make it digital again, not being one of them).\n\nAnother alarming fact I want to mention in this context is that the [average internet speed in Germany is even far behind countries like Sri-Lanka and Vietnam](https://en.wikipedia.org/wiki/List_of_countries_by_Internet_connection_speeds#Akamai_Q3_2015_rankings).\n\n***\"Once a new technology rolls over you, if youâ€™re not part of the steamroller, youâ€™re part of the road.â€Šâ€”â€ŠStewart Brand\"***\n\nWhat this all amounts to is that Germany should really watch out to not get passed by countries where the people are more ambitious and motivated and less conservative and formal. We should never rest on our laurels but try to permanently improve in a continuous evolution â€“ or to quote many speakers at the conference mentioned above: to not fall into the process of disruptive self-destruction.","source":"_posts/innovation-in-germany-not.md","raw":"---\ntitle: Innovation in Germany - not\ndate: 2016-05-19 23:00:53\ntags:\n---\n\nOver last last while I got confronted with this topic quite frequently. Eventually [this german article](http://t3n.de/news/hotspots-unitymedia-abgemahnt-707512/) â€“ or more precisely the comments below it â€“ caused me to write my own little post on my personal perception of how innovation takes place in Germany. For the non-german readers among us I want to give a brief summary of that article. Recently the german internet provider â€œUnitymediaâ€ came up with the idea to provide free WiFi-Hotspots for everyone, since internet connection in public places is pretty much a negative report in Germany. The key point with that is their intention of how to implement those so called â€œWifiSpotsâ€. Every Unitymedia customer who has a Wifi-capable router in her home should become such a hotspot, while they promise that the hotspot network is completely isolated from the customerâ€™s own network â€“ in terms of both security and bandwidth. Personally I like the idea, because I consider it quite efficient. Why put effort in distributing routers in public places if there already is full Wifi coverage? Most peopleâ€™s routers are nowhere near working at capacity anyway. And if itâ€™s guaranteed that the public internet traffic doesnâ€™t influence you at all, why not? The article tells that the consumer protection center of North Rhine-Westphalia had admonished Unitymedia for their plans recently. One of the top comments below the article says about the following:\n\n*\"Thatâ€™s exactly the reason why innovation isnâ€™t possible in Germany. As soon as a company tries to solve peopleâ€™s problems, everybody goes to the barricades. One gets punished for experiments â€“ not surprisingly nobody wants to found a company.\"*\n\nEven though the comment received a lot of bad write-up, that boils it down for me quite well. In my opinion Germany is ways too sluggish and conservative when it comes to adapting something new. Even though most representatives of the german manufacture consider themselves progressive, I actually donâ€™t think they are â€“ at least not as much as they once were. I went to a conference on [Industry 4.0](https://en.wikipedia.org/wiki/Industry_4.0) last week where one speaker claimed that Germany was at least one to two years ahead of other countries at Industry 4.0 topics, but what I picked out between the lines is that quite the opposite is true. While the Germany are continuously trying to define standards, develop well-defined business-processes, clarify legal aspects and the like other countries are just doing it. They simply try it out, taking not too much risk, and if it fails, it fails. But if it succeeds â€“ and I claim that if not applied totally wrong, new technology is likely to â€“ they are given a competitive advantage, while the current big playersâ€™ lead is melting. Of course, with this attitude you are more likely to fail as if you examine every little aspect fussily. But youâ€™re also so much more likely to win big. As a professor at university had repeatedly said: â€œthink big!â€.\n\n***\"If your dreams do not scare you, they are not big enough! â€“ Ellen Johnson Sirleaf\"***\n\nThatâ€™s what often is referred to as the Silicon valley mindset. In fact, as the diagram below shows, most startups are founded in the U.S.A. and I guess if there was a ranking of really big and successful startups (like Uber, WhatsApp, Tesla, â€¦) the contrast would be even more dramatic. Take Elon Musk â€“ the founder of Tesla Motors and SpaceX â€“ (I really recommend his biography) as an instance. He thought big and he obviously won (admittedly he took a really high risk). I donâ€™t think they evaluate and plan new technology (like VR and stuff) that much at SpaceX â€“ they just do it.\n\n[![](/images/statista.png)](http://www.statista.com/statistics/268786/start-ups-in-leading-economic-nations/)\nSource: Statista.com\n\nAnother example for Germanyâ€™s innovation power is the following. Iâ€™ve worked for two different companies as a working student â€“ both were software manufacturers. One was a typical german medium-sized company and the other was an american corporation. In one of them, the second-latest version of Internet Explorer was the only browser installed on every employeeâ€™s computer and if you desired another, you had to open a ticket to make the software distribution department install an outdated version of Firefox a few hours later. I donâ€™t want to blame that company â€“ they did a great job at what they did. But the overall way of thinking there was old-fashioned, strict and not open-minded at all. Primarily itâ€™s the peopleâ€™s mindset that differentiates those two companies completely. I canâ€™t really imagine that this first company is a workplace where you really feel comfortable and where youâ€™re looking forward to a workday. At the time I worked there, they were about to release a little mobile app, whose development effort I estimate to only few weeks of intensive work of a small group of developers. The appâ€™s purpose was great, but unfortunately, it was modern and innovative. Therefore there were only too few people to insistently support it. And thereâ€™s also the fact that processes were ways too sluggish to do a rapid development. As a result the app is still not released, but instead, two american countries each released an app with pretty much the exact same purpose. So much for that mindset in german companies â€“ of course and as always, there definitely are exceptions (a really big global player originated in Germany at which one department prints out document to hand it over to the other department, at which a trainee typewrites it to make it digital again, not being one of them).\n\nAnother alarming fact I want to mention in this context is that the [average internet speed in Germany is even far behind countries like Sri-Lanka and Vietnam](https://en.wikipedia.org/wiki/List_of_countries_by_Internet_connection_speeds#Akamai_Q3_2015_rankings).\n\n***\"Once a new technology rolls over you, if youâ€™re not part of the steamroller, youâ€™re part of the road.â€Šâ€”â€ŠStewart Brand\"***\n\nWhat this all amounts to is that Germany should really watch out to not get passed by countries where the people are more ambitious and motivated and less conservative and formal. We should never rest on our laurels but try to permanently improve in a continuous evolution â€“ or to quote many speakers at the conference mentioned above: to not fall into the process of disruptive self-destruction.","slug":"innovation-in-germany-not","published":1,"updated":"2018-03-19T09:30:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2giom5000fcxrgnvzkrqai","content":"<p>Over last last while I got confronted with this topic quite frequently. Eventually <a href=\"http://t3n.de/news/hotspots-unitymedia-abgemahnt-707512/\" target=\"_blank\" rel=\"noopener\">this german article</a> â€“ or more precisely the comments below it â€“ caused me to write my own little post on my personal perception of how innovation takes place in Germany. For the non-german readers among us I want to give a brief summary of that article. Recently the german internet provider â€œUnitymediaâ€ came up with the idea to provide free WiFi-Hotspots for everyone, since internet connection in public places is pretty much a negative report in Germany. The key point with that is their intention of how to implement those so called â€œWifiSpotsâ€. Every Unitymedia customer who has a Wifi-capable router in her home should become such a hotspot, while they promise that the hotspot network is completely isolated from the customerâ€™s own network â€“ in terms of both security and bandwidth. Personally I like the idea, because I consider it quite efficient. Why put effort in distributing routers in public places if there already is full Wifi coverage? Most peopleâ€™s routers are nowhere near working at capacity anyway. And if itâ€™s guaranteed that the public internet traffic doesnâ€™t influence you at all, why not? The article tells that the consumer protection center of North Rhine-Westphalia had admonished Unitymedia for their plans recently. One of the top comments below the article says about the following:</p>\n<p><em>â€œThatâ€™s exactly the reason why innovation isnâ€™t possible in Germany. As soon as a company tries to solve peopleâ€™s problems, everybody goes to the barricades. One gets punished for experiments â€“ not surprisingly nobody wants to found a company.â€</em></p>\n<p>Even though the comment received a lot of bad write-up, that boils it down for me quite well. In my opinion Germany is ways too sluggish and conservative when it comes to adapting something new. Even though most representatives of the german manufacture consider themselves progressive, I actually donâ€™t think they are â€“ at least not as much as they once were. I went to a conference on <a href=\"https://en.wikipedia.org/wiki/Industry_4.0\" target=\"_blank\" rel=\"noopener\">Industry 4.0</a> last week where one speaker claimed that Germany was at least one to two years ahead of other countries at Industry 4.0 topics, but what I picked out between the lines is that quite the opposite is true. While the Germany are continuously trying to define standards, develop well-defined business-processes, clarify legal aspects and the like other countries are just doing it. They simply try it out, taking not too much risk, and if it fails, it fails. But if it succeeds â€“ and I claim that if not applied totally wrong, new technology is likely to â€“ they are given a competitive advantage, while the current big playersâ€™ lead is melting. Of course, with this attitude you are more likely to fail as if you examine every little aspect fussily. But youâ€™re also so much more likely to win big. As a professor at university had repeatedly said: â€œthink big!â€.</p>\n<p><strong><em>â€œIf your dreams do not scare you, they are not big enough! â€“ Ellen Johnson Sirleafâ€</em></strong></p>\n<p>Thatâ€™s what often is referred to as the Silicon valley mindset. In fact, as the diagram below shows, most startups are founded in the U.S.A. and I guess if there was a ranking of really big and successful startups (like Uber, WhatsApp, Tesla, â€¦) the contrast would be even more dramatic. Take Elon Musk â€“ the founder of Tesla Motors and SpaceX â€“ (I really recommend his biography) as an instance. He thought big and he obviously won (admittedly he took a really high risk). I donâ€™t think they evaluate and plan new technology (like VR and stuff) that much at SpaceX â€“ they just do it.</p>\n<p><a href=\"http://www.statista.com/statistics/268786/start-ups-in-leading-economic-nations/\" target=\"_blank\" rel=\"noopener\"><img src=\"/images/statista.png\" alt=\"\"></a><br>Source: Statista.com</p>\n<p>Another example for Germanyâ€™s innovation power is the following. Iâ€™ve worked for two different companies as a working student â€“ both were software manufacturers. One was a typical german medium-sized company and the other was an american corporation. In one of them, the second-latest version of Internet Explorer was the only browser installed on every employeeâ€™s computer and if you desired another, you had to open a ticket to make the software distribution department install an outdated version of Firefox a few hours later. I donâ€™t want to blame that company â€“ they did a great job at what they did. But the overall way of thinking there was old-fashioned, strict and not open-minded at all. Primarily itâ€™s the peopleâ€™s mindset that differentiates those two companies completely. I canâ€™t really imagine that this first company is a workplace where you really feel comfortable and where youâ€™re looking forward to a workday. At the time I worked there, they were about to release a little mobile app, whose development effort I estimate to only few weeks of intensive work of a small group of developers. The appâ€™s purpose was great, but unfortunately, it was modern and innovative. Therefore there were only too few people to insistently support it. And thereâ€™s also the fact that processes were ways too sluggish to do a rapid development. As a result the app is still not released, but instead, two american countries each released an app with pretty much the exact same purpose. So much for that mindset in german companies â€“ of course and as always, there definitely are exceptions (a really big global player originated in Germany at which one department prints out document to hand it over to the other department, at which a trainee typewrites it to make it digital again, not being one of them).</p>\n<p>Another alarming fact I want to mention in this context is that the <a href=\"https://en.wikipedia.org/wiki/List_of_countries_by_Internet_connection_speeds#Akamai_Q3_2015_rankings\" target=\"_blank\" rel=\"noopener\">average internet speed in Germany is even far behind countries like Sri-Lanka and Vietnam</a>.</p>\n<p><strong><em>â€œOnce a new technology rolls over you, if youâ€™re not part of the steamroller, youâ€™re part of the road.â€Šâ€”â€ŠStewart Brandâ€</em></strong></p>\n<p>What this all amounts to is that Germany should really watch out to not get passed by countries where the people are more ambitious and motivated and less conservative and formal. We should never rest on our laurels but try to permanently improve in a continuous evolution â€“ or to quote many speakers at the conference mentioned above: to not fall into the process of disruptive self-destruction.</p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<p>Over last last while I got confronted with this topic quite frequently. Eventually <a href=\"http://t3n.de/news/hotspots-unitymedia-abgemahnt-707512/\" target=\"_blank\" rel=\"noopener\">this german article</a> â€“ or more precisely the comments below it â€“ caused me to write my own little post on my personal perception of how innovation takes place in Germany. For the non-german readers among us I want to give a brief summary of that article. Recently the german internet provider â€œUnitymediaâ€ came up with the idea to provide free WiFi-Hotspots for everyone, since internet connection in public places is pretty much a negative report in Germany. The key point with that is their intention of how to implement those so called â€œWifiSpotsâ€. Every Unitymedia customer who has a Wifi-capable router in her home should become such a hotspot, while they promise that the hotspot network is completely isolated from the customerâ€™s own network â€“ in terms of both security and bandwidth. Personally I like the idea, because I consider it quite efficient. Why put effort in distributing routers in public places if there already is full Wifi coverage? Most peopleâ€™s routers are nowhere near working at capacity anyway. And if itâ€™s guaranteed that the public internet traffic doesnâ€™t influence you at all, why not? The article tells that the consumer protection center of North Rhine-Westphalia had admonished Unitymedia for their plans recently. One of the top comments below the article says about the following:</p>\n<p><em>â€œThatâ€™s exactly the reason why innovation isnâ€™t possible in Germany. As soon as a company tries to solve peopleâ€™s problems, everybody goes to the barricades. One gets punished for experiments â€“ not surprisingly nobody wants to found a company.â€</em></p>\n<p>Even though the comment received a lot of bad write-up, that boils it down for me quite well. In my opinion Germany is ways too sluggish and conservative when it comes to adapting something new. Even though most representatives of the german manufacture consider themselves progressive, I actually donâ€™t think they are â€“ at least not as much as they once were. I went to a conference on <a href=\"https://en.wikipedia.org/wiki/Industry_4.0\" target=\"_blank\" rel=\"noopener\">Industry 4.0</a> last week where one speaker claimed that Germany was at least one to two years ahead of other countries at Industry 4.0 topics, but what I picked out between the lines is that quite the opposite is true. While the Germany are continuously trying to define standards, develop well-defined business-processes, clarify legal aspects and the like other countries are just doing it. They simply try it out, taking not too much risk, and if it fails, it fails. But if it succeeds â€“ and I claim that if not applied totally wrong, new technology is likely to â€“ they are given a competitive advantage, while the current big playersâ€™ lead is melting. Of course, with this attitude you are more likely to fail as if you examine every little aspect fussily. But youâ€™re also so much more likely to win big. As a professor at university had repeatedly said: â€œthink big!â€.</p>\n<p><strong><em>â€œIf your dreams do not scare you, they are not big enough! â€“ Ellen Johnson Sirleafâ€</em></strong></p>\n<p>Thatâ€™s what often is referred to as the Silicon valley mindset. In fact, as the diagram below shows, most startups are founded in the U.S.A. and I guess if there was a ranking of really big and successful startups (like Uber, WhatsApp, Tesla, â€¦) the contrast would be even more dramatic. Take Elon Musk â€“ the founder of Tesla Motors and SpaceX â€“ (I really recommend his biography) as an instance. He thought big and he obviously won (admittedly he took a really high risk). I donâ€™t think they evaluate and plan new technology (like VR and stuff) that much at SpaceX â€“ they just do it.</p>\n<p><a href=\"http://www.statista.com/statistics/268786/start-ups-in-leading-economic-nations/\" target=\"_blank\" rel=\"noopener\"><img src=\"/images/statista.png\" alt=\"\"></a><br>Source: Statista.com</p>\n<p>Another example for Germanyâ€™s innovation power is the following. Iâ€™ve worked for two different companies as a working student â€“ both were software manufacturers. One was a typical german medium-sized company and the other was an american corporation. In one of them, the second-latest version of Internet Explorer was the only browser installed on every employeeâ€™s computer and if you desired another, you had to open a ticket to make the software distribution department install an outdated version of Firefox a few hours later. I donâ€™t want to blame that company â€“ they did a great job at what they did. But the overall way of thinking there was old-fashioned, strict and not open-minded at all. Primarily itâ€™s the peopleâ€™s mindset that differentiates those two companies completely. I canâ€™t really imagine that this first company is a workplace where you really feel comfortable and where youâ€™re looking forward to a workday. At the time I worked there, they were about to release a little mobile app, whose development effort I estimate to only few weeks of intensive work of a small group of developers. The appâ€™s purpose was great, but unfortunately, it was modern and innovative. Therefore there were only too few people to insistently support it. And thereâ€™s also the fact that processes were ways too sluggish to do a rapid development. As a result the app is still not released, but instead, two american countries each released an app with pretty much the exact same purpose. So much for that mindset in german companies â€“ of course and as always, there definitely are exceptions (a really big global player originated in Germany at which one department prints out document to hand it over to the other department, at which a trainee typewrites it to make it digital again, not being one of them).</p>\n<p>Another alarming fact I want to mention in this context is that the <a href=\"https://en.wikipedia.org/wiki/List_of_countries_by_Internet_connection_speeds#Akamai_Q3_2015_rankings\" target=\"_blank\" rel=\"noopener\">average internet speed in Germany is even far behind countries like Sri-Lanka and Vietnam</a>.</p>\n<p><strong><em>â€œOnce a new technology rolls over you, if youâ€™re not part of the steamroller, youâ€™re part of the road.â€Šâ€”â€ŠStewart Brandâ€</em></strong></p>\n<p>What this all amounts to is that Germany should really watch out to not get passed by countries where the people are more ambitious and motivated and less conservative and formal. We should never rest on our laurels but try to permanently improve in a continuous evolution â€“ or to quote many speakers at the conference mentioned above: to not fall into the process of disruptive self-destruction.</p>\n"},{"title":"Instant messenger security / encryption overview","date":"2016-02-01T21:48:46.000Z","_content":"\nI found a very nice page showing an overview of the security features of almost any instant messenger available. Nowadays where digital privacy observation is on everyones lips it is really interesting to see in how far the messengers we use every day are actually secure and who can potentially read or messages or not.\n\n![](/images/scorecard.jpg)\n\n[https://www.eff.org/secure-messaging-scorecard](https://www.eff.org/secure-messaging-scorecard \"https://www.eff.org/secure-messaging-scorecard\")\n\nThe aspects â€œEncrypted in transit?â€ and â€œEncrypted so the provider canâ€™t read it?â€ are probably the most important ones and are a different way of saying if the application uses encrypted transmission (probably HTTPS for the most cases) and if it has end-to-end encryption. The last one means that keys are exchanged between sender and recipient which are used for asynchronous encryption so that nobody who potentially receives the message in the middle between them could read it â€“ neither the provider nor the government. To prove that this is actually implemented properly it is required to have an open code which can be reviewed by anyone, because if nobody has ever seen the code it could potentially be the case that your messenger might use end-to-end encryption but the provider grabs your private key too or things the like.\n\nWhat I miss about this â€œSecure Messaging Scorecardâ€ is a specification of whether images (and audio recordings, videos, â€¦) get encrypted, too, by messengers that have a checkmark in the second column. Maybe I will do some research on this for some of the listed messengers.\n\nWhat I find alarming is that some commonly used apps like Skype donâ€™t even have end-to-end encryption â€“ it is not that hard to integrate and for me this should be standard today. I donâ€™t care that extremely much about online privacy because eventually I donâ€™t have anything to hide but anyhow â€“ why should Microsoft employees potentially be able to read my messages and view my pics?","source":"_posts/instant-messenger-security-encryption-overview.md","raw":"---\ntitle: Instant messenger security / encryption overview\ndate: 2016-02-01 22:48:46\ntags:\n---\n\nI found a very nice page showing an overview of the security features of almost any instant messenger available. Nowadays where digital privacy observation is on everyones lips it is really interesting to see in how far the messengers we use every day are actually secure and who can potentially read or messages or not.\n\n![](/images/scorecard.jpg)\n\n[https://www.eff.org/secure-messaging-scorecard](https://www.eff.org/secure-messaging-scorecard \"https://www.eff.org/secure-messaging-scorecard\")\n\nThe aspects â€œEncrypted in transit?â€ and â€œEncrypted so the provider canâ€™t read it?â€ are probably the most important ones and are a different way of saying if the application uses encrypted transmission (probably HTTPS for the most cases) and if it has end-to-end encryption. The last one means that keys are exchanged between sender and recipient which are used for asynchronous encryption so that nobody who potentially receives the message in the middle between them could read it â€“ neither the provider nor the government. To prove that this is actually implemented properly it is required to have an open code which can be reviewed by anyone, because if nobody has ever seen the code it could potentially be the case that your messenger might use end-to-end encryption but the provider grabs your private key too or things the like.\n\nWhat I miss about this â€œSecure Messaging Scorecardâ€ is a specification of whether images (and audio recordings, videos, â€¦) get encrypted, too, by messengers that have a checkmark in the second column. Maybe I will do some research on this for some of the listed messengers.\n\nWhat I find alarming is that some commonly used apps like Skype donâ€™t even have end-to-end encryption â€“ it is not that hard to integrate and for me this should be standard today. I donâ€™t care that extremely much about online privacy because eventually I donâ€™t have anything to hide but anyhow â€“ why should Microsoft employees potentially be able to read my messages and view my pics?","slug":"instant-messenger-security-encryption-overview","published":1,"updated":"2018-03-19T09:30:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2giom6000gcxrgn2aabwth","content":"<p>I found a very nice page showing an overview of the security features of almost any instant messenger available. Nowadays where digital privacy observation is on everyones lips it is really interesting to see in how far the messengers we use every day are actually secure and who can potentially read or messages or not.</p>\n<p><img src=\"/images/scorecard.jpg\" alt=\"\"></p>\n<p><a href=\"https://www.eff.org/secure-messaging-scorecard\" title=\"https://www.eff.org/secure-messaging-scorecard\" target=\"_blank\" rel=\"noopener\">https://www.eff.org/secure-messaging-scorecard</a></p>\n<p>The aspects â€œEncrypted in transit?â€ and â€œEncrypted so the provider canâ€™t read it?â€ are probably the most important ones and are a different way of saying if the application uses encrypted transmission (probably HTTPS for the most cases) and if it has end-to-end encryption. The last one means that keys are exchanged between sender and recipient which are used for asynchronous encryption so that nobody who potentially receives the message in the middle between them could read it â€“ neither the provider nor the government. To prove that this is actually implemented properly it is required to have an open code which can be reviewed by anyone, because if nobody has ever seen the code it could potentially be the case that your messenger might use end-to-end encryption but the provider grabs your private key too or things the like.</p>\n<p>What I miss about this â€œSecure Messaging Scorecardâ€ is a specification of whether images (and audio recordings, videos, â€¦) get encrypted, too, by messengers that have a checkmark in the second column. Maybe I will do some research on this for some of the listed messengers.</p>\n<p>What I find alarming is that some commonly used apps like Skype donâ€™t even have end-to-end encryption â€“ it is not that hard to integrate and for me this should be standard today. I donâ€™t care that extremely much about online privacy because eventually I donâ€™t have anything to hide but anyhow â€“ why should Microsoft employees potentially be able to read my messages and view my pics?</p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<p>I found a very nice page showing an overview of the security features of almost any instant messenger available. Nowadays where digital privacy observation is on everyones lips it is really interesting to see in how far the messengers we use every day are actually secure and who can potentially read or messages or not.</p>\n<p><img src=\"/images/scorecard.jpg\" alt=\"\"></p>\n<p><a href=\"https://www.eff.org/secure-messaging-scorecard\" title=\"https://www.eff.org/secure-messaging-scorecard\" target=\"_blank\" rel=\"noopener\">https://www.eff.org/secure-messaging-scorecard</a></p>\n<p>The aspects â€œEncrypted in transit?â€ and â€œEncrypted so the provider canâ€™t read it?â€ are probably the most important ones and are a different way of saying if the application uses encrypted transmission (probably HTTPS for the most cases) and if it has end-to-end encryption. The last one means that keys are exchanged between sender and recipient which are used for asynchronous encryption so that nobody who potentially receives the message in the middle between them could read it â€“ neither the provider nor the government. To prove that this is actually implemented properly it is required to have an open code which can be reviewed by anyone, because if nobody has ever seen the code it could potentially be the case that your messenger might use end-to-end encryption but the provider grabs your private key too or things the like.</p>\n<p>What I miss about this â€œSecure Messaging Scorecardâ€ is a specification of whether images (and audio recordings, videos, â€¦) get encrypted, too, by messengers that have a checkmark in the second column. Maybe I will do some research on this for some of the listed messengers.</p>\n<p>What I find alarming is that some commonly used apps like Skype donâ€™t even have end-to-end encryption â€“ it is not that hard to integrate and for me this should be standard today. I donâ€™t care that extremely much about online privacy because eventually I donâ€™t have anything to hide but anyhow â€“ why should Microsoft employees potentially be able to read my messages and view my pics?</p>\n"},{"title":"Learning Angular2: What is new?","date":"2016-02-17T21:51:59.000Z","_content":"\n![](/images/angular2_logo.png)\n\nA few days ago i started teaching myself [Angular 2](http://angular.io), which is the successor of the popular frontend web-framework [AngularJS 1.x](https://angularjs.org/). It is still in development and only released as a beta and the developers at Google recommend to not use it in production yet. But Iâ€™m sure it will come some time in the near future so why not take a step ahead and already learn it now? As Angular 1 has become very successful and wide-spread for web-applicationsâ€™ client side I have no doubts that Angular 2 will establish itself pretty quick too.\n\nFor those of you who are familiar with Angular 1 and have developed with it yet: according to what Iâ€™ve seen so far you will definitely need to take some time for learning Angular 2 â€“ it is considerably different from the first version and got few major changes, at least in my eyes. Those changes include:\n\n*   **Different syntax for directives** in HTML: They have introduced parantheses (), brackets [], stars *, hashtags # and combinations of them to be used in your markup. E.g. parantheses () are used as attributes in HTML elements to bind to their events.\n*   There are no controllers anymore. Instead everything is based on (Web-)**Components** (as you may know them from [Google Polymer](https://www.polymer-project.org/1.0/) â€“ if you donâ€™t check this out as well, it is pretty cool), which basically consist of the componentâ€™s logic and a view and define a new custom HTML element each. Almost everything in Angular 2 is a component, which enables the code to be even more structurable, more modular and more reusable. But it is a completely new way of thinking in comparison to Angular 1â€™s controllers.\n*   It is based on **ES6 and [TypeScript](http://www.typescriptlang.org/)**. ES6 is the latest JavaScript standard (or version so to say) and TypeScript is even a superset of that, which basically introduces types and modifiers for variables and functions (as you may know from strongly-typed languages like Java). This brings some completely [new features](https://github.com/lukehoban/es6features) and syntax you need to get familiar with. For instance you can define classes with attributes and methods like this now:\n```javascript\n    class Greeter {\n        greeting: string;\n        constructor(message: string) {\n            this.greeting = message;\n        }\n        greet() {\n            return \"Hello, \" + this.greeting;\n        }\n    }\n\n    var greeter = new Greeter(\"world\");</pre>\n```\n\nAlso there are interfaces, import statements, a shorthand way for anonymous functions called â€œarrow functionsâ€ and many more. Before learning Angular 2 I really recommend to first learn JavaScript ES6 for which [these two videos](https://www.youtube.com/playlist?list=PLoYCgNOIyGACDQLaThEEKBAlgs4OIUGif) are really great.\n\n*   **Dependency injection** has also been reworked to be better understandable, easier to use and more modular now. You will no use @Inectable decorators for injectable services and other modules and provide in the modules by referencing to them in a providers property in componentsâ€™ @Component decorator.\n*   Two-way data-binding is still available but the focus is now on **one-way data-binding** (if I got it right the main reason are performance considerations). One-way data-binding means that data isnâ€™t continuously updated between template and component but only based on events triggered.\n\nThose where just some of the major changes I got so far. If you want to learn Angular 2 I recommend you the following resources:\n\n * [Angularâ€™s offical Getting Started](https://angular.io/docs/ts/latest/quickstart.html)\n * [Angular 2 Fundamentals](https://www.udemy.com/angular-2-fundamentals/) (a free video course on [Udemy](http://udemy.com) for the very basic concepts)\n * This video tutorial on YouTube which I found quite good (and I really had to laugh at 30:20 minutes). You can skip the first few minutes.  \n\n[![](http://img.youtube.com/vi/KL4Yi3WtymA/0.jpg)](http://www.youtube.com/watch?v=KL4Yi3WtymA)\n\nBeing able to develop the brand new, fancy Angular 2 with the brand new JavaScript ES6 (which is so new that most of todayâ€™s browsers wonâ€™t even understand it and as a result it needs to get transpiled to ES5 at present) will definitely give you benefits in web development and also in finding a job in that sector â€“ which is probably the fastest growing and most hyped one at the moment.","source":"_posts/learning-angular2-what-is-new.md","raw":"---\ntitle: 'Learning Angular2: What is new?'\ndate: 2016-02-17 22:51:59\ntags:\n---\n\n![](/images/angular2_logo.png)\n\nA few days ago i started teaching myself [Angular 2](http://angular.io), which is the successor of the popular frontend web-framework [AngularJS 1.x](https://angularjs.org/). It is still in development and only released as a beta and the developers at Google recommend to not use it in production yet. But Iâ€™m sure it will come some time in the near future so why not take a step ahead and already learn it now? As Angular 1 has become very successful and wide-spread for web-applicationsâ€™ client side I have no doubts that Angular 2 will establish itself pretty quick too.\n\nFor those of you who are familiar with Angular 1 and have developed with it yet: according to what Iâ€™ve seen so far you will definitely need to take some time for learning Angular 2 â€“ it is considerably different from the first version and got few major changes, at least in my eyes. Those changes include:\n\n*   **Different syntax for directives** in HTML: They have introduced parantheses (), brackets [], stars *, hashtags # and combinations of them to be used in your markup. E.g. parantheses () are used as attributes in HTML elements to bind to their events.\n*   There are no controllers anymore. Instead everything is based on (Web-)**Components** (as you may know them from [Google Polymer](https://www.polymer-project.org/1.0/) â€“ if you donâ€™t check this out as well, it is pretty cool), which basically consist of the componentâ€™s logic and a view and define a new custom HTML element each. Almost everything in Angular 2 is a component, which enables the code to be even more structurable, more modular and more reusable. But it is a completely new way of thinking in comparison to Angular 1â€™s controllers.\n*   It is based on **ES6 and [TypeScript](http://www.typescriptlang.org/)**. ES6 is the latest JavaScript standard (or version so to say) and TypeScript is even a superset of that, which basically introduces types and modifiers for variables and functions (as you may know from strongly-typed languages like Java). This brings some completely [new features](https://github.com/lukehoban/es6features) and syntax you need to get familiar with. For instance you can define classes with attributes and methods like this now:\n```javascript\n    class Greeter {\n        greeting: string;\n        constructor(message: string) {\n            this.greeting = message;\n        }\n        greet() {\n            return \"Hello, \" + this.greeting;\n        }\n    }\n\n    var greeter = new Greeter(\"world\");</pre>\n```\n\nAlso there are interfaces, import statements, a shorthand way for anonymous functions called â€œarrow functionsâ€ and many more. Before learning Angular 2 I really recommend to first learn JavaScript ES6 for which [these two videos](https://www.youtube.com/playlist?list=PLoYCgNOIyGACDQLaThEEKBAlgs4OIUGif) are really great.\n\n*   **Dependency injection** has also been reworked to be better understandable, easier to use and more modular now. You will no use @Inectable decorators for injectable services and other modules and provide in the modules by referencing to them in a providers property in componentsâ€™ @Component decorator.\n*   Two-way data-binding is still available but the focus is now on **one-way data-binding** (if I got it right the main reason are performance considerations). One-way data-binding means that data isnâ€™t continuously updated between template and component but only based on events triggered.\n\nThose where just some of the major changes I got so far. If you want to learn Angular 2 I recommend you the following resources:\n\n * [Angularâ€™s offical Getting Started](https://angular.io/docs/ts/latest/quickstart.html)\n * [Angular 2 Fundamentals](https://www.udemy.com/angular-2-fundamentals/) (a free video course on [Udemy](http://udemy.com) for the very basic concepts)\n * This video tutorial on YouTube which I found quite good (and I really had to laugh at 30:20 minutes). You can skip the first few minutes.  \n\n[![](http://img.youtube.com/vi/KL4Yi3WtymA/0.jpg)](http://www.youtube.com/watch?v=KL4Yi3WtymA)\n\nBeing able to develop the brand new, fancy Angular 2 with the brand new JavaScript ES6 (which is so new that most of todayâ€™s browsers wonâ€™t even understand it and as a result it needs to get transpiled to ES5 at present) will definitely give you benefits in web development and also in finding a job in that sector â€“ which is probably the fastest growing and most hyped one at the moment.","slug":"learning-angular2-what-is-new","published":1,"updated":"2018-03-19T09:30:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2giom8000hcxrgaz3njl0p","content":"<p><img src=\"/images/angular2_logo.png\" alt=\"\"></p>\n<p>A few days ago i started teaching myself <a href=\"http://angular.io\" target=\"_blank\" rel=\"noopener\">Angular 2</a>, which is the successor of the popular frontend web-framework <a href=\"https://angularjs.org/\" target=\"_blank\" rel=\"noopener\">AngularJS 1.x</a>. It is still in development and only released as a beta and the developers at Google recommend to not use it in production yet. But Iâ€™m sure it will come some time in the near future so why not take a step ahead and already learn it now? As Angular 1 has become very successful and wide-spread for web-applicationsâ€™ client side I have no doubts that Angular 2 will establish itself pretty quick too.</p>\n<p>For those of you who are familiar with Angular 1 and have developed with it yet: according to what Iâ€™ve seen so far you will definitely need to take some time for learning Angular 2 â€“ it is considerably different from the first version and got few major changes, at least in my eyes. Those changes include:</p>\n<ul>\n<li><strong>Different syntax for directives</strong> in HTML: They have introduced parantheses (), brackets [], stars *, hashtags # and combinations of them to be used in your markup. E.g. parantheses () are used as attributes in HTML elements to bind to their events.</li>\n<li>There are no controllers anymore. Instead everything is based on (Web-)<strong>Components</strong> (as you may know them from <a href=\"https://www.polymer-project.org/1.0/\" target=\"_blank\" rel=\"noopener\">Google Polymer</a> â€“ if you donâ€™t check this out as well, it is pretty cool), which basically consist of the componentâ€™s logic and a view and define a new custom HTML element each. Almost everything in Angular 2 is a component, which enables the code to be even more structurable, more modular and more reusable. But it is a completely new way of thinking in comparison to Angular 1â€™s controllers.</li>\n<li>It is based on <strong>ES6 and <a href=\"http://www.typescriptlang.org/\" target=\"_blank\" rel=\"noopener\">TypeScript</a></strong>. ES6 is the latest JavaScript standard (or version so to say) and TypeScript is even a superset of that, which basically introduces types and modifiers for variables and functions (as you may know from strongly-typed languages like Java). This brings some completely <a href=\"https://github.com/lukehoban/es6features\" target=\"_blank\" rel=\"noopener\">new features</a> and syntax you need to get familiar with. For instance you can define classes with attributes and methods like this now:<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Greeter</span> </span>&#123;</span><br><span class=\"line\">    greeting: string;</span><br><span class=\"line\">    <span class=\"keyword\">constructor</span>(message: string) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.greeting = message;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    greet() &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"string\">\"Hello, \"</span> + <span class=\"keyword\">this</span>.greeting;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> greeter = <span class=\"keyword\">new</span> Greeter(<span class=\"string\">\"world\"</span>);&lt;/pre&gt;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>Also there are interfaces, import statements, a shorthand way for anonymous functions called â€œarrow functionsâ€ and many more. Before learning Angular 2 I really recommend to first learn JavaScript ES6 for which <a href=\"https://www.youtube.com/playlist?list=PLoYCgNOIyGACDQLaThEEKBAlgs4OIUGif\" target=\"_blank\" rel=\"noopener\">these two videos</a> are really great.</p>\n<ul>\n<li><strong>Dependency injection</strong> has also been reworked to be better understandable, easier to use and more modular now. You will no use @Inectable decorators for injectable services and other modules and provide in the modules by referencing to them in a providers property in componentsâ€™ @Component decorator.</li>\n<li>Two-way data-binding is still available but the focus is now on <strong>one-way data-binding</strong> (if I got it right the main reason are performance considerations). One-way data-binding means that data isnâ€™t continuously updated between template and component but only based on events triggered.</li>\n</ul>\n<p>Those where just some of the major changes I got so far. If you want to learn Angular 2 I recommend you the following resources:</p>\n<ul>\n<li><a href=\"https://angular.io/docs/ts/latest/quickstart.html\" target=\"_blank\" rel=\"noopener\">Angularâ€™s offical Getting Started</a></li>\n<li><a href=\"https://www.udemy.com/angular-2-fundamentals/\" target=\"_blank\" rel=\"noopener\">Angular 2 Fundamentals</a> (a free video course on <a href=\"http://udemy.com\" target=\"_blank\" rel=\"noopener\">Udemy</a> for the very basic concepts)</li>\n<li>This video tutorial on YouTube which I found quite good (and I really had to laugh at 30:20 minutes). You can skip the first few minutes.  </li>\n</ul>\n<p><a href=\"http://www.youtube.com/watch?v=KL4Yi3WtymA\" target=\"_blank\" rel=\"noopener\"><img src=\"http://img.youtube.com/vi/KL4Yi3WtymA/0.jpg\" alt=\"\"></a></p>\n<p>Being able to develop the brand new, fancy Angular 2 with the brand new JavaScript ES6 (which is so new that most of todayâ€™s browsers wonâ€™t even understand it and as a result it needs to get transpiled to ES5 at present) will definitely give you benefits in web development and also in finding a job in that sector â€“ which is probably the fastest growing and most hyped one at the moment.</p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<p><img src=\"/images/angular2_logo.png\" alt=\"\"></p>\n<p>A few days ago i started teaching myself <a href=\"http://angular.io\" target=\"_blank\" rel=\"noopener\">Angular 2</a>, which is the successor of the popular frontend web-framework <a href=\"https://angularjs.org/\" target=\"_blank\" rel=\"noopener\">AngularJS 1.x</a>. It is still in development and only released as a beta and the developers at Google recommend to not use it in production yet. But Iâ€™m sure it will come some time in the near future so why not take a step ahead and already learn it now? As Angular 1 has become very successful and wide-spread for web-applicationsâ€™ client side I have no doubts that Angular 2 will establish itself pretty quick too.</p>\n<p>For those of you who are familiar with Angular 1 and have developed with it yet: according to what Iâ€™ve seen so far you will definitely need to take some time for learning Angular 2 â€“ it is considerably different from the first version and got few major changes, at least in my eyes. Those changes include:</p>\n<ul>\n<li><strong>Different syntax for directives</strong> in HTML: They have introduced parantheses (), brackets [], stars *, hashtags # and combinations of them to be used in your markup. E.g. parantheses () are used as attributes in HTML elements to bind to their events.</li>\n<li>There are no controllers anymore. Instead everything is based on (Web-)<strong>Components</strong> (as you may know them from <a href=\"https://www.polymer-project.org/1.0/\" target=\"_blank\" rel=\"noopener\">Google Polymer</a> â€“ if you donâ€™t check this out as well, it is pretty cool), which basically consist of the componentâ€™s logic and a view and define a new custom HTML element each. Almost everything in Angular 2 is a component, which enables the code to be even more structurable, more modular and more reusable. But it is a completely new way of thinking in comparison to Angular 1â€™s controllers.</li>\n<li>It is based on <strong>ES6 and <a href=\"http://www.typescriptlang.org/\" target=\"_blank\" rel=\"noopener\">TypeScript</a></strong>. ES6 is the latest JavaScript standard (or version so to say) and TypeScript is even a superset of that, which basically introduces types and modifiers for variables and functions (as you may know from strongly-typed languages like Java). This brings some completely <a href=\"https://github.com/lukehoban/es6features\" target=\"_blank\" rel=\"noopener\">new features</a> and syntax you need to get familiar with. For instance you can define classes with attributes and methods like this now:<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Greeter</span> </span>&#123;</span><br><span class=\"line\">    greeting: string;</span><br><span class=\"line\">    <span class=\"keyword\">constructor</span>(message: string) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.greeting = message;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    greet() &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"string\">\"Hello, \"</span> + <span class=\"keyword\">this</span>.greeting;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> greeter = <span class=\"keyword\">new</span> Greeter(<span class=\"string\">\"world\"</span>);&lt;/pre&gt;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>Also there are interfaces, import statements, a shorthand way for anonymous functions called â€œarrow functionsâ€ and many more. Before learning Angular 2 I really recommend to first learn JavaScript ES6 for which <a href=\"https://www.youtube.com/playlist?list=PLoYCgNOIyGACDQLaThEEKBAlgs4OIUGif\" target=\"_blank\" rel=\"noopener\">these two videos</a> are really great.</p>\n<ul>\n<li><strong>Dependency injection</strong> has also been reworked to be better understandable, easier to use and more modular now. You will no use @Inectable decorators for injectable services and other modules and provide in the modules by referencing to them in a providers property in componentsâ€™ @Component decorator.</li>\n<li>Two-way data-binding is still available but the focus is now on <strong>one-way data-binding</strong> (if I got it right the main reason are performance considerations). One-way data-binding means that data isnâ€™t continuously updated between template and component but only based on events triggered.</li>\n</ul>\n<p>Those where just some of the major changes I got so far. If you want to learn Angular 2 I recommend you the following resources:</p>\n<ul>\n<li><a href=\"https://angular.io/docs/ts/latest/quickstart.html\" target=\"_blank\" rel=\"noopener\">Angularâ€™s offical Getting Started</a></li>\n<li><a href=\"https://www.udemy.com/angular-2-fundamentals/\" target=\"_blank\" rel=\"noopener\">Angular 2 Fundamentals</a> (a free video course on <a href=\"http://udemy.com\" target=\"_blank\" rel=\"noopener\">Udemy</a> for the very basic concepts)</li>\n<li>This video tutorial on YouTube which I found quite good (and I really had to laugh at 30:20 minutes). You can skip the first few minutes.  </li>\n</ul>\n<p><a href=\"http://www.youtube.com/watch?v=KL4Yi3WtymA\" target=\"_blank\" rel=\"noopener\"><img src=\"http://img.youtube.com/vi/KL4Yi3WtymA/0.jpg\" alt=\"\"></a></p>\n<p>Being able to develop the brand new, fancy Angular 2 with the brand new JavaScript ES6 (which is so new that most of todayâ€™s browsers wonâ€™t even understand it and as a result it needs to get transpiled to ES5 at present) will definitely give you benefits in web development and also in finding a job in that sector â€“ which is probably the fastest growing and most hyped one at the moment.</p>\n"},{"title":"LinkedData Trivia Game","date":"2017-02-01T22:09:18.000Z","_content":"\nOriginally I got inspired by [this recent post](https://news.ycombinator.com/item?id=13677748) on HackerNews, where [alex_g](https://news.ycombinator.com/user?id=alex_g) has built a quiz, which automatically generates questions from Wikipedia articles using natural language processing (NLP). However, I found the results not that satisfying, yet, and decides to build my own dynamic quiz. Instead of NLP processing I decided to use Linked Data as a base for generating questions. More precisely I'm using the [DBPedia](https://dbpedia.org) knowledge base to retreive fact information from, which mostly originates in Wikipedia articles as well. The data is structured as an RDF graph and can be queried using SPARQL. Despite from the official DBPedia SPARQL endpoint this little proof-of-concept-like app uses another webservice, [kit-lod16-knowledge-panel](https://github.com/n1try/kit-lod16-knowledge-panel), which I developed in the context of the Linked Open Data seminar at university. It is responsible for ranking RDF properties for specific RDF entities by relevance in order to decide, which one to display to an end-user (or include to a quiz).\n\n[Code on GitHub](https://github.com/n1try/linkeddata-trivia)\n\n![](images/trivia.jpg)\n\n### Limitations\nThis project is __not a production-ready__ app at all, but rather a __proof-of-concept__ to experiment with. Currently, the __major issue is performance__. Since the app fires a bunch of rather expensive, non-optimized SPARQL queries at the public DBPedia endpoint, the whole process of generating a quiz question takes several seconds on average, sometimes even up to a minute. This could be optimized to a certain extent (e.g. currently there are at least 8 separate HTTP requests from this app plus a few more from the ranking webservice), but all in all querying RDF data is still pretty slow. \n\nAnother limitation is the way \"wrong\" answer options are generated. Currently, random values within a certain interval around the \"correct\" answer are generated for dates and numbers. For properties, whose _rdfs:range_ are entities of a class, a random set of other entities from the same class is fetched from DBPedia and shown as alternative answers. However, __string-valued answers, among others, are ignored__ completely, because it's hard to auto-generate an alternative value for a plain string. There's room for enhancement here.\n\nA third way for improvement would be to include not only DBPedia, but also [Yago](https://yago-knowledge.org), Wikidata and other sources. ","source":"_posts/linkeddata-trivia-game.md","raw":"---\ntitle: LinkedData Trivia Game\ndate: 2017-02-01 23:09:18\ntags:\n---\n\nOriginally I got inspired by [this recent post](https://news.ycombinator.com/item?id=13677748) on HackerNews, where [alex_g](https://news.ycombinator.com/user?id=alex_g) has built a quiz, which automatically generates questions from Wikipedia articles using natural language processing (NLP). However, I found the results not that satisfying, yet, and decides to build my own dynamic quiz. Instead of NLP processing I decided to use Linked Data as a base for generating questions. More precisely I'm using the [DBPedia](https://dbpedia.org) knowledge base to retreive fact information from, which mostly originates in Wikipedia articles as well. The data is structured as an RDF graph and can be queried using SPARQL. Despite from the official DBPedia SPARQL endpoint this little proof-of-concept-like app uses another webservice, [kit-lod16-knowledge-panel](https://github.com/n1try/kit-lod16-knowledge-panel), which I developed in the context of the Linked Open Data seminar at university. It is responsible for ranking RDF properties for specific RDF entities by relevance in order to decide, which one to display to an end-user (or include to a quiz).\n\n[Code on GitHub](https://github.com/n1try/linkeddata-trivia)\n\n![](images/trivia.jpg)\n\n### Limitations\nThis project is __not a production-ready__ app at all, but rather a __proof-of-concept__ to experiment with. Currently, the __major issue is performance__. Since the app fires a bunch of rather expensive, non-optimized SPARQL queries at the public DBPedia endpoint, the whole process of generating a quiz question takes several seconds on average, sometimes even up to a minute. This could be optimized to a certain extent (e.g. currently there are at least 8 separate HTTP requests from this app plus a few more from the ranking webservice), but all in all querying RDF data is still pretty slow. \n\nAnother limitation is the way \"wrong\" answer options are generated. Currently, random values within a certain interval around the \"correct\" answer are generated for dates and numbers. For properties, whose _rdfs:range_ are entities of a class, a random set of other entities from the same class is fetched from DBPedia and shown as alternative answers. However, __string-valued answers, among others, are ignored__ completely, because it's hard to auto-generate an alternative value for a plain string. There's room for enhancement here.\n\nA third way for improvement would be to include not only DBPedia, but also [Yago](https://yago-knowledge.org), Wikidata and other sources. ","slug":"linkeddata-trivia-game","published":1,"updated":"2018-03-19T09:30:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2giom9000icxrgusos6zwi","content":"<p>Originally I got inspired by <a href=\"https://news.ycombinator.com/item?id=13677748\" target=\"_blank\" rel=\"noopener\">this recent post</a> on HackerNews, where <a href=\"https://news.ycombinator.com/user?id=alex_g\" target=\"_blank\" rel=\"noopener\">alex_g</a> has built a quiz, which automatically generates questions from Wikipedia articles using natural language processing (NLP). However, I found the results not that satisfying, yet, and decides to build my own dynamic quiz. Instead of NLP processing I decided to use Linked Data as a base for generating questions. More precisely Iâ€™m using the <a href=\"https://dbpedia.org\" target=\"_blank\" rel=\"noopener\">DBPedia</a> knowledge base to retreive fact information from, which mostly originates in Wikipedia articles as well. The data is structured as an RDF graph and can be queried using SPARQL. Despite from the official DBPedia SPARQL endpoint this little proof-of-concept-like app uses another webservice, <a href=\"https://github.com/n1try/kit-lod16-knowledge-panel\" target=\"_blank\" rel=\"noopener\">kit-lod16-knowledge-panel</a>, which I developed in the context of the Linked Open Data seminar at university. It is responsible for ranking RDF properties for specific RDF entities by relevance in order to decide, which one to display to an end-user (or include to a quiz).</p>\n<p><a href=\"https://github.com/n1try/linkeddata-trivia\" target=\"_blank\" rel=\"noopener\">Code on GitHub</a></p>\n<p><img src=\"images/trivia.jpg\" alt=\"\"></p>\n<h3 id=\"Limitations\"><a href=\"#Limitations\" class=\"headerlink\" title=\"Limitations\"></a>Limitations</h3><p>This project is <strong>not a production-ready</strong> app at all, but rather a <strong>proof-of-concept</strong> to experiment with. Currently, the <strong>major issue is performance</strong>. Since the app fires a bunch of rather expensive, non-optimized SPARQL queries at the public DBPedia endpoint, the whole process of generating a quiz question takes several seconds on average, sometimes even up to a minute. This could be optimized to a certain extent (e.g. currently there are at least 8 separate HTTP requests from this app plus a few more from the ranking webservice), but all in all querying RDF data is still pretty slow. </p>\n<p>Another limitation is the way â€œwrongâ€ answer options are generated. Currently, random values within a certain interval around the â€œcorrectâ€ answer are generated for dates and numbers. For properties, whose <em>rdfs:range</em> are entities of a class, a random set of other entities from the same class is fetched from DBPedia and shown as alternative answers. However, <strong>string-valued answers, among others, are ignored</strong> completely, because itâ€™s hard to auto-generate an alternative value for a plain string. Thereâ€™s room for enhancement here.</p>\n<p>A third way for improvement would be to include not only DBPedia, but also <a href=\"https://yago-knowledge.org\" target=\"_blank\" rel=\"noopener\">Yago</a>, Wikidata and other sources. </p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<p>Originally I got inspired by <a href=\"https://news.ycombinator.com/item?id=13677748\" target=\"_blank\" rel=\"noopener\">this recent post</a> on HackerNews, where <a href=\"https://news.ycombinator.com/user?id=alex_g\" target=\"_blank\" rel=\"noopener\">alex_g</a> has built a quiz, which automatically generates questions from Wikipedia articles using natural language processing (NLP). However, I found the results not that satisfying, yet, and decides to build my own dynamic quiz. Instead of NLP processing I decided to use Linked Data as a base for generating questions. More precisely Iâ€™m using the <a href=\"https://dbpedia.org\" target=\"_blank\" rel=\"noopener\">DBPedia</a> knowledge base to retreive fact information from, which mostly originates in Wikipedia articles as well. The data is structured as an RDF graph and can be queried using SPARQL. Despite from the official DBPedia SPARQL endpoint this little proof-of-concept-like app uses another webservice, <a href=\"https://github.com/n1try/kit-lod16-knowledge-panel\" target=\"_blank\" rel=\"noopener\">kit-lod16-knowledge-panel</a>, which I developed in the context of the Linked Open Data seminar at university. It is responsible for ranking RDF properties for specific RDF entities by relevance in order to decide, which one to display to an end-user (or include to a quiz).</p>\n<p><a href=\"https://github.com/n1try/linkeddata-trivia\" target=\"_blank\" rel=\"noopener\">Code on GitHub</a></p>\n<p><img src=\"images/trivia.jpg\" alt=\"\"></p>\n<h3 id=\"Limitations\"><a href=\"#Limitations\" class=\"headerlink\" title=\"Limitations\"></a>Limitations</h3><p>This project is <strong>not a production-ready</strong> app at all, but rather a <strong>proof-of-concept</strong> to experiment with. Currently, the <strong>major issue is performance</strong>. Since the app fires a bunch of rather expensive, non-optimized SPARQL queries at the public DBPedia endpoint, the whole process of generating a quiz question takes several seconds on average, sometimes even up to a minute. This could be optimized to a certain extent (e.g. currently there are at least 8 separate HTTP requests from this app plus a few more from the ranking webservice), but all in all querying RDF data is still pretty slow. </p>\n<p>Another limitation is the way â€œwrongâ€ answer options are generated. Currently, random values within a certain interval around the â€œcorrectâ€ answer are generated for dates and numbers. For properties, whose <em>rdfs:range</em> are entities of a class, a random set of other entities from the same class is fetched from DBPedia and shown as alternative answers. However, <strong>string-valued answers, among others, are ignored</strong> completely, because itâ€™s hard to auto-generate an alternative value for a plain string. Thereâ€™s room for enhancement here.</p>\n<p>A third way for improvement would be to include not only DBPedia, but also <a href=\"https://yago-knowledge.org\" target=\"_blank\" rel=\"noopener\">Yago</a>, Wikidata and other sources. </p>\n"},{"title":"Linux - Cache information bash script","date":"2015-02-27T21:31:53.000Z","_content":"\nThis is a little bash script to get the CPU cache ratios on Ubuntu.\n\n```\nCache Level: (1, 2 or 3)\nCache Type: (data-, instruction or general cache)\nCapacity: of the respective cache\nAssociativity: (set size)\nBlock capacity: / capacity of a cache line\nNumber of sets: ((total capacity / block capacity) / associativity)\n```\n\nConcerning the associativity, see [https://en.wikipedia.org/wiki/CPU_cache#Associativity](https://en.wikipedia.org/wiki/CPU_cache#Associativity).\n\n```bash\nfor DIR0 in /sys/devices/system/cpu/cpu0/cache/*\n    do\n        LEVEL0=$(sudo cat $DIR0\\/level)\n        TYPE0=$(sudo cat $DIR0\\/type)\n        SIZE0=$(sudo cat $DIR0\\/size)\n        ASSOC0=$(sudo cat $DIR0\\/ways_of_associativity)\n        BLOCK0=$(sudo cat $DIR0\\/coherency_line_size)\n        SETS0=$(sudo cat $DIR0\\/number_of_sets)\n\n        printf &quot;Cache level: %s\\nCache type: %s\\nCapacity: %s Bytes\\nAssociativity: %s\\nSets: %s\\nBlock size: %s Bytes\\n\\n&quot; &quot;$LEVEL0&quot; &quot;$TYPE0&quot; &quot;$SIZE0&quot; &quot;$ASSOC0&quot; &quot;$SETS0&quot; &quot;$BLOCK0&quot;\ndone\n```\n\n**Usage:**\n\n1.  Save code to file, e.g. _~/cacheinfo.sh_\n2.  Make it executable: _chmod +x cacheinfo.sh_\n3.  Execute: _sudo sh cacheinfo.sh_","source":"_posts/linux-cache-information-bash-script.md","raw":"---\ntitle: Linux - Cache information bash script\ndate: 2015-02-27 22:31:53\ntags:\n---\n\nThis is a little bash script to get the CPU cache ratios on Ubuntu.\n\n```\nCache Level: (1, 2 or 3)\nCache Type: (data-, instruction or general cache)\nCapacity: of the respective cache\nAssociativity: (set size)\nBlock capacity: / capacity of a cache line\nNumber of sets: ((total capacity / block capacity) / associativity)\n```\n\nConcerning the associativity, see [https://en.wikipedia.org/wiki/CPU_cache#Associativity](https://en.wikipedia.org/wiki/CPU_cache#Associativity).\n\n```bash\nfor DIR0 in /sys/devices/system/cpu/cpu0/cache/*\n    do\n        LEVEL0=$(sudo cat $DIR0\\/level)\n        TYPE0=$(sudo cat $DIR0\\/type)\n        SIZE0=$(sudo cat $DIR0\\/size)\n        ASSOC0=$(sudo cat $DIR0\\/ways_of_associativity)\n        BLOCK0=$(sudo cat $DIR0\\/coherency_line_size)\n        SETS0=$(sudo cat $DIR0\\/number_of_sets)\n\n        printf &quot;Cache level: %s\\nCache type: %s\\nCapacity: %s Bytes\\nAssociativity: %s\\nSets: %s\\nBlock size: %s Bytes\\n\\n&quot; &quot;$LEVEL0&quot; &quot;$TYPE0&quot; &quot;$SIZE0&quot; &quot;$ASSOC0&quot; &quot;$SETS0&quot; &quot;$BLOCK0&quot;\ndone\n```\n\n**Usage:**\n\n1.  Save code to file, e.g. _~/cacheinfo.sh_\n2.  Make it executable: _chmod +x cacheinfo.sh_\n3.  Execute: _sudo sh cacheinfo.sh_","slug":"linux-cache-information-bash-script","published":1,"updated":"2018-03-19T09:30:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2gioma000jcxrgzrr4nqlk","content":"<p>This is a little bash script to get the CPU cache ratios on Ubuntu.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Cache Level: (1, 2 or 3)</span><br><span class=\"line\">Cache Type: (data-, instruction or general cache)</span><br><span class=\"line\">Capacity: of the respective cache</span><br><span class=\"line\">Associativity: (set size)</span><br><span class=\"line\">Block capacity: / capacity of a cache line</span><br><span class=\"line\">Number of sets: ((total capacity / block capacity) / associativity)</span><br></pre></td></tr></table></figure>\n<p>Concerning the associativity, see <a href=\"https://en.wikipedia.org/wiki/CPU_cache#Associativity\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/CPU_cache#Associativity</a>.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> DIR0 <span class=\"keyword\">in</span> /sys/devices/system/cpu/cpu0/cache/*</span><br><span class=\"line\">    <span class=\"keyword\">do</span></span><br><span class=\"line\">        LEVEL0=$(sudo cat <span class=\"variable\">$DIR0</span>\\/level)</span><br><span class=\"line\">        TYPE0=$(sudo cat <span class=\"variable\">$DIR0</span>\\/<span class=\"built_in\">type</span>)</span><br><span class=\"line\">        SIZE0=$(sudo cat <span class=\"variable\">$DIR0</span>\\/size)</span><br><span class=\"line\">        ASSOC0=$(sudo cat <span class=\"variable\">$DIR0</span>\\/ways_of_associativity)</span><br><span class=\"line\">        BLOCK0=$(sudo cat <span class=\"variable\">$DIR0</span>\\/coherency_line_size)</span><br><span class=\"line\">        SETS0=$(sudo cat <span class=\"variable\">$DIR0</span>\\/number_of_sets)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"built_in\">printf</span> &amp;quot;Cache level: %s\\nCache <span class=\"built_in\">type</span>: %s\\nCapacity: %s Bytes\\nAssociativity: %s\\nSets: %s\\nBlock size: %s Bytes\\n\\n&amp;quot; &amp;quot;<span class=\"variable\">$LEVEL0</span>&amp;quot; &amp;quot;<span class=\"variable\">$TYPE0</span>&amp;quot; &amp;quot;<span class=\"variable\">$SIZE0</span>&amp;quot; &amp;quot;<span class=\"variable\">$ASSOC0</span>&amp;quot; &amp;quot;<span class=\"variable\">$SETS0</span>&amp;quot; &amp;quot;<span class=\"variable\">$BLOCK0</span>&amp;quot;</span><br><span class=\"line\"><span class=\"keyword\">done</span></span><br></pre></td></tr></table></figure>\n<p><strong>Usage:</strong></p>\n<ol>\n<li>Save code to file, e.g. <em>~/cacheinfo.sh</em></li>\n<li>Make it executable: <em>chmod +x cacheinfo.sh</em></li>\n<li>Execute: <em>sudo sh cacheinfo.sh</em></li>\n</ol>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<p>This is a little bash script to get the CPU cache ratios on Ubuntu.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Cache Level: (1, 2 or 3)</span><br><span class=\"line\">Cache Type: (data-, instruction or general cache)</span><br><span class=\"line\">Capacity: of the respective cache</span><br><span class=\"line\">Associativity: (set size)</span><br><span class=\"line\">Block capacity: / capacity of a cache line</span><br><span class=\"line\">Number of sets: ((total capacity / block capacity) / associativity)</span><br></pre></td></tr></table></figure>\n<p>Concerning the associativity, see <a href=\"https://en.wikipedia.org/wiki/CPU_cache#Associativity\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/CPU_cache#Associativity</a>.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> DIR0 <span class=\"keyword\">in</span> /sys/devices/system/cpu/cpu0/cache/*</span><br><span class=\"line\">    <span class=\"keyword\">do</span></span><br><span class=\"line\">        LEVEL0=$(sudo cat <span class=\"variable\">$DIR0</span>\\/level)</span><br><span class=\"line\">        TYPE0=$(sudo cat <span class=\"variable\">$DIR0</span>\\/<span class=\"built_in\">type</span>)</span><br><span class=\"line\">        SIZE0=$(sudo cat <span class=\"variable\">$DIR0</span>\\/size)</span><br><span class=\"line\">        ASSOC0=$(sudo cat <span class=\"variable\">$DIR0</span>\\/ways_of_associativity)</span><br><span class=\"line\">        BLOCK0=$(sudo cat <span class=\"variable\">$DIR0</span>\\/coherency_line_size)</span><br><span class=\"line\">        SETS0=$(sudo cat <span class=\"variable\">$DIR0</span>\\/number_of_sets)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"built_in\">printf</span> &amp;quot;Cache level: %s\\nCache <span class=\"built_in\">type</span>: %s\\nCapacity: %s Bytes\\nAssociativity: %s\\nSets: %s\\nBlock size: %s Bytes\\n\\n&amp;quot; &amp;quot;<span class=\"variable\">$LEVEL0</span>&amp;quot; &amp;quot;<span class=\"variable\">$TYPE0</span>&amp;quot; &amp;quot;<span class=\"variable\">$SIZE0</span>&amp;quot; &amp;quot;<span class=\"variable\">$ASSOC0</span>&amp;quot; &amp;quot;<span class=\"variable\">$SETS0</span>&amp;quot; &amp;quot;<span class=\"variable\">$BLOCK0</span>&amp;quot;</span><br><span class=\"line\"><span class=\"keyword\">done</span></span><br></pre></td></tr></table></figure>\n<p><strong>Usage:</strong></p>\n<ol>\n<li>Save code to file, e.g. <em>~/cacheinfo.sh</em></li>\n<li>Make it executable: <em>chmod +x cacheinfo.sh</em></li>\n<li>Execute: <em>sudo sh cacheinfo.sh</em></li>\n</ol>\n"},{"title":"Migrate Maildir to new server using imapsync","date":"2016-07-23T21:01:44.000Z","_content":"\n\nThis is a little tutorial for mailserver administrators, who want to *migrate* to a new server while *keeping all e-mails*. This works for mailservers whose MDA uses the [Maildir](https://en.wikipedia.org/wiki/Maildir) format â€“ like Dovecot by default â€“ and have *IMAP* enabled.  \nThis tutorial does *not* cover how to set up and configure a new mailserver on a new machine, based on the old oneâ€™s configuration, but only how to migrate the e-mails. Simply *tar*ing the Maildir folder and un_tar_ing it on the new machine again usually wonâ€™t work. But donâ€™t worry, there is a cleaner way that abstracts away any actual mailserver or file-level considerations by only using the IMAP protocolâ€™s methods. Therefore, we use a tool *imapsync*, which is written Perl. It acts as an ordinary IMAP client â€“ just as Outlook or Thunderbird â€“ that connects to both mailservers, the old and the new one. All information needed is how to authenticate the respective user with both servers. Actually one â€œmanualâ€ way to migrate the mails would be to set up both mail accounts in Outlook or Thunderbird, let download the mails via IMAP from the old one and Ctrl+A and Drag&Drop them over to the new one. imapsync does just that â€“ yet automatically and without Outlook or Thunderbird.\n\nFirst we need to *install imapsync*. You could install imapsync on your local PC, just as you would with Outlook or Thunderbird, but then there would be a unnecessary detour from server 1 over your PC to server 2\\. And since your local internet connection is probably ways slower then the serversâ€™, your PC would be a bottleneck. So I recommend to install imapsync on either the old or the new mailserverâ€™s host machine. Letâ€™s do it.\n\n1.  Clone the imapsync repository to any folder on your machine, e.g. `/opt/imapsync`: `git clone https://github.com/imapsync/imapsync`\n\n2.  Read the installation notes for your specific operation system at [https://github.com/imapsync/imapsync/tree/master/INSTALL.d](https://github.com/imapsync/imapsync/tree/master/INSTALL.d) and do exactly whatâ€™s described there. Usually, you will need to install some dependencies and the like.\n\n3.  Now you should be able to execute `./imapsync` from within the directory where you have cloned it to, e.g. `/opt/imapsync`. You should see a description on how to use the program.\n\nLetâ€™s now assume that you want to migrate mails from your old server with ip *12.34.45.78* for user â€œ*foo@example.orgâ€* with password â€œ*suchsecretâ€* to your new server with ip *98.76.54.32*. A prerequisite is that on both machines the mailserver is up and running and the respective user is configured. Further, letâ€™s assume that on the new machine the user, as it makes sense, is called â€œ*foo@example.orgâ€* again, but his password is â€œ*ssshhhhhâ€* now and that both MDAs require a *TLS*-secured connection, use standard *PLAIN* login method and are listening on *port 143*.\n\nTo perform the migration now, run the following command:\n\n```bash\n./imapsync --host1 12.34.45.78 --user1 foo@example.org --password1 suchsecret --authmech1 PLAIN --tls1 --host2 98.76.54.32 --user2 foo@example.org --password2 ssshhhhh --authmech2 PLAIN --tls2\n```\n\nNow all mails should be transferred from `host1` through the imapsync client to `host2`, using nothing but the IMAP protocol. If you want to test if everything is working fine first, before actually transferring data, you could add the `--dry` option to the above command.\n\nTo migrate multiple accounts at once, you could write a small scripts that takes username-password combinations from a text file, as described here: [https://wiki.ubuntuusers.de/imapsync/#Massenmigration](https://wiki.ubuntuusers.de/imapsync/#Massenmigration) (although that article is in German, the code should be clear).","source":"_posts/migrate-maildir-to-new-server-using-imapsync.md","raw":"---\ntitle: Migrate Maildir to new server using imapsync\ndate: 2016-07-23 23:01:44\ntags:\n---\n\n\nThis is a little tutorial for mailserver administrators, who want to *migrate* to a new server while *keeping all e-mails*. This works for mailservers whose MDA uses the [Maildir](https://en.wikipedia.org/wiki/Maildir) format â€“ like Dovecot by default â€“ and have *IMAP* enabled.  \nThis tutorial does *not* cover how to set up and configure a new mailserver on a new machine, based on the old oneâ€™s configuration, but only how to migrate the e-mails. Simply *tar*ing the Maildir folder and un_tar_ing it on the new machine again usually wonâ€™t work. But donâ€™t worry, there is a cleaner way that abstracts away any actual mailserver or file-level considerations by only using the IMAP protocolâ€™s methods. Therefore, we use a tool *imapsync*, which is written Perl. It acts as an ordinary IMAP client â€“ just as Outlook or Thunderbird â€“ that connects to both mailservers, the old and the new one. All information needed is how to authenticate the respective user with both servers. Actually one â€œmanualâ€ way to migrate the mails would be to set up both mail accounts in Outlook or Thunderbird, let download the mails via IMAP from the old one and Ctrl+A and Drag&Drop them over to the new one. imapsync does just that â€“ yet automatically and without Outlook or Thunderbird.\n\nFirst we need to *install imapsync*. You could install imapsync on your local PC, just as you would with Outlook or Thunderbird, but then there would be a unnecessary detour from server 1 over your PC to server 2\\. And since your local internet connection is probably ways slower then the serversâ€™, your PC would be a bottleneck. So I recommend to install imapsync on either the old or the new mailserverâ€™s host machine. Letâ€™s do it.\n\n1.  Clone the imapsync repository to any folder on your machine, e.g. `/opt/imapsync`: `git clone https://github.com/imapsync/imapsync`\n\n2.  Read the installation notes for your specific operation system at [https://github.com/imapsync/imapsync/tree/master/INSTALL.d](https://github.com/imapsync/imapsync/tree/master/INSTALL.d) and do exactly whatâ€™s described there. Usually, you will need to install some dependencies and the like.\n\n3.  Now you should be able to execute `./imapsync` from within the directory where you have cloned it to, e.g. `/opt/imapsync`. You should see a description on how to use the program.\n\nLetâ€™s now assume that you want to migrate mails from your old server with ip *12.34.45.78* for user â€œ*foo@example.orgâ€* with password â€œ*suchsecretâ€* to your new server with ip *98.76.54.32*. A prerequisite is that on both machines the mailserver is up and running and the respective user is configured. Further, letâ€™s assume that on the new machine the user, as it makes sense, is called â€œ*foo@example.orgâ€* again, but his password is â€œ*ssshhhhhâ€* now and that both MDAs require a *TLS*-secured connection, use standard *PLAIN* login method and are listening on *port 143*.\n\nTo perform the migration now, run the following command:\n\n```bash\n./imapsync --host1 12.34.45.78 --user1 foo@example.org --password1 suchsecret --authmech1 PLAIN --tls1 --host2 98.76.54.32 --user2 foo@example.org --password2 ssshhhhh --authmech2 PLAIN --tls2\n```\n\nNow all mails should be transferred from `host1` through the imapsync client to `host2`, using nothing but the IMAP protocol. If you want to test if everything is working fine first, before actually transferring data, you could add the `--dry` option to the above command.\n\nTo migrate multiple accounts at once, you could write a small scripts that takes username-password combinations from a text file, as described here: [https://wiki.ubuntuusers.de/imapsync/#Massenmigration](https://wiki.ubuntuusers.de/imapsync/#Massenmigration) (although that article is in German, the code should be clear).","slug":"migrate-maildir-to-new-server-using-imapsync","published":1,"updated":"2018-03-19T09:30:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2giomb000kcxrgu2cx0dun","content":"<p>This is a little tutorial for mailserver administrators, who want to <em>migrate</em> to a new server while <em>keeping all e-mails</em>. This works for mailservers whose MDA uses the <a href=\"https://en.wikipedia.org/wiki/Maildir\" target=\"_blank\" rel=\"noopener\">Maildir</a> format â€“ like Dovecot by default â€“ and have <em>IMAP</em> enabled.<br>This tutorial does <em>not</em> cover how to set up and configure a new mailserver on a new machine, based on the old oneâ€™s configuration, but only how to migrate the e-mails. Simply <em>tar</em>ing the Maildir folder and un_tar_ing it on the new machine again usually wonâ€™t work. But donâ€™t worry, there is a cleaner way that abstracts away any actual mailserver or file-level considerations by only using the IMAP protocolâ€™s methods. Therefore, we use a tool <em>imapsync</em>, which is written Perl. It acts as an ordinary IMAP client â€“ just as Outlook or Thunderbird â€“ that connects to both mailservers, the old and the new one. All information needed is how to authenticate the respective user with both servers. Actually one â€œmanualâ€ way to migrate the mails would be to set up both mail accounts in Outlook or Thunderbird, let download the mails via IMAP from the old one and Ctrl+A and Drag&amp;Drop them over to the new one. imapsync does just that â€“ yet automatically and without Outlook or Thunderbird.</p>\n<p>First we need to <em>install imapsync</em>. You could install imapsync on your local PC, just as you would with Outlook or Thunderbird, but then there would be a unnecessary detour from server 1 over your PC to server 2. And since your local internet connection is probably ways slower then the serversâ€™, your PC would be a bottleneck. So I recommend to install imapsync on either the old or the new mailserverâ€™s host machine. Letâ€™s do it.</p>\n<ol>\n<li><p>Clone the imapsync repository to any folder on your machine, e.g. <code>/opt/imapsync</code>: <code>git clone https://github.com/imapsync/imapsync</code></p>\n</li>\n<li><p>Read the installation notes for your specific operation system at <a href=\"https://github.com/imapsync/imapsync/tree/master/INSTALL.d\" target=\"_blank\" rel=\"noopener\">https://github.com/imapsync/imapsync/tree/master/INSTALL.d</a> and do exactly whatâ€™s described there. Usually, you will need to install some dependencies and the like.</p>\n</li>\n<li><p>Now you should be able to execute <code>./imapsync</code> from within the directory where you have cloned it to, e.g. <code>/opt/imapsync</code>. You should see a description on how to use the program.</p>\n</li>\n</ol>\n<p>Letâ€™s now assume that you want to migrate mails from your old server with ip <em>12.34.45.78</em> for user â€œ<a href=\"mailto:*foo@example.org\" target=\"_blank\" rel=\"noopener\">*foo@example.org</a>â€<em> with password â€œ</em>suchsecretâ€<em> to your new server with ip </em>98.76.54.32<em>. A prerequisite is that on both machines the mailserver is up and running and the respective user is configured. Further, letâ€™s assume that on the new machine the user, as it makes sense, is called â€œ</em><a href=\"mailto:foo@example.org\" target=\"_blank\" rel=\"noopener\">foo@example.org</a>â€<em> again, but his password is â€œ</em>ssshhhhhâ€<em> now and that both MDAs require a </em>TLS<em>-secured connection, use standard </em>PLAIN<em> login method and are listening on </em>port 143*.</p>\n<p>To perform the migration now, run the following command:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./imapsync --host1 12.34.45.78 --user1 foo@example.org --password1 suchsecret --authmech1 PLAIN --tls1 --host2 98.76.54.32 --user2 foo@example.org --password2 ssshhhhh --authmech2 PLAIN --tls2</span><br></pre></td></tr></table></figure>\n<p>Now all mails should be transferred from <code>host1</code> through the imapsync client to <code>host2</code>, using nothing but the IMAP protocol. If you want to test if everything is working fine first, before actually transferring data, you could add the <code>--dry</code> option to the above command.</p>\n<p>To migrate multiple accounts at once, you could write a small scripts that takes username-password combinations from a text file, as described here: <a href=\"https://wiki.ubuntuusers.de/imapsync/#Massenmigration\" target=\"_blank\" rel=\"noopener\">https://wiki.ubuntuusers.de/imapsync/#Massenmigration</a> (although that article is in German, the code should be clear).</p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<p>This is a little tutorial for mailserver administrators, who want to <em>migrate</em> to a new server while <em>keeping all e-mails</em>. This works for mailservers whose MDA uses the <a href=\"https://en.wikipedia.org/wiki/Maildir\" target=\"_blank\" rel=\"noopener\">Maildir</a> format â€“ like Dovecot by default â€“ and have <em>IMAP</em> enabled.<br>This tutorial does <em>not</em> cover how to set up and configure a new mailserver on a new machine, based on the old oneâ€™s configuration, but only how to migrate the e-mails. Simply <em>tar</em>ing the Maildir folder and un_tar_ing it on the new machine again usually wonâ€™t work. But donâ€™t worry, there is a cleaner way that abstracts away any actual mailserver or file-level considerations by only using the IMAP protocolâ€™s methods. Therefore, we use a tool <em>imapsync</em>, which is written Perl. It acts as an ordinary IMAP client â€“ just as Outlook or Thunderbird â€“ that connects to both mailservers, the old and the new one. All information needed is how to authenticate the respective user with both servers. Actually one â€œmanualâ€ way to migrate the mails would be to set up both mail accounts in Outlook or Thunderbird, let download the mails via IMAP from the old one and Ctrl+A and Drag&amp;Drop them over to the new one. imapsync does just that â€“ yet automatically and without Outlook or Thunderbird.</p>\n<p>First we need to <em>install imapsync</em>. You could install imapsync on your local PC, just as you would with Outlook or Thunderbird, but then there would be a unnecessary detour from server 1 over your PC to server 2. And since your local internet connection is probably ways slower then the serversâ€™, your PC would be a bottleneck. So I recommend to install imapsync on either the old or the new mailserverâ€™s host machine. Letâ€™s do it.</p>\n<ol>\n<li><p>Clone the imapsync repository to any folder on your machine, e.g. <code>/opt/imapsync</code>: <code>git clone https://github.com/imapsync/imapsync</code></p>\n</li>\n<li><p>Read the installation notes for your specific operation system at <a href=\"https://github.com/imapsync/imapsync/tree/master/INSTALL.d\" target=\"_blank\" rel=\"noopener\">https://github.com/imapsync/imapsync/tree/master/INSTALL.d</a> and do exactly whatâ€™s described there. Usually, you will need to install some dependencies and the like.</p>\n</li>\n<li><p>Now you should be able to execute <code>./imapsync</code> from within the directory where you have cloned it to, e.g. <code>/opt/imapsync</code>. You should see a description on how to use the program.</p>\n</li>\n</ol>\n<p>Letâ€™s now assume that you want to migrate mails from your old server with ip <em>12.34.45.78</em> for user â€œ<a href=\"mailto:*foo@example.org\" target=\"_blank\" rel=\"noopener\">*foo@example.org</a>â€<em> with password â€œ</em>suchsecretâ€<em> to your new server with ip </em>98.76.54.32<em>. A prerequisite is that on both machines the mailserver is up and running and the respective user is configured. Further, letâ€™s assume that on the new machine the user, as it makes sense, is called â€œ</em><a href=\"mailto:foo@example.org\" target=\"_blank\" rel=\"noopener\">foo@example.org</a>â€<em> again, but his password is â€œ</em>ssshhhhhâ€<em> now and that both MDAs require a </em>TLS<em>-secured connection, use standard </em>PLAIN<em> login method and are listening on </em>port 143*.</p>\n<p>To perform the migration now, run the following command:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./imapsync --host1 12.34.45.78 --user1 foo@example.org --password1 suchsecret --authmech1 PLAIN --tls1 --host2 98.76.54.32 --user2 foo@example.org --password2 ssshhhhh --authmech2 PLAIN --tls2</span><br></pre></td></tr></table></figure>\n<p>Now all mails should be transferred from <code>host1</code> through the imapsync client to <code>host2</code>, using nothing but the IMAP protocol. If you want to test if everything is working fine first, before actually transferring data, you could add the <code>--dry</code> option to the above command.</p>\n<p>To migrate multiple accounts at once, you could write a small scripts that takes username-password combinations from a text file, as described here: <a href=\"https://wiki.ubuntuusers.de/imapsync/#Massenmigration\" target=\"_blank\" rel=\"noopener\">https://wiki.ubuntuusers.de/imapsync/#Massenmigration</a> (although that article is in German, the code should be clear).</p>\n"},{"title":"My teck stack if I had to build an app today","date":"2016-11-11T22:04:56.000Z","_content":"\nWhat technology stack would I choose, if I had to develop a web application completely from scratch? That's the question this article will cover.\n\nFirst of all: by saying web application I'm referring to something between a plain static HTML page and an entire Facebook. Basically, an application that fulfills a certain domain of tasks for the user and that requires the usual features like user management, a backend database, multiple UI views and controls, etc. The size of application I'm thinking of could be a browser-based chat app, password-manager or something similar. Neither too simple, nor too complex.\n\nBack to the topic. Choosing the right technology for a web app feels much like customizing a new PC or even a new car. There are nearly endless options to be weighed to finally pick a bunch of them for a new web application. This super famous article [How it feels to learn JavaScript in 2016](https://hackernoon.com/how-it-feels-to-learn-javascript-in-2016-d3a717dd577f#.m1nodqu6f) complains about the confusing and ever-growing, chaotic jungle of new JavaScript frameworks in an ironical way. Indeed, I hear similar arguments from many developers these days. Many of them claim that code quality was getting worse in the web and that every newbie JavaScript programmer threw out his own new framework on yet another .io domain. Although that might be true to a certain extent, I personally still like the great technological variety and innovation. I love to browse GitHub, Reddit, Hackernews and Co. to discover new cool libraries to try out in a project some day. And here's what I would pick if I had to realize such a project right today and if there weren't any restrictions. \n\nOf course, the technology choice depends on the concrete project requirements to a certain extent, but not completely. Consequently, a new project is always a chance to try something new. ThoughtWorks just published their new [technology radar for 2016](https://www.thoughtworks.com/de/radar), where they separate into categories _adopt_, _trial_, _assess_ and _hold_. Of course, _hold_-techs are not an option for new projects and I actually pretty much agree with their views on what has to be in the _hold_ category. _Adopt_ basically are things that are modern, but also well-established enough to avoid too much risk. _Trial_-techs are more experimental and _assess_ are the latest fancy s***, so to say. Since I'm extremely eager to try out new things, my stack would probably mostly consist of technologies from the last category. So what would my stack now look like? Actually, I couldn't decide on one stack, but set up two: _the fancy one_ and _the super fancy one_. Additionally, I define their intersection as _the base stack_, which consists of fundamental tools etc. that both have in common.\n\n### The base stack\nFirst of all, I'd use __Git__ for version control, __Visual Studio Code__ as code editor and __GitLab__ for repository hosting and as build server. If I didn't had to implement user management myself, I'd pick __Auth0__ for that. For deployment, I'd use containers with __Docker__ on __DigitalOcean__ machines and if I needed multiple instances, __Rancher__ would help me to manage them. As reverse proxy in front of the backend I'd choose __nginx__ since it's extremely efficient, performant and has __HTTP/2.0__ support. For bundling, __Webpack__ would be my choice and task automation would be done using plain __npm scripts__. For styling the UI, I'd simply use __Bootstrap 4__ and __SCSS__.  \n\n### The super fancy stack\nThe key point here is that I'd want to abandon a traditional REST API in my project and use __GraphQL__ instead. The backend would be written in __NodeJS__ with [__Graffiti__](https://github.com/RisingStack/graffiti) as GraphQL implementation. I don't know much about the latter one, yet, except for that it's the de-facto GraphQL solution for Node. Why Node? Because it's simply the best choice for the web (my view...). It's performant, comfortable to develop and especially brings consistency by having JS in front- and backend. By always being quite up-to-date with the latest ES* features, Node doesn't get boring. Since GraphQL is told to work best with other Facebook technology, I'd not be that experimental here and build the frontend on __React__ plus __Relay__ (which is still completely new for me). Database would probably be a __MongoDB__ (JSON everywhere!) with [__Waterline__](https://github.com/balderdashy/waterline) ORM. To put a cherry on the cake, I'd also introduce __Redux__ in addition. I haven't worked with it much, yet, and I heard that it's kind of mind-blowing in the beginning. However, I consider its concept to cover a large potential to manage consistency in my app. The last thing here is that I desperately want is ES6 syntax. It isn't supported by the React compiler afaik (please correct me, if I'm wrong), so I'd use __Babel__ to have latest JavaScript features. If having to go mobile, __React Native__ would be the rational choice.\n\n### The fancy stack\nThis stack differs from the _super fancy stack_ in a few points. A key point is that it would not use GraphQL, but a good old REST API. This API would be written in __Go__, since I like the language - especially its efficiency and its good suitability for web development. More precisely, I'd use the [__Iris__](http://iris-go.com/) framework. I've read the documentation and it looked incredibly powerful to me (in terms of both functionality and perfomance). _(__EDIT:__ It's not what it seems! Please see my comment below!)._ For the frontend I'm balancing between __Angular 2__ and [__Aurelia__](http://aurelia.io/). Angular 2 is guaranteed to work for any potential case, is extremely powerful and has great community- and library support. However, Aurelia look promising, too, and probably is even more clear and less boilerplate code. Consequently, I'd give it a try. But if having to go mobile, I'd still favor Angular 2, since it perfectly aligns with __Ionic 2__.\n\nTwo other options, which look really interesting to me are __Meteor__ and __HorizonJS__. However, I'm not sure, if it's a good idea to commit to only one comprehensive framework through the full stack.\n\nSo these are my two alternative ways through the webdev jungle - btw, [this good article](https://medium.freecodecamp.com/a-study-plan-to-cure-javascript-fatigue-8ad3a54f2eb1#.3ri3a1fdv) describes another one, especially for newcomer web developers. Sorry, that I haven't justified all choices. Actually, as you probably know, if you're a developer, subjective views like these often aren't even based on pure rational considerations, but are rather emotional and spontaneous.\n\nPlease feel free to give me feedback on my tech stack of choice! \n\n__EDIT:__ Another framework Iâ€™d really like to try out is [InfernoJS](https://infernojs.org/), because it claims to be extremely lightweight and performant. However, before using Inferno, one should probably be familiar with React, since it uses very similar concepts and syntaxes.\n\n__EDIT 2:__ After having read [this article](http://www.florinpatan.ro/2016/10/why-you-should-not-use-iris-for-your-go.html) and having done some further research on the Iris framework I really have to retract my above statement that Iâ€™d use it as a web backend. While it looks nice on paper, after diving a little deeper I really have to admit that itâ€™d be morally tenable to support the authors of that project. So please forget about Iris and take a look at [Beego](https://beego.me/) instead.","source":"_posts/my-teck-stack-if-i-had-to-build-an-app-today.md","raw":"---\ntitle: My teck stack if I had to build an app today\ndate: 2016-11-11 23:04:56\ntags:\n---\n\nWhat technology stack would I choose, if I had to develop a web application completely from scratch? That's the question this article will cover.\n\nFirst of all: by saying web application I'm referring to something between a plain static HTML page and an entire Facebook. Basically, an application that fulfills a certain domain of tasks for the user and that requires the usual features like user management, a backend database, multiple UI views and controls, etc. The size of application I'm thinking of could be a browser-based chat app, password-manager or something similar. Neither too simple, nor too complex.\n\nBack to the topic. Choosing the right technology for a web app feels much like customizing a new PC or even a new car. There are nearly endless options to be weighed to finally pick a bunch of them for a new web application. This super famous article [How it feels to learn JavaScript in 2016](https://hackernoon.com/how-it-feels-to-learn-javascript-in-2016-d3a717dd577f#.m1nodqu6f) complains about the confusing and ever-growing, chaotic jungle of new JavaScript frameworks in an ironical way. Indeed, I hear similar arguments from many developers these days. Many of them claim that code quality was getting worse in the web and that every newbie JavaScript programmer threw out his own new framework on yet another .io domain. Although that might be true to a certain extent, I personally still like the great technological variety and innovation. I love to browse GitHub, Reddit, Hackernews and Co. to discover new cool libraries to try out in a project some day. And here's what I would pick if I had to realize such a project right today and if there weren't any restrictions. \n\nOf course, the technology choice depends on the concrete project requirements to a certain extent, but not completely. Consequently, a new project is always a chance to try something new. ThoughtWorks just published their new [technology radar for 2016](https://www.thoughtworks.com/de/radar), where they separate into categories _adopt_, _trial_, _assess_ and _hold_. Of course, _hold_-techs are not an option for new projects and I actually pretty much agree with their views on what has to be in the _hold_ category. _Adopt_ basically are things that are modern, but also well-established enough to avoid too much risk. _Trial_-techs are more experimental and _assess_ are the latest fancy s***, so to say. Since I'm extremely eager to try out new things, my stack would probably mostly consist of technologies from the last category. So what would my stack now look like? Actually, I couldn't decide on one stack, but set up two: _the fancy one_ and _the super fancy one_. Additionally, I define their intersection as _the base stack_, which consists of fundamental tools etc. that both have in common.\n\n### The base stack\nFirst of all, I'd use __Git__ for version control, __Visual Studio Code__ as code editor and __GitLab__ for repository hosting and as build server. If I didn't had to implement user management myself, I'd pick __Auth0__ for that. For deployment, I'd use containers with __Docker__ on __DigitalOcean__ machines and if I needed multiple instances, __Rancher__ would help me to manage them. As reverse proxy in front of the backend I'd choose __nginx__ since it's extremely efficient, performant and has __HTTP/2.0__ support. For bundling, __Webpack__ would be my choice and task automation would be done using plain __npm scripts__. For styling the UI, I'd simply use __Bootstrap 4__ and __SCSS__.  \n\n### The super fancy stack\nThe key point here is that I'd want to abandon a traditional REST API in my project and use __GraphQL__ instead. The backend would be written in __NodeJS__ with [__Graffiti__](https://github.com/RisingStack/graffiti) as GraphQL implementation. I don't know much about the latter one, yet, except for that it's the de-facto GraphQL solution for Node. Why Node? Because it's simply the best choice for the web (my view...). It's performant, comfortable to develop and especially brings consistency by having JS in front- and backend. By always being quite up-to-date with the latest ES* features, Node doesn't get boring. Since GraphQL is told to work best with other Facebook technology, I'd not be that experimental here and build the frontend on __React__ plus __Relay__ (which is still completely new for me). Database would probably be a __MongoDB__ (JSON everywhere!) with [__Waterline__](https://github.com/balderdashy/waterline) ORM. To put a cherry on the cake, I'd also introduce __Redux__ in addition. I haven't worked with it much, yet, and I heard that it's kind of mind-blowing in the beginning. However, I consider its concept to cover a large potential to manage consistency in my app. The last thing here is that I desperately want is ES6 syntax. It isn't supported by the React compiler afaik (please correct me, if I'm wrong), so I'd use __Babel__ to have latest JavaScript features. If having to go mobile, __React Native__ would be the rational choice.\n\n### The fancy stack\nThis stack differs from the _super fancy stack_ in a few points. A key point is that it would not use GraphQL, but a good old REST API. This API would be written in __Go__, since I like the language - especially its efficiency and its good suitability for web development. More precisely, I'd use the [__Iris__](http://iris-go.com/) framework. I've read the documentation and it looked incredibly powerful to me (in terms of both functionality and perfomance). _(__EDIT:__ It's not what it seems! Please see my comment below!)._ For the frontend I'm balancing between __Angular 2__ and [__Aurelia__](http://aurelia.io/). Angular 2 is guaranteed to work for any potential case, is extremely powerful and has great community- and library support. However, Aurelia look promising, too, and probably is even more clear and less boilerplate code. Consequently, I'd give it a try. But if having to go mobile, I'd still favor Angular 2, since it perfectly aligns with __Ionic 2__.\n\nTwo other options, which look really interesting to me are __Meteor__ and __HorizonJS__. However, I'm not sure, if it's a good idea to commit to only one comprehensive framework through the full stack.\n\nSo these are my two alternative ways through the webdev jungle - btw, [this good article](https://medium.freecodecamp.com/a-study-plan-to-cure-javascript-fatigue-8ad3a54f2eb1#.3ri3a1fdv) describes another one, especially for newcomer web developers. Sorry, that I haven't justified all choices. Actually, as you probably know, if you're a developer, subjective views like these often aren't even based on pure rational considerations, but are rather emotional and spontaneous.\n\nPlease feel free to give me feedback on my tech stack of choice! \n\n__EDIT:__ Another framework Iâ€™d really like to try out is [InfernoJS](https://infernojs.org/), because it claims to be extremely lightweight and performant. However, before using Inferno, one should probably be familiar with React, since it uses very similar concepts and syntaxes.\n\n__EDIT 2:__ After having read [this article](http://www.florinpatan.ro/2016/10/why-you-should-not-use-iris-for-your-go.html) and having done some further research on the Iris framework I really have to retract my above statement that Iâ€™d use it as a web backend. While it looks nice on paper, after diving a little deeper I really have to admit that itâ€™d be morally tenable to support the authors of that project. So please forget about Iris and take a look at [Beego](https://beego.me/) instead.","slug":"my-teck-stack-if-i-had-to-build-an-app-today","published":1,"updated":"2018-03-19T09:30:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2giomd000lcxrg6sacuclm","content":"<p>What technology stack would I choose, if I had to develop a web application completely from scratch? Thatâ€™s the question this article will cover.</p>\n<p>First of all: by saying web application Iâ€™m referring to something between a plain static HTML page and an entire Facebook. Basically, an application that fulfills a certain domain of tasks for the user and that requires the usual features like user management, a backend database, multiple UI views and controls, etc. The size of application Iâ€™m thinking of could be a browser-based chat app, password-manager or something similar. Neither too simple, nor too complex.</p>\n<p>Back to the topic. Choosing the right technology for a web app feels much like customizing a new PC or even a new car. There are nearly endless options to be weighed to finally pick a bunch of them for a new web application. This super famous article <a href=\"https://hackernoon.com/how-it-feels-to-learn-javascript-in-2016-d3a717dd577f#.m1nodqu6f\" target=\"_blank\" rel=\"noopener\">How it feels to learn JavaScript in 2016</a> complains about the confusing and ever-growing, chaotic jungle of new JavaScript frameworks in an ironical way. Indeed, I hear similar arguments from many developers these days. Many of them claim that code quality was getting worse in the web and that every newbie JavaScript programmer threw out his own new framework on yet another .io domain. Although that might be true to a certain extent, I personally still like the great technological variety and innovation. I love to browse GitHub, Reddit, Hackernews and Co. to discover new cool libraries to try out in a project some day. And hereâ€™s what I would pick if I had to realize such a project right today and if there werenâ€™t any restrictions. </p>\n<p>Of course, the technology choice depends on the concrete project requirements to a certain extent, but not completely. Consequently, a new project is always a chance to try something new. ThoughtWorks just published their new <a href=\"https://www.thoughtworks.com/de/radar\" target=\"_blank\" rel=\"noopener\">technology radar for 2016</a>, where they separate into categories <em>adopt</em>, <em>trial</em>, <em>assess</em> and <em>hold</em>. Of course, <em>hold</em>-techs are not an option for new projects and I actually pretty much agree with their views on what has to be in the <em>hold</em> category. <em>Adopt</em> basically are things that are modern, but also well-established enough to avoid too much risk. <em>Trial</em>-techs are more experimental and <em>assess</em> are the latest fancy s***, so to say. Since Iâ€™m extremely eager to try out new things, my stack would probably mostly consist of technologies from the last category. So what would my stack now look like? Actually, I couldnâ€™t decide on one stack, but set up two: <em>the fancy one</em> and <em>the super fancy one</em>. Additionally, I define their intersection as <em>the base stack</em>, which consists of fundamental tools etc. that both have in common.</p>\n<h3 id=\"The-base-stack\"><a href=\"#The-base-stack\" class=\"headerlink\" title=\"The base stack\"></a>The base stack</h3><p>First of all, Iâ€™d use <strong>Git</strong> for version control, <strong>Visual Studio Code</strong> as code editor and <strong>GitLab</strong> for repository hosting and as build server. If I didnâ€™t had to implement user management myself, Iâ€™d pick <strong>Auth0</strong> for that. For deployment, Iâ€™d use containers with <strong>Docker</strong> on <strong>DigitalOcean</strong> machines and if I needed multiple instances, <strong>Rancher</strong> would help me to manage them. As reverse proxy in front of the backend Iâ€™d choose <strong>nginx</strong> since itâ€™s extremely efficient, performant and has <strong>HTTP/2.0</strong> support. For bundling, <strong>Webpack</strong> would be my choice and task automation would be done using plain <strong>npm scripts</strong>. For styling the UI, Iâ€™d simply use <strong>Bootstrap 4</strong> and <strong>SCSS</strong>.  </p>\n<h3 id=\"The-super-fancy-stack\"><a href=\"#The-super-fancy-stack\" class=\"headerlink\" title=\"The super fancy stack\"></a>The super fancy stack</h3><p>The key point here is that Iâ€™d want to abandon a traditional REST API in my project and use <strong>GraphQL</strong> instead. The backend would be written in <strong>NodeJS</strong> with <a href=\"https://github.com/RisingStack/graffiti\" target=\"_blank\" rel=\"noopener\"><strong>Graffiti</strong></a> as GraphQL implementation. I donâ€™t know much about the latter one, yet, except for that itâ€™s the de-facto GraphQL solution for Node. Why Node? Because itâ€™s simply the best choice for the web (my viewâ€¦). Itâ€™s performant, comfortable to develop and especially brings consistency by having JS in front- and backend. By always being quite up-to-date with the latest ES* features, Node doesnâ€™t get boring. Since GraphQL is told to work best with other Facebook technology, Iâ€™d not be that experimental here and build the frontend on <strong>React</strong> plus <strong>Relay</strong> (which is still completely new for me). Database would probably be a <strong>MongoDB</strong> (JSON everywhere!) with <a href=\"https://github.com/balderdashy/waterline\" target=\"_blank\" rel=\"noopener\"><strong>Waterline</strong></a> ORM. To put a cherry on the cake, Iâ€™d also introduce <strong>Redux</strong> in addition. I havenâ€™t worked with it much, yet, and I heard that itâ€™s kind of mind-blowing in the beginning. However, I consider its concept to cover a large potential to manage consistency in my app. The last thing here is that I desperately want is ES6 syntax. It isnâ€™t supported by the React compiler afaik (please correct me, if Iâ€™m wrong), so Iâ€™d use <strong>Babel</strong> to have latest JavaScript features. If having to go mobile, <strong>React Native</strong> would be the rational choice.</p>\n<h3 id=\"The-fancy-stack\"><a href=\"#The-fancy-stack\" class=\"headerlink\" title=\"The fancy stack\"></a>The fancy stack</h3><p>This stack differs from the <em>super fancy stack</em> in a few points. A key point is that it would not use GraphQL, but a good old REST API. This API would be written in <strong>Go</strong>, since I like the language - especially its efficiency and its good suitability for web development. More precisely, Iâ€™d use the <a href=\"http://iris-go.com/\" target=\"_blank\" rel=\"noopener\"><strong>Iris</strong></a> framework. Iâ€™ve read the documentation and it looked incredibly powerful to me (in terms of both functionality and perfomance). <em>(<strong>EDIT:</strong> Itâ€™s not what it seems! Please see my comment below!).</em> For the frontend Iâ€™m balancing between <strong>Angular 2</strong> and <a href=\"http://aurelia.io/\" target=\"_blank\" rel=\"noopener\"><strong>Aurelia</strong></a>. Angular 2 is guaranteed to work for any potential case, is extremely powerful and has great community- and library support. However, Aurelia look promising, too, and probably is even more clear and less boilerplate code. Consequently, Iâ€™d give it a try. But if having to go mobile, Iâ€™d still favor Angular 2, since it perfectly aligns with <strong>Ionic 2</strong>.</p>\n<p>Two other options, which look really interesting to me are <strong>Meteor</strong> and <strong>HorizonJS</strong>. However, Iâ€™m not sure, if itâ€™s a good idea to commit to only one comprehensive framework through the full stack.</p>\n<p>So these are my two alternative ways through the webdev jungle - btw, <a href=\"https://medium.freecodecamp.com/a-study-plan-to-cure-javascript-fatigue-8ad3a54f2eb1#.3ri3a1fdv\" target=\"_blank\" rel=\"noopener\">this good article</a> describes another one, especially for newcomer web developers. Sorry, that I havenâ€™t justified all choices. Actually, as you probably know, if youâ€™re a developer, subjective views like these often arenâ€™t even based on pure rational considerations, but are rather emotional and spontaneous.</p>\n<p>Please feel free to give me feedback on my tech stack of choice! </p>\n<p><strong>EDIT:</strong> Another framework Iâ€™d really like to try out is <a href=\"https://infernojs.org/\" target=\"_blank\" rel=\"noopener\">InfernoJS</a>, because it claims to be extremely lightweight and performant. However, before using Inferno, one should probably be familiar with React, since it uses very similar concepts and syntaxes.</p>\n<p><strong>EDIT 2:</strong> After having read <a href=\"http://www.florinpatan.ro/2016/10/why-you-should-not-use-iris-for-your-go.html\" target=\"_blank\" rel=\"noopener\">this article</a> and having done some further research on the Iris framework I really have to retract my above statement that Iâ€™d use it as a web backend. While it looks nice on paper, after diving a little deeper I really have to admit that itâ€™d be morally tenable to support the authors of that project. So please forget about Iris and take a look at <a href=\"https://beego.me/\" target=\"_blank\" rel=\"noopener\">Beego</a> instead.</p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<p>What technology stack would I choose, if I had to develop a web application completely from scratch? Thatâ€™s the question this article will cover.</p>\n<p>First of all: by saying web application Iâ€™m referring to something between a plain static HTML page and an entire Facebook. Basically, an application that fulfills a certain domain of tasks for the user and that requires the usual features like user management, a backend database, multiple UI views and controls, etc. The size of application Iâ€™m thinking of could be a browser-based chat app, password-manager or something similar. Neither too simple, nor too complex.</p>\n<p>Back to the topic. Choosing the right technology for a web app feels much like customizing a new PC or even a new car. There are nearly endless options to be weighed to finally pick a bunch of them for a new web application. This super famous article <a href=\"https://hackernoon.com/how-it-feels-to-learn-javascript-in-2016-d3a717dd577f#.m1nodqu6f\" target=\"_blank\" rel=\"noopener\">How it feels to learn JavaScript in 2016</a> complains about the confusing and ever-growing, chaotic jungle of new JavaScript frameworks in an ironical way. Indeed, I hear similar arguments from many developers these days. Many of them claim that code quality was getting worse in the web and that every newbie JavaScript programmer threw out his own new framework on yet another .io domain. Although that might be true to a certain extent, I personally still like the great technological variety and innovation. I love to browse GitHub, Reddit, Hackernews and Co. to discover new cool libraries to try out in a project some day. And hereâ€™s what I would pick if I had to realize such a project right today and if there werenâ€™t any restrictions. </p>\n<p>Of course, the technology choice depends on the concrete project requirements to a certain extent, but not completely. Consequently, a new project is always a chance to try something new. ThoughtWorks just published their new <a href=\"https://www.thoughtworks.com/de/radar\" target=\"_blank\" rel=\"noopener\">technology radar for 2016</a>, where they separate into categories <em>adopt</em>, <em>trial</em>, <em>assess</em> and <em>hold</em>. Of course, <em>hold</em>-techs are not an option for new projects and I actually pretty much agree with their views on what has to be in the <em>hold</em> category. <em>Adopt</em> basically are things that are modern, but also well-established enough to avoid too much risk. <em>Trial</em>-techs are more experimental and <em>assess</em> are the latest fancy s***, so to say. Since Iâ€™m extremely eager to try out new things, my stack would probably mostly consist of technologies from the last category. So what would my stack now look like? Actually, I couldnâ€™t decide on one stack, but set up two: <em>the fancy one</em> and <em>the super fancy one</em>. Additionally, I define their intersection as <em>the base stack</em>, which consists of fundamental tools etc. that both have in common.</p>\n<h3 id=\"The-base-stack\"><a href=\"#The-base-stack\" class=\"headerlink\" title=\"The base stack\"></a>The base stack</h3><p>First of all, Iâ€™d use <strong>Git</strong> for version control, <strong>Visual Studio Code</strong> as code editor and <strong>GitLab</strong> for repository hosting and as build server. If I didnâ€™t had to implement user management myself, Iâ€™d pick <strong>Auth0</strong> for that. For deployment, Iâ€™d use containers with <strong>Docker</strong> on <strong>DigitalOcean</strong> machines and if I needed multiple instances, <strong>Rancher</strong> would help me to manage them. As reverse proxy in front of the backend Iâ€™d choose <strong>nginx</strong> since itâ€™s extremely efficient, performant and has <strong>HTTP/2.0</strong> support. For bundling, <strong>Webpack</strong> would be my choice and task automation would be done using plain <strong>npm scripts</strong>. For styling the UI, Iâ€™d simply use <strong>Bootstrap 4</strong> and <strong>SCSS</strong>.  </p>\n<h3 id=\"The-super-fancy-stack\"><a href=\"#The-super-fancy-stack\" class=\"headerlink\" title=\"The super fancy stack\"></a>The super fancy stack</h3><p>The key point here is that Iâ€™d want to abandon a traditional REST API in my project and use <strong>GraphQL</strong> instead. The backend would be written in <strong>NodeJS</strong> with <a href=\"https://github.com/RisingStack/graffiti\" target=\"_blank\" rel=\"noopener\"><strong>Graffiti</strong></a> as GraphQL implementation. I donâ€™t know much about the latter one, yet, except for that itâ€™s the de-facto GraphQL solution for Node. Why Node? Because itâ€™s simply the best choice for the web (my viewâ€¦). Itâ€™s performant, comfortable to develop and especially brings consistency by having JS in front- and backend. By always being quite up-to-date with the latest ES* features, Node doesnâ€™t get boring. Since GraphQL is told to work best with other Facebook technology, Iâ€™d not be that experimental here and build the frontend on <strong>React</strong> plus <strong>Relay</strong> (which is still completely new for me). Database would probably be a <strong>MongoDB</strong> (JSON everywhere!) with <a href=\"https://github.com/balderdashy/waterline\" target=\"_blank\" rel=\"noopener\"><strong>Waterline</strong></a> ORM. To put a cherry on the cake, Iâ€™d also introduce <strong>Redux</strong> in addition. I havenâ€™t worked with it much, yet, and I heard that itâ€™s kind of mind-blowing in the beginning. However, I consider its concept to cover a large potential to manage consistency in my app. The last thing here is that I desperately want is ES6 syntax. It isnâ€™t supported by the React compiler afaik (please correct me, if Iâ€™m wrong), so Iâ€™d use <strong>Babel</strong> to have latest JavaScript features. If having to go mobile, <strong>React Native</strong> would be the rational choice.</p>\n<h3 id=\"The-fancy-stack\"><a href=\"#The-fancy-stack\" class=\"headerlink\" title=\"The fancy stack\"></a>The fancy stack</h3><p>This stack differs from the <em>super fancy stack</em> in a few points. A key point is that it would not use GraphQL, but a good old REST API. This API would be written in <strong>Go</strong>, since I like the language - especially its efficiency and its good suitability for web development. More precisely, Iâ€™d use the <a href=\"http://iris-go.com/\" target=\"_blank\" rel=\"noopener\"><strong>Iris</strong></a> framework. Iâ€™ve read the documentation and it looked incredibly powerful to me (in terms of both functionality and perfomance). <em>(<strong>EDIT:</strong> Itâ€™s not what it seems! Please see my comment below!).</em> For the frontend Iâ€™m balancing between <strong>Angular 2</strong> and <a href=\"http://aurelia.io/\" target=\"_blank\" rel=\"noopener\"><strong>Aurelia</strong></a>. Angular 2 is guaranteed to work for any potential case, is extremely powerful and has great community- and library support. However, Aurelia look promising, too, and probably is even more clear and less boilerplate code. Consequently, Iâ€™d give it a try. But if having to go mobile, Iâ€™d still favor Angular 2, since it perfectly aligns with <strong>Ionic 2</strong>.</p>\n<p>Two other options, which look really interesting to me are <strong>Meteor</strong> and <strong>HorizonJS</strong>. However, Iâ€™m not sure, if itâ€™s a good idea to commit to only one comprehensive framework through the full stack.</p>\n<p>So these are my two alternative ways through the webdev jungle - btw, <a href=\"https://medium.freecodecamp.com/a-study-plan-to-cure-javascript-fatigue-8ad3a54f2eb1#.3ri3a1fdv\" target=\"_blank\" rel=\"noopener\">this good article</a> describes another one, especially for newcomer web developers. Sorry, that I havenâ€™t justified all choices. Actually, as you probably know, if youâ€™re a developer, subjective views like these often arenâ€™t even based on pure rational considerations, but are rather emotional and spontaneous.</p>\n<p>Please feel free to give me feedback on my tech stack of choice! </p>\n<p><strong>EDIT:</strong> Another framework Iâ€™d really like to try out is <a href=\"https://infernojs.org/\" target=\"_blank\" rel=\"noopener\">InfernoJS</a>, because it claims to be extremely lightweight and performant. However, before using Inferno, one should probably be familiar with React, since it uses very similar concepts and syntaxes.</p>\n<p><strong>EDIT 2:</strong> After having read <a href=\"http://www.florinpatan.ro/2016/10/why-you-should-not-use-iris-for-your-go.html\" target=\"_blank\" rel=\"noopener\">this article</a> and having done some further research on the Iris framework I really have to retract my above statement that Iâ€™d use it as a web backend. While it looks nice on paper, after diving a little deeper I really have to admit that itâ€™d be morally tenable to support the authors of that project. So please forget about Iris and take a look at <a href=\"https://beego.me/\" target=\"_blank\" rel=\"noopener\">Beego</a> instead.</p>\n"},{"title":"ML: Telegram chat message classification","date":"2017-02-28T22:10:05.000Z","_content":"\n### Intro\nFirst of all, a short disclaimer: I'm not an expert in machine learning at all. In fact I'm in a rather early stage of the learning process, have basic knowledge and this project is kind of my first practical hands-on ML. I've done the [machine learning course](https://www.youtube.com/user/UWCSE/playlists?sort=dd&shelf_id=16&view=50) by [Pedro Domingos](https://homes.cs.washington.edu/~pedrod/) at University of Washington, [Intro to Machine Learning](https://www.udacity.com/course/intro-to-machine-learning--ud120) by Udacity and Google and the [Machine Learning 1 lecture at Karlsruhe Institute Of Technology](https://his.anthropomatik.kit.edu/english/28_315.php), all of which I can really recommend.\nAfter having gathered all that theoretical knowledge, I wanted to try something practical on my own. I decided to learn a simple classifier for chat messages from my [Telegram](https://telegram.com) messenger history. I wanted to learn a program that can, given a chat message, tell who the sender of that message is. I further got inspired after having read the papers related to Facebook's [fastText](https://github.com/facebookresearch/fastText) text classification algorithm. In their examples they classify Wikipedia abstracts / descriptions to [DBPedia](https://dbpedia.org) classes or news article headlines to their respective news categories, only based on plain, natural words. Basically these problems are very similar to mine, so I decided to give it a try. Since I found that many text classifiers are learned using the Naive Bayes algorithm (especially popular in spam detection and part of [SpamAssassin](http://spamassassin.apache.org/)) and it's really easy to understand, I decided to go for that one, too. Inspired by [this article](http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/), where the sentiment of tweets is analyzed, I chose to also use the [natural language toolkit](http://www.nltk.org/) for Python. Another option would have been [sklearn](http://scikit-learn.org/), but NLTK also provided some useful utilities beyond the pure ML scope. \n\nAll of my __code is [available on GitHub](https://github.com/n1try/tg-chat-classification/)__.\n\n### Basic Steps\n1. The very first step was to download the data, namely the chat messages. Luckily, Telegram has an open API. However it's not a classical REST API, but instead they're using the [MTProto](https://core.telegram.org/mtproto) protocol. I found [vysheng/tg](https://github.com/vysheng/tg) as a cool C++-written commandline client on GitHub as well as [tvdstaaij/telegram-history-dump](https://github.com/tvdstaaij/telegram-history-dump) as a Ruby script to automate the history download for a set of users / chat partners. I told the script (ran in a Docker container, since I didn't want to install Ruby) to fetch at max 40,000 messages for my top three chat partners (let's call them _M_, _P_ and _J_). The outcome were three [JSON Lines](http://jsonlines.org/) files.\n2. To pre-process these files as needed for my learning algorithm, I wrote a Python script that extracted only message text and sender from all incoming messages and dumped these data to a JSON file. Additionally I also extracted the same information for all outgoing messages, i.e. all messages where the sender was me. Consequently, there are four classes: __C = { _M_, _P_, _J_, _F_ }__\n3. Another data-preprocessing step was to convert the JSON objects with class names as keys for message-arrays to one large list of tuples of the form _(text, label)_, where _label_ is the name of the message's sender and _text_ is the respective message text. In this step I also discarded words with a length of less than 2 characters and converted everything to lower case.\n4. Next step was to extract the features. In text classification, there is often one binary (_contains_ / _contains not_) feature for every possible word. So if all messages in total comprise X different words, there will be a X-dimensional feature vector.\n5. Last step before actually training the classifier is to compute the feature vector for every messages. For examples if the total feature set is `['in', 'case', 'of', 'fire', 'coffee', 'we', 'trust']`, the resultung feature vector for a message _\"in coffee we trust\"_ would be `('in'=True, 'case'=False, 'of'=False, 'fire'=False, 'coffee'=True, 'we'=True, 'trust'=True)`.\n6. One more minor thing: shuffle the feature set so that the order of messages and message senders is random. Also divide the feature set into training- and test data, where test data contains about 10 % of the number of messages in the train data.\n7. Train [nltk.NaiveBayesClassifier](http://www.nltk.org/api/nltk.classify.html) classifier. This is really just one line of code.\n8. Use the returned classifier to predict classes for the test messages, validate them and compute the accuracy.\n\nUsing that basic initial setup on a set of __37257 messages__, (7931 from M, 9795 from P, 9314 from F and 10217 from J), I ended up with an __accuracy of 0.58__. There seemed to be room for optimization.\n\n### Optimizations\n* Inspired by _fastText_, I decided to include n-grams. This seemed resonable to me, because intuitively I'd say that single words a way less characteristic for a person's writing style than certain phrases. I extended the feature list from step 4 by all possible __bi- and tri-grams__, which are easy to compute with NLTK. Actually I'm not taking ALL bi- and tri-grams and I'm not even take all single words as features. Reason for that is that there were approx. 35k different words in the dataset. Plus the n-grams this would make an extremely multi-dimensional feature vector and as it turned out, it was way to complex for my 16 GB MacBook Pro to compute. Consequently, I only took the __top 5000 single words, bigrams and trigrams__, ranked descending by their overall frequency. \n* Since NLTK already provides a corpus of __stopwords__ (like \"in\", \"and\", \"of\", etc.), which are obviously not characteristic for a person's style of chatting, I decided to remove them (the German ones) from the message set in step 2.\n\nWith these optimizations, I ended up with an __accuracy of 0.61__ after a training time of 348 seconds (I didn't log testing time at that point).\n\n### Conclusion\nCertainly 61 % accuracy isn't really a good classifier, but at least significantly better than random guessing (chance of 1/4 in this case). However, I trained a __fastText__ classifier on my data as a comparison baseline and it even only reached __60 % accuracy__ (but with a much better __training time of only 0.66 seconds__). \nMy intuitive explanation for these rather bad results is the complexity of the problem itself. Given only a set of words without any context and semantics, it's not only hard for a machine to predict the message's sender but also for a human. \nMoreover, given more training data (I'd need a longer message history) and more computing power to handle larger feature sets, the accuracy might further improve slightly.\nActually, the practical relevance of this project isn't quit high anyway, but it was a good practice for me to get into the basics of ML and it's really fun!\n\nPlease leave me feedback if you like to.","source":"_posts/ml-telegram-chat-message-classification.md","raw":"---\ntitle: 'ML: Telegram chat message classification'\ndate: 2017-02-28 23:10:05\ntags:\n---\n\n### Intro\nFirst of all, a short disclaimer: I'm not an expert in machine learning at all. In fact I'm in a rather early stage of the learning process, have basic knowledge and this project is kind of my first practical hands-on ML. I've done the [machine learning course](https://www.youtube.com/user/UWCSE/playlists?sort=dd&shelf_id=16&view=50) by [Pedro Domingos](https://homes.cs.washington.edu/~pedrod/) at University of Washington, [Intro to Machine Learning](https://www.udacity.com/course/intro-to-machine-learning--ud120) by Udacity and Google and the [Machine Learning 1 lecture at Karlsruhe Institute Of Technology](https://his.anthropomatik.kit.edu/english/28_315.php), all of which I can really recommend.\nAfter having gathered all that theoretical knowledge, I wanted to try something practical on my own. I decided to learn a simple classifier for chat messages from my [Telegram](https://telegram.com) messenger history. I wanted to learn a program that can, given a chat message, tell who the sender of that message is. I further got inspired after having read the papers related to Facebook's [fastText](https://github.com/facebookresearch/fastText) text classification algorithm. In their examples they classify Wikipedia abstracts / descriptions to [DBPedia](https://dbpedia.org) classes or news article headlines to their respective news categories, only based on plain, natural words. Basically these problems are very similar to mine, so I decided to give it a try. Since I found that many text classifiers are learned using the Naive Bayes algorithm (especially popular in spam detection and part of [SpamAssassin](http://spamassassin.apache.org/)) and it's really easy to understand, I decided to go for that one, too. Inspired by [this article](http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/), where the sentiment of tweets is analyzed, I chose to also use the [natural language toolkit](http://www.nltk.org/) for Python. Another option would have been [sklearn](http://scikit-learn.org/), but NLTK also provided some useful utilities beyond the pure ML scope. \n\nAll of my __code is [available on GitHub](https://github.com/n1try/tg-chat-classification/)__.\n\n### Basic Steps\n1. The very first step was to download the data, namely the chat messages. Luckily, Telegram has an open API. However it's not a classical REST API, but instead they're using the [MTProto](https://core.telegram.org/mtproto) protocol. I found [vysheng/tg](https://github.com/vysheng/tg) as a cool C++-written commandline client on GitHub as well as [tvdstaaij/telegram-history-dump](https://github.com/tvdstaaij/telegram-history-dump) as a Ruby script to automate the history download for a set of users / chat partners. I told the script (ran in a Docker container, since I didn't want to install Ruby) to fetch at max 40,000 messages for my top three chat partners (let's call them _M_, _P_ and _J_). The outcome were three [JSON Lines](http://jsonlines.org/) files.\n2. To pre-process these files as needed for my learning algorithm, I wrote a Python script that extracted only message text and sender from all incoming messages and dumped these data to a JSON file. Additionally I also extracted the same information for all outgoing messages, i.e. all messages where the sender was me. Consequently, there are four classes: __C = { _M_, _P_, _J_, _F_ }__\n3. Another data-preprocessing step was to convert the JSON objects with class names as keys for message-arrays to one large list of tuples of the form _(text, label)_, where _label_ is the name of the message's sender and _text_ is the respective message text. In this step I also discarded words with a length of less than 2 characters and converted everything to lower case.\n4. Next step was to extract the features. In text classification, there is often one binary (_contains_ / _contains not_) feature for every possible word. So if all messages in total comprise X different words, there will be a X-dimensional feature vector.\n5. Last step before actually training the classifier is to compute the feature vector for every messages. For examples if the total feature set is `['in', 'case', 'of', 'fire', 'coffee', 'we', 'trust']`, the resultung feature vector for a message _\"in coffee we trust\"_ would be `('in'=True, 'case'=False, 'of'=False, 'fire'=False, 'coffee'=True, 'we'=True, 'trust'=True)`.\n6. One more minor thing: shuffle the feature set so that the order of messages and message senders is random. Also divide the feature set into training- and test data, where test data contains about 10 % of the number of messages in the train data.\n7. Train [nltk.NaiveBayesClassifier](http://www.nltk.org/api/nltk.classify.html) classifier. This is really just one line of code.\n8. Use the returned classifier to predict classes for the test messages, validate them and compute the accuracy.\n\nUsing that basic initial setup on a set of __37257 messages__, (7931 from M, 9795 from P, 9314 from F and 10217 from J), I ended up with an __accuracy of 0.58__. There seemed to be room for optimization.\n\n### Optimizations\n* Inspired by _fastText_, I decided to include n-grams. This seemed resonable to me, because intuitively I'd say that single words a way less characteristic for a person's writing style than certain phrases. I extended the feature list from step 4 by all possible __bi- and tri-grams__, which are easy to compute with NLTK. Actually I'm not taking ALL bi- and tri-grams and I'm not even take all single words as features. Reason for that is that there were approx. 35k different words in the dataset. Plus the n-grams this would make an extremely multi-dimensional feature vector and as it turned out, it was way to complex for my 16 GB MacBook Pro to compute. Consequently, I only took the __top 5000 single words, bigrams and trigrams__, ranked descending by their overall frequency. \n* Since NLTK already provides a corpus of __stopwords__ (like \"in\", \"and\", \"of\", etc.), which are obviously not characteristic for a person's style of chatting, I decided to remove them (the German ones) from the message set in step 2.\n\nWith these optimizations, I ended up with an __accuracy of 0.61__ after a training time of 348 seconds (I didn't log testing time at that point).\n\n### Conclusion\nCertainly 61 % accuracy isn't really a good classifier, but at least significantly better than random guessing (chance of 1/4 in this case). However, I trained a __fastText__ classifier on my data as a comparison baseline and it even only reached __60 % accuracy__ (but with a much better __training time of only 0.66 seconds__). \nMy intuitive explanation for these rather bad results is the complexity of the problem itself. Given only a set of words without any context and semantics, it's not only hard for a machine to predict the message's sender but also for a human. \nMoreover, given more training data (I'd need a longer message history) and more computing power to handle larger feature sets, the accuracy might further improve slightly.\nActually, the practical relevance of this project isn't quit high anyway, but it was a good practice for me to get into the basics of ML and it's really fun!\n\nPlease leave me feedback if you like to.","slug":"ml-telegram-chat-message-classification","published":1,"updated":"2018-03-19T09:30:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2giomd000mcxrg7n4da59t","content":"<h3 id=\"Intro\"><a href=\"#Intro\" class=\"headerlink\" title=\"Intro\"></a>Intro</h3><p>First of all, a short disclaimer: Iâ€™m not an expert in machine learning at all. In fact Iâ€™m in a rather early stage of the learning process, have basic knowledge and this project is kind of my first practical hands-on ML. Iâ€™ve done the <a href=\"https://www.youtube.com/user/UWCSE/playlists?sort=dd&amp;shelf_id=16&amp;view=50\" target=\"_blank\" rel=\"noopener\">machine learning course</a> by <a href=\"https://homes.cs.washington.edu/~pedrod/\" target=\"_blank\" rel=\"noopener\">Pedro Domingos</a> at University of Washington, <a href=\"https://www.udacity.com/course/intro-to-machine-learning--ud120\" target=\"_blank\" rel=\"noopener\">Intro to Machine Learning</a> by Udacity and Google and the <a href=\"https://his.anthropomatik.kit.edu/english/28_315.php\" target=\"_blank\" rel=\"noopener\">Machine Learning 1 lecture at Karlsruhe Institute Of Technology</a>, all of which I can really recommend.<br>After having gathered all that theoretical knowledge, I wanted to try something practical on my own. I decided to learn a simple classifier for chat messages from my <a href=\"https://telegram.com\" target=\"_blank\" rel=\"noopener\">Telegram</a> messenger history. I wanted to learn a program that can, given a chat message, tell who the sender of that message is. I further got inspired after having read the papers related to Facebookâ€™s <a href=\"https://github.com/facebookresearch/fastText\" target=\"_blank\" rel=\"noopener\">fastText</a> text classification algorithm. In their examples they classify Wikipedia abstracts / descriptions to <a href=\"https://dbpedia.org\" target=\"_blank\" rel=\"noopener\">DBPedia</a> classes or news article headlines to their respective news categories, only based on plain, natural words. Basically these problems are very similar to mine, so I decided to give it a try. Since I found that many text classifiers are learned using the Naive Bayes algorithm (especially popular in spam detection and part of <a href=\"http://spamassassin.apache.org/\" target=\"_blank\" rel=\"noopener\">SpamAssassin</a>) and itâ€™s really easy to understand, I decided to go for that one, too. Inspired by <a href=\"http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/\" target=\"_blank\" rel=\"noopener\">this article</a>, where the sentiment of tweets is analyzed, I chose to also use the <a href=\"http://www.nltk.org/\" target=\"_blank\" rel=\"noopener\">natural language toolkit</a> for Python. Another option would have been <a href=\"http://scikit-learn.org/\" target=\"_blank\" rel=\"noopener\">sklearn</a>, but NLTK also provided some useful utilities beyond the pure ML scope. </p>\n<p>All of my <strong>code is <a href=\"https://github.com/n1try/tg-chat-classification/\" target=\"_blank\" rel=\"noopener\">available on GitHub</a></strong>.</p>\n<h3 id=\"Basic-Steps\"><a href=\"#Basic-Steps\" class=\"headerlink\" title=\"Basic Steps\"></a>Basic Steps</h3><ol>\n<li>The very first step was to download the data, namely the chat messages. Luckily, Telegram has an open API. However itâ€™s not a classical REST API, but instead theyâ€™re using the <a href=\"https://core.telegram.org/mtproto\" target=\"_blank\" rel=\"noopener\">MTProto</a> protocol. I found <a href=\"https://github.com/vysheng/tg\" target=\"_blank\" rel=\"noopener\">vysheng/tg</a> as a cool C++-written commandline client on GitHub as well as <a href=\"https://github.com/tvdstaaij/telegram-history-dump\" target=\"_blank\" rel=\"noopener\">tvdstaaij/telegram-history-dump</a> as a Ruby script to automate the history download for a set of users / chat partners. I told the script (ran in a Docker container, since I didnâ€™t want to install Ruby) to fetch at max 40,000 messages for my top three chat partners (letâ€™s call them _M_, _P_ and _J_). The outcome were three <a href=\"http://jsonlines.org/\" target=\"_blank\" rel=\"noopener\">JSON Lines</a> files.</li>\n<li>To pre-process these files as needed for my learning algorithm, I wrote a Python script that extracted only message text and sender from all incoming messages and dumped these data to a JSON file. Additionally I also extracted the same information for all outgoing messages, i.e. all messages where the sender was me. Consequently, there are four classes: <strong>C = { _M_, _P_, _J_, _F_ }</strong></li>\n<li>Another data-preprocessing step was to convert the JSON objects with class names as keys for message-arrays to one large list of tuples of the form <em>(text, label)</em>, where <em>label</em> is the name of the messageâ€™s sender and <em>text</em> is the respective message text. In this step I also discarded words with a length of less than 2 characters and converted everything to lower case.</li>\n<li>Next step was to extract the features. In text classification, there is often one binary (<em>contains</em> / <em>contains not</em>) feature for every possible word. So if all messages in total comprise X different words, there will be a X-dimensional feature vector.</li>\n<li>Last step before actually training the classifier is to compute the feature vector for every messages. For examples if the total feature set is <code>[&#39;in&#39;, &#39;case&#39;, &#39;of&#39;, &#39;fire&#39;, &#39;coffee&#39;, &#39;we&#39;, &#39;trust&#39;]</code>, the resultung feature vector for a message <em>â€œin coffee we trustâ€</em> would be <code>(&#39;in&#39;=True, &#39;case&#39;=False, &#39;of&#39;=False, &#39;fire&#39;=False, &#39;coffee&#39;=True, &#39;we&#39;=True, &#39;trust&#39;=True)</code>.</li>\n<li>One more minor thing: shuffle the feature set so that the order of messages and message senders is random. Also divide the feature set into training- and test data, where test data contains about 10 % of the number of messages in the train data.</li>\n<li>Train <a href=\"http://www.nltk.org/api/nltk.classify.html\" target=\"_blank\" rel=\"noopener\">nltk.NaiveBayesClassifier</a> classifier. This is really just one line of code.</li>\n<li>Use the returned classifier to predict classes for the test messages, validate them and compute the accuracy.</li>\n</ol>\n<p>Using that basic initial setup on a set of <strong>37257 messages</strong>, (7931 from M, 9795 from P, 9314 from F and 10217 from J), I ended up with an <strong>accuracy of 0.58</strong>. There seemed to be room for optimization.</p>\n<h3 id=\"Optimizations\"><a href=\"#Optimizations\" class=\"headerlink\" title=\"Optimizations\"></a>Optimizations</h3><ul>\n<li>Inspired by <em>fastText</em>, I decided to include n-grams. This seemed resonable to me, because intuitively Iâ€™d say that single words a way less characteristic for a personâ€™s writing style than certain phrases. I extended the feature list from step 4 by all possible <strong>bi- and tri-grams</strong>, which are easy to compute with NLTK. Actually Iâ€™m not taking ALL bi- and tri-grams and Iâ€™m not even take all single words as features. Reason for that is that there were approx. 35k different words in the dataset. Plus the n-grams this would make an extremely multi-dimensional feature vector and as it turned out, it was way to complex for my 16 GB MacBook Pro to compute. Consequently, I only took the <strong>top 5000 single words, bigrams and trigrams</strong>, ranked descending by their overall frequency. </li>\n<li>Since NLTK already provides a corpus of <strong>stopwords</strong> (like â€œinâ€, â€œandâ€, â€œofâ€, etc.), which are obviously not characteristic for a personâ€™s style of chatting, I decided to remove them (the German ones) from the message set in step 2.</li>\n</ul>\n<p>With these optimizations, I ended up with an <strong>accuracy of 0.61</strong> after a training time of 348 seconds (I didnâ€™t log testing time at that point).</p>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>Certainly 61 % accuracy isnâ€™t really a good classifier, but at least significantly better than random guessing (chance of 1/4 in this case). However, I trained a <strong>fastText</strong> classifier on my data as a comparison baseline and it even only reached <strong>60 % accuracy</strong> (but with a much better <strong>training time of only 0.66 seconds</strong>).<br>My intuitive explanation for these rather bad results is the complexity of the problem itself. Given only a set of words without any context and semantics, itâ€™s not only hard for a machine to predict the messageâ€™s sender but also for a human.<br>Moreover, given more training data (Iâ€™d need a longer message history) and more computing power to handle larger feature sets, the accuracy might further improve slightly.<br>Actually, the practical relevance of this project isnâ€™t quit high anyway, but it was a good practice for me to get into the basics of ML and itâ€™s really fun!</p>\n<p>Please leave me feedback if you like to.</p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<h3 id=\"Intro\"><a href=\"#Intro\" class=\"headerlink\" title=\"Intro\"></a>Intro</h3><p>First of all, a short disclaimer: Iâ€™m not an expert in machine learning at all. In fact Iâ€™m in a rather early stage of the learning process, have basic knowledge and this project is kind of my first practical hands-on ML. Iâ€™ve done the <a href=\"https://www.youtube.com/user/UWCSE/playlists?sort=dd&amp;shelf_id=16&amp;view=50\" target=\"_blank\" rel=\"noopener\">machine learning course</a> by <a href=\"https://homes.cs.washington.edu/~pedrod/\" target=\"_blank\" rel=\"noopener\">Pedro Domingos</a> at University of Washington, <a href=\"https://www.udacity.com/course/intro-to-machine-learning--ud120\" target=\"_blank\" rel=\"noopener\">Intro to Machine Learning</a> by Udacity and Google and the <a href=\"https://his.anthropomatik.kit.edu/english/28_315.php\" target=\"_blank\" rel=\"noopener\">Machine Learning 1 lecture at Karlsruhe Institute Of Technology</a>, all of which I can really recommend.<br>After having gathered all that theoretical knowledge, I wanted to try something practical on my own. I decided to learn a simple classifier for chat messages from my <a href=\"https://telegram.com\" target=\"_blank\" rel=\"noopener\">Telegram</a> messenger history. I wanted to learn a program that can, given a chat message, tell who the sender of that message is. I further got inspired after having read the papers related to Facebookâ€™s <a href=\"https://github.com/facebookresearch/fastText\" target=\"_blank\" rel=\"noopener\">fastText</a> text classification algorithm. In their examples they classify Wikipedia abstracts / descriptions to <a href=\"https://dbpedia.org\" target=\"_blank\" rel=\"noopener\">DBPedia</a> classes or news article headlines to their respective news categories, only based on plain, natural words. Basically these problems are very similar to mine, so I decided to give it a try. Since I found that many text classifiers are learned using the Naive Bayes algorithm (especially popular in spam detection and part of <a href=\"http://spamassassin.apache.org/\" target=\"_blank\" rel=\"noopener\">SpamAssassin</a>) and itâ€™s really easy to understand, I decided to go for that one, too. Inspired by <a href=\"http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/\" target=\"_blank\" rel=\"noopener\">this article</a>, where the sentiment of tweets is analyzed, I chose to also use the <a href=\"http://www.nltk.org/\" target=\"_blank\" rel=\"noopener\">natural language toolkit</a> for Python. Another option would have been <a href=\"http://scikit-learn.org/\" target=\"_blank\" rel=\"noopener\">sklearn</a>, but NLTK also provided some useful utilities beyond the pure ML scope. </p>\n<p>All of my <strong>code is <a href=\"https://github.com/n1try/tg-chat-classification/\" target=\"_blank\" rel=\"noopener\">available on GitHub</a></strong>.</p>\n<h3 id=\"Basic-Steps\"><a href=\"#Basic-Steps\" class=\"headerlink\" title=\"Basic Steps\"></a>Basic Steps</h3><ol>\n<li>The very first step was to download the data, namely the chat messages. Luckily, Telegram has an open API. However itâ€™s not a classical REST API, but instead theyâ€™re using the <a href=\"https://core.telegram.org/mtproto\" target=\"_blank\" rel=\"noopener\">MTProto</a> protocol. I found <a href=\"https://github.com/vysheng/tg\" target=\"_blank\" rel=\"noopener\">vysheng/tg</a> as a cool C++-written commandline client on GitHub as well as <a href=\"https://github.com/tvdstaaij/telegram-history-dump\" target=\"_blank\" rel=\"noopener\">tvdstaaij/telegram-history-dump</a> as a Ruby script to automate the history download for a set of users / chat partners. I told the script (ran in a Docker container, since I didnâ€™t want to install Ruby) to fetch at max 40,000 messages for my top three chat partners (letâ€™s call them _M_, _P_ and _J_). The outcome were three <a href=\"http://jsonlines.org/\" target=\"_blank\" rel=\"noopener\">JSON Lines</a> files.</li>\n<li>To pre-process these files as needed for my learning algorithm, I wrote a Python script that extracted only message text and sender from all incoming messages and dumped these data to a JSON file. Additionally I also extracted the same information for all outgoing messages, i.e. all messages where the sender was me. Consequently, there are four classes: <strong>C = { _M_, _P_, _J_, _F_ }</strong></li>\n<li>Another data-preprocessing step was to convert the JSON objects with class names as keys for message-arrays to one large list of tuples of the form <em>(text, label)</em>, where <em>label</em> is the name of the messageâ€™s sender and <em>text</em> is the respective message text. In this step I also discarded words with a length of less than 2 characters and converted everything to lower case.</li>\n<li>Next step was to extract the features. In text classification, there is often one binary (<em>contains</em> / <em>contains not</em>) feature for every possible word. So if all messages in total comprise X different words, there will be a X-dimensional feature vector.</li>\n<li>Last step before actually training the classifier is to compute the feature vector for every messages. For examples if the total feature set is <code>[&#39;in&#39;, &#39;case&#39;, &#39;of&#39;, &#39;fire&#39;, &#39;coffee&#39;, &#39;we&#39;, &#39;trust&#39;]</code>, the resultung feature vector for a message <em>â€œin coffee we trustâ€</em> would be <code>(&#39;in&#39;=True, &#39;case&#39;=False, &#39;of&#39;=False, &#39;fire&#39;=False, &#39;coffee&#39;=True, &#39;we&#39;=True, &#39;trust&#39;=True)</code>.</li>\n<li>One more minor thing: shuffle the feature set so that the order of messages and message senders is random. Also divide the feature set into training- and test data, where test data contains about 10 % of the number of messages in the train data.</li>\n<li>Train <a href=\"http://www.nltk.org/api/nltk.classify.html\" target=\"_blank\" rel=\"noopener\">nltk.NaiveBayesClassifier</a> classifier. This is really just one line of code.</li>\n<li>Use the returned classifier to predict classes for the test messages, validate them and compute the accuracy.</li>\n</ol>\n<p>Using that basic initial setup on a set of <strong>37257 messages</strong>, (7931 from M, 9795 from P, 9314 from F and 10217 from J), I ended up with an <strong>accuracy of 0.58</strong>. There seemed to be room for optimization.</p>\n<h3 id=\"Optimizations\"><a href=\"#Optimizations\" class=\"headerlink\" title=\"Optimizations\"></a>Optimizations</h3><ul>\n<li>Inspired by <em>fastText</em>, I decided to include n-grams. This seemed resonable to me, because intuitively Iâ€™d say that single words a way less characteristic for a personâ€™s writing style than certain phrases. I extended the feature list from step 4 by all possible <strong>bi- and tri-grams</strong>, which are easy to compute with NLTK. Actually Iâ€™m not taking ALL bi- and tri-grams and Iâ€™m not even take all single words as features. Reason for that is that there were approx. 35k different words in the dataset. Plus the n-grams this would make an extremely multi-dimensional feature vector and as it turned out, it was way to complex for my 16 GB MacBook Pro to compute. Consequently, I only took the <strong>top 5000 single words, bigrams and trigrams</strong>, ranked descending by their overall frequency. </li>\n<li>Since NLTK already provides a corpus of <strong>stopwords</strong> (like â€œinâ€, â€œandâ€, â€œofâ€, etc.), which are obviously not characteristic for a personâ€™s style of chatting, I decided to remove them (the German ones) from the message set in step 2.</li>\n</ul>\n<p>With these optimizations, I ended up with an <strong>accuracy of 0.61</strong> after a training time of 348 seconds (I didnâ€™t log testing time at that point).</p>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>Certainly 61 % accuracy isnâ€™t really a good classifier, but at least significantly better than random guessing (chance of 1/4 in this case). However, I trained a <strong>fastText</strong> classifier on my data as a comparison baseline and it even only reached <strong>60 % accuracy</strong> (but with a much better <strong>training time of only 0.66 seconds</strong>).<br>My intuitive explanation for these rather bad results is the complexity of the problem itself. Given only a set of words without any context and semantics, itâ€™s not only hard for a machine to predict the messageâ€™s sender but also for a human.<br>Moreover, given more training data (Iâ€™d need a longer message history) and more computing power to handle larger feature sets, the accuracy might further improve slightly.<br>Actually, the practical relevance of this project isnâ€™t quit high anyway, but it was a good practice for me to get into the basics of ML and itâ€™s really fun!</p>\n<p>Please leave me feedback if you like to.</p>\n"},{"title":"Telegram bot example code in Node.js","date":"2015-12-01T21:42:05.000Z","_content":"\nAs a response to my [latest article](how-to-make-telegram-bots.html) on how to make Telegram bots, I got many requests from guys who had problems with actually getting such a bot set up with my tutorial and they asked for a complete, working code example. So I made one. It is limited to the very basics, but it works and may serve as inspiration for you. What most of you would probably like to have further in your bots, but what is not covered in my example, is a database connection. Because in most cases your bot will probably need to persist data. To realize this you should have a little rather advanced skills in Node as well as basic knowledge of the database system of your choice, which is MongoDB with Mongoose Node module for me.\n\nAlright, hereâ€™s my sample bot: [http://github.com/n1try/telegram-bot-node-sample](http://github.com/n1try/telegram-bot-node-sample/)\n\nAlso check out my _@FavoriteBot_.  \nHave fun and good luck...","source":"_posts/telegram-bot-example-code-in-nodejs.md","raw":"---\ntitle: Telegram bot example code in Node.js\ndate: 2015-12-01 22:42:05\ntags:\n---\n\nAs a response to my [latest article](how-to-make-telegram-bots.html) on how to make Telegram bots, I got many requests from guys who had problems with actually getting such a bot set up with my tutorial and they asked for a complete, working code example. So I made one. It is limited to the very basics, but it works and may serve as inspiration for you. What most of you would probably like to have further in your bots, but what is not covered in my example, is a database connection. Because in most cases your bot will probably need to persist data. To realize this you should have a little rather advanced skills in Node as well as basic knowledge of the database system of your choice, which is MongoDB with Mongoose Node module for me.\n\nAlright, hereâ€™s my sample bot: [http://github.com/n1try/telegram-bot-node-sample](http://github.com/n1try/telegram-bot-node-sample/)\n\nAlso check out my _@FavoriteBot_.  \nHave fun and good luck...","slug":"telegram-bot-example-code-in-nodejs","published":1,"updated":"2018-03-19T09:30:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2giome000ncxrguie64vlg","content":"<p>As a response to my <a href=\"how-to-make-telegram-bots.html\">latest article</a> on how to make Telegram bots, I got many requests from guys who had problems with actually getting such a bot set up with my tutorial and they asked for a complete, working code example. So I made one. It is limited to the very basics, but it works and may serve as inspiration for you. What most of you would probably like to have further in your bots, but what is not covered in my example, is a database connection. Because in most cases your bot will probably need to persist data. To realize this you should have a little rather advanced skills in Node as well as basic knowledge of the database system of your choice, which is MongoDB with Mongoose Node module for me.</p>\n<p>Alright, hereâ€™s my sample bot: <a href=\"http://github.com/n1try/telegram-bot-node-sample/\" target=\"_blank\" rel=\"noopener\">http://github.com/n1try/telegram-bot-node-sample</a></p>\n<p>Also check out my <em>@FavoriteBot</em>.<br>Have fun and good luckâ€¦</p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<p>As a response to my <a href=\"how-to-make-telegram-bots.html\">latest article</a> on how to make Telegram bots, I got many requests from guys who had problems with actually getting such a bot set up with my tutorial and they asked for a complete, working code example. So I made one. It is limited to the very basics, but it works and may serve as inspiration for you. What most of you would probably like to have further in your bots, but what is not covered in my example, is a database connection. Because in most cases your bot will probably need to persist data. To realize this you should have a little rather advanced skills in Node as well as basic knowledge of the database system of your choice, which is MongoDB with Mongoose Node module for me.</p>\n<p>Alright, hereâ€™s my sample bot: <a href=\"http://github.com/n1try/telegram-bot-node-sample/\" target=\"_blank\" rel=\"noopener\">http://github.com/n1try/telegram-bot-node-sample</a></p>\n<p>Also check out my <em>@FavoriteBot</em>.<br>Have fun and good luckâ€¦</p>\n"},{"title":"Telegram: ExpenseBot & DoodlerBot","date":"2016-05-08T20:59:33.000Z","_content":"\n\nIn 2015, the [Telegram](https://telegram.org) messenger announced their [Bots](https://core.telegram.org/bots). Basically they are pieces of software that act like a normal chat user in many ways. They could have any functionality, from being helpful at daily tasks to even simple games or trivias â€“ all within an ordinary Telegram chat. You send them message, they give answers â€“ some more and some less intelligent. Recently, also other companies â€“ like [Facebook](http://techcrunch.com/2016/04/07/facebook-chatbots/) or [Microsoft](https://dev.botframework.com/) â€“ announced such bots for their messaging apps. Sometimes bots are even considered kind of the next step after native (web-) applications in the future.\n\nFrom a developerâ€™s perspective, making a bot is fun, because there are almost no restrictions on how to develop your bot. All communication with Telegram works by requesting a single REST API provided by them. Choices like which programming language and -framework to use and how to structure the code are completely up to the developer. A Telegram bot can theoretically be built in any programming language. The only requirements are to be able to make HTTP request from the application and to have a server to host the bot on.\n\nIâ€™ve recently created two bots for Telegram that should each help with a daily task.\n\n### ExpenseBot â€“ Keep track of your finances\n\n![1461614801_Money-Increase](/images/expensebot_icon.png)\n\nThis botâ€™s purpose is to help people manage their daily expenses and keep track of their financial situation. Users can add expenses from wherever they are using a few simple commands from within the chat and have an eye on how much they have spent in a month or a day. This obviates the need for confusing Excel spreadsheets or paper notes. You can reach the bot by sending a Message to *[@ExpenseBot](https://telegram.me/ExpenseBot)* in Telegram.\n\n### DoodlerBot â€“ Coordinate group appointments\n\n![1462726473_calendar](/images/doodlerbot_icon.png)\n\nMy second bot helps users coordinate a group of people and find the right date for a common appointment, just like you might know from [doodle.com](http://doodle.com) (even though it doesnâ€™t have anything to do with that commercial service, except for fulfilling the same need). Open a new doodle and let your mates in the group chat vote for their preferred date to finally make the best decision for everyone. You can reach the bot by sending a Message to *[@DoodlerBot](https://telegram.me/DoodlerBot)* in Telegram.\n\nBoth projects are completely independent, non-commercial and privately operated. If you have any questions our found a bug (both bots are still in beta phase and therefore might show some unexpected behavior), please contact me at @n1try or via e-mail. In both cases, you should first read a basic introduction on how to use the respective bot, by sending a message with */help* to it.\n\nIn case you like my bots, Iâ€™d be really happy if you rated them at [https://storebot.me/bot/expensebot](https://storebot.me/bot/expensebot) and [https://storebot.me/bot/doodlerbot](https://storebot.me/bot/doodlerbot). Have fun!","source":"_posts/telegram-expensebot-doodlerbot.md","raw":"---\ntitle: 'Telegram: ExpenseBot & DoodlerBot'\ndate: 2016-05-08 22:59:33\ntags:\n---\n\n\nIn 2015, the [Telegram](https://telegram.org) messenger announced their [Bots](https://core.telegram.org/bots). Basically they are pieces of software that act like a normal chat user in many ways. They could have any functionality, from being helpful at daily tasks to even simple games or trivias â€“ all within an ordinary Telegram chat. You send them message, they give answers â€“ some more and some less intelligent. Recently, also other companies â€“ like [Facebook](http://techcrunch.com/2016/04/07/facebook-chatbots/) or [Microsoft](https://dev.botframework.com/) â€“ announced such bots for their messaging apps. Sometimes bots are even considered kind of the next step after native (web-) applications in the future.\n\nFrom a developerâ€™s perspective, making a bot is fun, because there are almost no restrictions on how to develop your bot. All communication with Telegram works by requesting a single REST API provided by them. Choices like which programming language and -framework to use and how to structure the code are completely up to the developer. A Telegram bot can theoretically be built in any programming language. The only requirements are to be able to make HTTP request from the application and to have a server to host the bot on.\n\nIâ€™ve recently created two bots for Telegram that should each help with a daily task.\n\n### ExpenseBot â€“ Keep track of your finances\n\n![1461614801_Money-Increase](/images/expensebot_icon.png)\n\nThis botâ€™s purpose is to help people manage their daily expenses and keep track of their financial situation. Users can add expenses from wherever they are using a few simple commands from within the chat and have an eye on how much they have spent in a month or a day. This obviates the need for confusing Excel spreadsheets or paper notes. You can reach the bot by sending a Message to *[@ExpenseBot](https://telegram.me/ExpenseBot)* in Telegram.\n\n### DoodlerBot â€“ Coordinate group appointments\n\n![1462726473_calendar](/images/doodlerbot_icon.png)\n\nMy second bot helps users coordinate a group of people and find the right date for a common appointment, just like you might know from [doodle.com](http://doodle.com) (even though it doesnâ€™t have anything to do with that commercial service, except for fulfilling the same need). Open a new doodle and let your mates in the group chat vote for their preferred date to finally make the best decision for everyone. You can reach the bot by sending a Message to *[@DoodlerBot](https://telegram.me/DoodlerBot)* in Telegram.\n\nBoth projects are completely independent, non-commercial and privately operated. If you have any questions our found a bug (both bots are still in beta phase and therefore might show some unexpected behavior), please contact me at @n1try or via e-mail. In both cases, you should first read a basic introduction on how to use the respective bot, by sending a message with */help* to it.\n\nIn case you like my bots, Iâ€™d be really happy if you rated them at [https://storebot.me/bot/expensebot](https://storebot.me/bot/expensebot) and [https://storebot.me/bot/doodlerbot](https://storebot.me/bot/doodlerbot). Have fun!","slug":"telegram-expensebot-doodlerbot","published":1,"updated":"2018-03-19T09:30:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2giomf000ocxrgmto0eujx","content":"<p>In 2015, the <a href=\"https://telegram.org\" target=\"_blank\" rel=\"noopener\">Telegram</a> messenger announced their <a href=\"https://core.telegram.org/bots\" target=\"_blank\" rel=\"noopener\">Bots</a>. Basically they are pieces of software that act like a normal chat user in many ways. They could have any functionality, from being helpful at daily tasks to even simple games or trivias â€“ all within an ordinary Telegram chat. You send them message, they give answers â€“ some more and some less intelligent. Recently, also other companies â€“ like <a href=\"http://techcrunch.com/2016/04/07/facebook-chatbots/\" target=\"_blank\" rel=\"noopener\">Facebook</a> or <a href=\"https://dev.botframework.com/\" target=\"_blank\" rel=\"noopener\">Microsoft</a> â€“ announced such bots for their messaging apps. Sometimes bots are even considered kind of the next step after native (web-) applications in the future.</p>\n<p>From a developerâ€™s perspective, making a bot is fun, because there are almost no restrictions on how to develop your bot. All communication with Telegram works by requesting a single REST API provided by them. Choices like which programming language and -framework to use and how to structure the code are completely up to the developer. A Telegram bot can theoretically be built in any programming language. The only requirements are to be able to make HTTP request from the application and to have a server to host the bot on.</p>\n<p>Iâ€™ve recently created two bots for Telegram that should each help with a daily task.</p>\n<h3 id=\"ExpenseBot-â€“-Keep-track-of-your-finances\"><a href=\"#ExpenseBot-â€“-Keep-track-of-your-finances\" class=\"headerlink\" title=\"ExpenseBot â€“ Keep track of your finances\"></a>ExpenseBot â€“ Keep track of your finances</h3><p><img src=\"/images/expensebot_icon.png\" alt=\"1461614801_Money-Increase\"></p>\n<p>This botâ€™s purpose is to help people manage their daily expenses and keep track of their financial situation. Users can add expenses from wherever they are using a few simple commands from within the chat and have an eye on how much they have spent in a month or a day. This obviates the need for confusing Excel spreadsheets or paper notes. You can reach the bot by sending a Message to <em><a href=\"https://telegram.me/ExpenseBot\" target=\"_blank\" rel=\"noopener\">@ExpenseBot</a></em> in Telegram.</p>\n<h3 id=\"DoodlerBot-â€“-Coordinate-group-appointments\"><a href=\"#DoodlerBot-â€“-Coordinate-group-appointments\" class=\"headerlink\" title=\"DoodlerBot â€“ Coordinate group appointments\"></a>DoodlerBot â€“ Coordinate group appointments</h3><p><img src=\"/images/doodlerbot_icon.png\" alt=\"1462726473_calendar\"></p>\n<p>My second bot helps users coordinate a group of people and find the right date for a common appointment, just like you might know from <a href=\"http://doodle.com\" target=\"_blank\" rel=\"noopener\">doodle.com</a> (even though it doesnâ€™t have anything to do with that commercial service, except for fulfilling the same need). Open a new doodle and let your mates in the group chat vote for their preferred date to finally make the best decision for everyone. You can reach the bot by sending a Message to <em><a href=\"https://telegram.me/DoodlerBot\" target=\"_blank\" rel=\"noopener\">@DoodlerBot</a></em> in Telegram.</p>\n<p>Both projects are completely independent, non-commercial and privately operated. If you have any questions our found a bug (both bots are still in beta phase and therefore might show some unexpected behavior), please contact me at @n1try or via e-mail. In both cases, you should first read a basic introduction on how to use the respective bot, by sending a message with <em>/help</em> to it.</p>\n<p>In case you like my bots, Iâ€™d be really happy if you rated them at <a href=\"https://storebot.me/bot/expensebot\" target=\"_blank\" rel=\"noopener\">https://storebot.me/bot/expensebot</a> and <a href=\"https://storebot.me/bot/doodlerbot\" target=\"_blank\" rel=\"noopener\">https://storebot.me/bot/doodlerbot</a>. Have fun!</p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<p>In 2015, the <a href=\"https://telegram.org\" target=\"_blank\" rel=\"noopener\">Telegram</a> messenger announced their <a href=\"https://core.telegram.org/bots\" target=\"_blank\" rel=\"noopener\">Bots</a>. Basically they are pieces of software that act like a normal chat user in many ways. They could have any functionality, from being helpful at daily tasks to even simple games or trivias â€“ all within an ordinary Telegram chat. You send them message, they give answers â€“ some more and some less intelligent. Recently, also other companies â€“ like <a href=\"http://techcrunch.com/2016/04/07/facebook-chatbots/\" target=\"_blank\" rel=\"noopener\">Facebook</a> or <a href=\"https://dev.botframework.com/\" target=\"_blank\" rel=\"noopener\">Microsoft</a> â€“ announced such bots for their messaging apps. Sometimes bots are even considered kind of the next step after native (web-) applications in the future.</p>\n<p>From a developerâ€™s perspective, making a bot is fun, because there are almost no restrictions on how to develop your bot. All communication with Telegram works by requesting a single REST API provided by them. Choices like which programming language and -framework to use and how to structure the code are completely up to the developer. A Telegram bot can theoretically be built in any programming language. The only requirements are to be able to make HTTP request from the application and to have a server to host the bot on.</p>\n<p>Iâ€™ve recently created two bots for Telegram that should each help with a daily task.</p>\n<h3 id=\"ExpenseBot-â€“-Keep-track-of-your-finances\"><a href=\"#ExpenseBot-â€“-Keep-track-of-your-finances\" class=\"headerlink\" title=\"ExpenseBot â€“ Keep track of your finances\"></a>ExpenseBot â€“ Keep track of your finances</h3><p><img src=\"/images/expensebot_icon.png\" alt=\"1461614801_Money-Increase\"></p>\n<p>This botâ€™s purpose is to help people manage their daily expenses and keep track of their financial situation. Users can add expenses from wherever they are using a few simple commands from within the chat and have an eye on how much they have spent in a month or a day. This obviates the need for confusing Excel spreadsheets or paper notes. You can reach the bot by sending a Message to <em><a href=\"https://telegram.me/ExpenseBot\" target=\"_blank\" rel=\"noopener\">@ExpenseBot</a></em> in Telegram.</p>\n<h3 id=\"DoodlerBot-â€“-Coordinate-group-appointments\"><a href=\"#DoodlerBot-â€“-Coordinate-group-appointments\" class=\"headerlink\" title=\"DoodlerBot â€“ Coordinate group appointments\"></a>DoodlerBot â€“ Coordinate group appointments</h3><p><img src=\"/images/doodlerbot_icon.png\" alt=\"1462726473_calendar\"></p>\n<p>My second bot helps users coordinate a group of people and find the right date for a common appointment, just like you might know from <a href=\"http://doodle.com\" target=\"_blank\" rel=\"noopener\">doodle.com</a> (even though it doesnâ€™t have anything to do with that commercial service, except for fulfilling the same need). Open a new doodle and let your mates in the group chat vote for their preferred date to finally make the best decision for everyone. You can reach the bot by sending a Message to <em><a href=\"https://telegram.me/DoodlerBot\" target=\"_blank\" rel=\"noopener\">@DoodlerBot</a></em> in Telegram.</p>\n<p>Both projects are completely independent, non-commercial and privately operated. If you have any questions our found a bug (both bots are still in beta phase and therefore might show some unexpected behavior), please contact me at @n1try or via e-mail. In both cases, you should first read a basic introduction on how to use the respective bot, by sending a message with <em>/help</em> to it.</p>\n<p>In case you like my bots, Iâ€™d be really happy if you rated them at <a href=\"https://storebot.me/bot/expensebot\" target=\"_blank\" rel=\"noopener\">https://storebot.me/bot/expensebot</a> and <a href=\"https://storebot.me/bot/doodlerbot\" target=\"_blank\" rel=\"noopener\">https://storebot.me/bot/doodlerbot</a>. Have fun!</p>\n"},{"title":"Middleman Bot - Push notifications as easy as POST","date":"2017-07-04T20:13:57.000Z","_content":"\n![](images/middleman.png)\n\n## E-Mails are so 2010\nE-Mails are everywhere. Literally anybody who gets in contact with a computer in some way will use the electronic mail system, which dates back to 1971. And certainly the E-Mail still has its right to exist, even in 2017. Especially in a business context it simply makes sense for many use cases - however not for all of those it is nowadays used for. The smaller the piece of information you want to communicate is, the less efficient e-mails are. Due to tons of header rows and other heavy load, a mail has a large overhead. Just look at a small random sample of mail from your inbox, find out the core information you get from it and look at the file size. Often you will find an overhead of more than 70 %. Great examples are subscription mails from online forum posts. Their essential information is basically only one bit in size, namely that something new has happened. However, they usually contain lots of HTML code, CSS, attachment pictures and some boilerplate text. Another example is those chatty-like conversations between two or more people, where each of them responds with only a few words to his conversation partner's last question or the like. Although only few words are added, the whole previous mail is replicated again, enriched with some headers and then sent to the server, where it is stored and delivered to the recipients. I'm glad that for those cases apps like Slack are gradually establishing and I hope they will replace the e-mail some day. Anyway, I get off the topic. This shouldn't be a hate letter against the e-mail. Rather I want to present another bot for the __Telegram__ instant messenger.\n\n## The pain I had\nIt mainly aims at developers and sysadmins, but is not limited to these addressees. Once I had the problem that I wanted to code a little watcher that regularly visits my university's website to check whether an announcement about the exam results has been made and notify me, if that was the case. The only way for realizing that notification that came to my mind was to send an e-mail. However, I had to integrate an SMTP library into my script then, which authenticates against my mail server using my account credentials - comparatively high effort. Then I wanted to write a little script that runs on my server in regular intervals to gather some basic statistics from log files and databases and send them to me so I could passively consume them (instead of me having to actively go to some webpage or so). Again, same problem. \n\n## The simple solution I created\nFor these reasons I created the Middleman Bot. It takes a simple, small JSON fragment as an input via HTTP call and forwards it to my Telegram chat. There's no need for an additional library (nearly every programming language has a built-in API for HTTP calls or you could use cURL) or authentication process. Simply register at the bot once and fire lightweight HTTP calls afterwards. \n\n## Example\nTo make my webserver send me a notification when its load is above a certain threshold, the only thing it would need to do is a `POST http://middleman.ferdinand-muetsch.de/api/messages` with this body: \n\n```json\n{\n\t\"recipient_token\": \"3edf633a-eab0-45ea-9721-16c07bb8f245\",\n\t\"text\": \"Watch out! Average load in the last 10 minutes is >= 10000 requests per second.\",\n\t\"origin\": \"Caddy webserver @ ferdinand-muetsch.de\"\n}\n```\n\nThe token is your unique identifier the bot uses internally to decide to which chat / recipient to route an incoming message to. (For the trolls among you: I've invalidated the token from the example, so nobody could spam me.)\n\nAnd there you go. \n\n![](images/middleman2.png)\n\n\n## Give it a try\nI've pushed the code as well as some introductions on how to run and use that bot to GitHub at  [n1try/telegram-middleman-bot](https://github.com/n1try/telegram-middleman-bot). You can either run your own instance of the bot or use mine, which is running at _http://middleman.ferdinand-muetsch.de_. Let me know what you think!","source":"_posts/telegram-middleman-bot-push-notifications-as-easy-as-post.md","raw":"---\ntitle: Middleman Bot - Push notifications as easy as POST\ndate: 2017-07-04 22:13:57\ntags:\n---\n\n![](images/middleman.png)\n\n## E-Mails are so 2010\nE-Mails are everywhere. Literally anybody who gets in contact with a computer in some way will use the electronic mail system, which dates back to 1971. And certainly the E-Mail still has its right to exist, even in 2017. Especially in a business context it simply makes sense for many use cases - however not for all of those it is nowadays used for. The smaller the piece of information you want to communicate is, the less efficient e-mails are. Due to tons of header rows and other heavy load, a mail has a large overhead. Just look at a small random sample of mail from your inbox, find out the core information you get from it and look at the file size. Often you will find an overhead of more than 70 %. Great examples are subscription mails from online forum posts. Their essential information is basically only one bit in size, namely that something new has happened. However, they usually contain lots of HTML code, CSS, attachment pictures and some boilerplate text. Another example is those chatty-like conversations between two or more people, where each of them responds with only a few words to his conversation partner's last question or the like. Although only few words are added, the whole previous mail is replicated again, enriched with some headers and then sent to the server, where it is stored and delivered to the recipients. I'm glad that for those cases apps like Slack are gradually establishing and I hope they will replace the e-mail some day. Anyway, I get off the topic. This shouldn't be a hate letter against the e-mail. Rather I want to present another bot for the __Telegram__ instant messenger.\n\n## The pain I had\nIt mainly aims at developers and sysadmins, but is not limited to these addressees. Once I had the problem that I wanted to code a little watcher that regularly visits my university's website to check whether an announcement about the exam results has been made and notify me, if that was the case. The only way for realizing that notification that came to my mind was to send an e-mail. However, I had to integrate an SMTP library into my script then, which authenticates against my mail server using my account credentials - comparatively high effort. Then I wanted to write a little script that runs on my server in regular intervals to gather some basic statistics from log files and databases and send them to me so I could passively consume them (instead of me having to actively go to some webpage or so). Again, same problem. \n\n## The simple solution I created\nFor these reasons I created the Middleman Bot. It takes a simple, small JSON fragment as an input via HTTP call and forwards it to my Telegram chat. There's no need for an additional library (nearly every programming language has a built-in API for HTTP calls or you could use cURL) or authentication process. Simply register at the bot once and fire lightweight HTTP calls afterwards. \n\n## Example\nTo make my webserver send me a notification when its load is above a certain threshold, the only thing it would need to do is a `POST http://middleman.ferdinand-muetsch.de/api/messages` with this body: \n\n```json\n{\n\t\"recipient_token\": \"3edf633a-eab0-45ea-9721-16c07bb8f245\",\n\t\"text\": \"Watch out! Average load in the last 10 minutes is >= 10000 requests per second.\",\n\t\"origin\": \"Caddy webserver @ ferdinand-muetsch.de\"\n}\n```\n\nThe token is your unique identifier the bot uses internally to decide to which chat / recipient to route an incoming message to. (For the trolls among you: I've invalidated the token from the example, so nobody could spam me.)\n\nAnd there you go. \n\n![](images/middleman2.png)\n\n\n## Give it a try\nI've pushed the code as well as some introductions on how to run and use that bot to GitHub at  [n1try/telegram-middleman-bot](https://github.com/n1try/telegram-middleman-bot). You can either run your own instance of the bot or use mine, which is running at _http://middleman.ferdinand-muetsch.de_. Let me know what you think!","slug":"telegram-middleman-bot-push-notifications-as-easy-as-post","published":1,"updated":"2018-03-19T09:30:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2giomg000pcxrg57uowipd","content":"<p><img src=\"images/middleman.png\" alt=\"\"></p>\n<h2 id=\"E-Mails-are-so-2010\"><a href=\"#E-Mails-are-so-2010\" class=\"headerlink\" title=\"E-Mails are so 2010\"></a>E-Mails are so 2010</h2><p>E-Mails are everywhere. Literally anybody who gets in contact with a computer in some way will use the electronic mail system, which dates back to 1971. And certainly the E-Mail still has its right to exist, even in 2017. Especially in a business context it simply makes sense for many use cases - however not for all of those it is nowadays used for. The smaller the piece of information you want to communicate is, the less efficient e-mails are. Due to tons of header rows and other heavy load, a mail has a large overhead. Just look at a small random sample of mail from your inbox, find out the core information you get from it and look at the file size. Often you will find an overhead of more than 70 %. Great examples are subscription mails from online forum posts. Their essential information is basically only one bit in size, namely that something new has happened. However, they usually contain lots of HTML code, CSS, attachment pictures and some boilerplate text. Another example is those chatty-like conversations between two or more people, where each of them responds with only a few words to his conversation partnerâ€™s last question or the like. Although only few words are added, the whole previous mail is replicated again, enriched with some headers and then sent to the server, where it is stored and delivered to the recipients. Iâ€™m glad that for those cases apps like Slack are gradually establishing and I hope they will replace the e-mail some day. Anyway, I get off the topic. This shouldnâ€™t be a hate letter against the e-mail. Rather I want to present another bot for the <strong>Telegram</strong> instant messenger.</p>\n<h2 id=\"The-pain-I-had\"><a href=\"#The-pain-I-had\" class=\"headerlink\" title=\"The pain I had\"></a>The pain I had</h2><p>It mainly aims at developers and sysadmins, but is not limited to these addressees. Once I had the problem that I wanted to code a little watcher that regularly visits my universityâ€™s website to check whether an announcement about the exam results has been made and notify me, if that was the case. The only way for realizing that notification that came to my mind was to send an e-mail. However, I had to integrate an SMTP library into my script then, which authenticates against my mail server using my account credentials - comparatively high effort. Then I wanted to write a little script that runs on my server in regular intervals to gather some basic statistics from log files and databases and send them to me so I could passively consume them (instead of me having to actively go to some webpage or so). Again, same problem. </p>\n<h2 id=\"The-simple-solution-I-created\"><a href=\"#The-simple-solution-I-created\" class=\"headerlink\" title=\"The simple solution I created\"></a>The simple solution I created</h2><p>For these reasons I created the Middleman Bot. It takes a simple, small JSON fragment as an input via HTTP call and forwards it to my Telegram chat. Thereâ€™s no need for an additional library (nearly every programming language has a built-in API for HTTP calls or you could use cURL) or authentication process. Simply register at the bot once and fire lightweight HTTP calls afterwards. </p>\n<h2 id=\"Example\"><a href=\"#Example\" class=\"headerlink\" title=\"Example\"></a>Example</h2><p>To make my webserver send me a notification when its load is above a certain threshold, the only thing it would need to do is a <code>POST http://middleman.ferdinand-muetsch.de/api/messages</code> with this body: </p>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">\t<span class=\"attr\">\"recipient_token\"</span>: <span class=\"string\">\"3edf633a-eab0-45ea-9721-16c07bb8f245\"</span>,</span><br><span class=\"line\">\t<span class=\"attr\">\"text\"</span>: <span class=\"string\">\"Watch out! Average load in the last 10 minutes is &gt;= 10000 requests per second.\"</span>,</span><br><span class=\"line\">\t<span class=\"attr\">\"origin\"</span>: <span class=\"string\">\"Caddy webserver @ ferdinand-muetsch.de\"</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>The token is your unique identifier the bot uses internally to decide to which chat / recipient to route an incoming message to. (For the trolls among you: Iâ€™ve invalidated the token from the example, so nobody could spam me.)</p>\n<p>And there you go. </p>\n<p><img src=\"images/middleman2.png\" alt=\"\"></p>\n<h2 id=\"Give-it-a-try\"><a href=\"#Give-it-a-try\" class=\"headerlink\" title=\"Give it a try\"></a>Give it a try</h2><p>Iâ€™ve pushed the code as well as some introductions on how to run and use that bot to GitHub at  <a href=\"https://github.com/n1try/telegram-middleman-bot\" target=\"_blank\" rel=\"noopener\">n1try/telegram-middleman-bot</a>. You can either run your own instance of the bot or use mine, which is running at <em><a href=\"http://middleman.ferdinand-muetsch.de\" target=\"_blank\" rel=\"noopener\">http://middleman.ferdinand-muetsch.de</a></em>. Let me know what you think!</p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<p><img src=\"images/middleman.png\" alt=\"\"></p>\n<h2 id=\"E-Mails-are-so-2010\"><a href=\"#E-Mails-are-so-2010\" class=\"headerlink\" title=\"E-Mails are so 2010\"></a>E-Mails are so 2010</h2><p>E-Mails are everywhere. Literally anybody who gets in contact with a computer in some way will use the electronic mail system, which dates back to 1971. And certainly the E-Mail still has its right to exist, even in 2017. Especially in a business context it simply makes sense for many use cases - however not for all of those it is nowadays used for. The smaller the piece of information you want to communicate is, the less efficient e-mails are. Due to tons of header rows and other heavy load, a mail has a large overhead. Just look at a small random sample of mail from your inbox, find out the core information you get from it and look at the file size. Often you will find an overhead of more than 70 %. Great examples are subscription mails from online forum posts. Their essential information is basically only one bit in size, namely that something new has happened. However, they usually contain lots of HTML code, CSS, attachment pictures and some boilerplate text. Another example is those chatty-like conversations between two or more people, where each of them responds with only a few words to his conversation partnerâ€™s last question or the like. Although only few words are added, the whole previous mail is replicated again, enriched with some headers and then sent to the server, where it is stored and delivered to the recipients. Iâ€™m glad that for those cases apps like Slack are gradually establishing and I hope they will replace the e-mail some day. Anyway, I get off the topic. This shouldnâ€™t be a hate letter against the e-mail. Rather I want to present another bot for the <strong>Telegram</strong> instant messenger.</p>\n<h2 id=\"The-pain-I-had\"><a href=\"#The-pain-I-had\" class=\"headerlink\" title=\"The pain I had\"></a>The pain I had</h2><p>It mainly aims at developers and sysadmins, but is not limited to these addressees. Once I had the problem that I wanted to code a little watcher that regularly visits my universityâ€™s website to check whether an announcement about the exam results has been made and notify me, if that was the case. The only way for realizing that notification that came to my mind was to send an e-mail. However, I had to integrate an SMTP library into my script then, which authenticates against my mail server using my account credentials - comparatively high effort. Then I wanted to write a little script that runs on my server in regular intervals to gather some basic statistics from log files and databases and send them to me so I could passively consume them (instead of me having to actively go to some webpage or so). Again, same problem. </p>\n<h2 id=\"The-simple-solution-I-created\"><a href=\"#The-simple-solution-I-created\" class=\"headerlink\" title=\"The simple solution I created\"></a>The simple solution I created</h2><p>For these reasons I created the Middleman Bot. It takes a simple, small JSON fragment as an input via HTTP call and forwards it to my Telegram chat. Thereâ€™s no need for an additional library (nearly every programming language has a built-in API for HTTP calls or you could use cURL) or authentication process. Simply register at the bot once and fire lightweight HTTP calls afterwards. </p>\n<h2 id=\"Example\"><a href=\"#Example\" class=\"headerlink\" title=\"Example\"></a>Example</h2><p>To make my webserver send me a notification when its load is above a certain threshold, the only thing it would need to do is a <code>POST http://middleman.ferdinand-muetsch.de/api/messages</code> with this body: </p>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">\t<span class=\"attr\">\"recipient_token\"</span>: <span class=\"string\">\"3edf633a-eab0-45ea-9721-16c07bb8f245\"</span>,</span><br><span class=\"line\">\t<span class=\"attr\">\"text\"</span>: <span class=\"string\">\"Watch out! Average load in the last 10 minutes is &gt;= 10000 requests per second.\"</span>,</span><br><span class=\"line\">\t<span class=\"attr\">\"origin\"</span>: <span class=\"string\">\"Caddy webserver @ ferdinand-muetsch.de\"</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>The token is your unique identifier the bot uses internally to decide to which chat / recipient to route an incoming message to. (For the trolls among you: Iâ€™ve invalidated the token from the example, so nobody could spam me.)</p>\n<p>And there you go. </p>\n<p><img src=\"images/middleman2.png\" alt=\"\"></p>\n<h2 id=\"Give-it-a-try\"><a href=\"#Give-it-a-try\" class=\"headerlink\" title=\"Give it a try\"></a>Give it a try</h2><p>Iâ€™ve pushed the code as well as some introductions on how to run and use that bot to GitHub at  <a href=\"https://github.com/n1try/telegram-middleman-bot\" target=\"_blank\" rel=\"noopener\">n1try/telegram-middleman-bot</a>. You can either run your own instance of the bot or use mine, which is running at <em><a href=\"http://middleman.ferdinand-muetsch.de\" target=\"_blank\" rel=\"noopener\">http://middleman.ferdinand-muetsch.de</a></em>. Let me know what you think!</p>\n"},{"title":"Unhosted.org applications with remoteStorage.io and WebFinger.net","date":"2016-04-12T20:57:43.000Z","_content":"\nLately you as an interested web developer might have heard or read about a thing called **unhosted applications**, mostly with a reference to [unhosted.org](http://unhosted.org/). This basically means web-apps running in your browser which do not rely on any kind of backend. Most apps youâ€™re using on the web store data to a backend service at the providerâ€™s host server, regardless of them being Google Docs, Evernote, Wunderlist or also [Anchr.io](https://anchr.io). Obviously this makes you dependent on the provider in terms of availability and security. Also these apps are usually online-only apps, meaning that you can only use them with an internet connection. Another type of apps are those without a specific backend but still with a central, cloud-based data store, e.g. Firebase. In this case your data is still anywhere out there in the cloud at a provider you potentially could not trust (even though not on any kind of dubious private-hosted server but on a certified platform of one of the big players â€“ deciding whether that is better or worse itâ€™s up to you, actually). These apps are usually offline-capable, so you can use them without internet connection and if the connection comes back again, the data is synced to the data platform. And then thereâ€™s this third kind of apps, which they call unhosted ones. These are intended to be completely static, without needing any kind of backend. Theoretically you could download a zip of their HTML, JavaScript and CSS files to your computer and perfectly run the app without a webserver and a database. Well, ok, probably youâ€™ll need a webserver, but it only needs to server static files (like an Apache2, nginx or [http-server](https://www.npmjs.com/package/http-server)), nothing else â€“ no PHP, node Node.jsâ€¦ Those apps (e.g. a simple todo-list) store all their data to your browserâ€™s localStorage or IndexedDB. As a result it obviously is only available on your local computer and only until you clear you browser data. After all you might still want to sync your data to other devices now â€“ but without giving your data away to a untrusted provider.\n\n![](/images/unhosted.jpg)\n\nThis is where quite a new thing called [RemoteStorage](https://remotestorage.io) comes in. Itâ€™s a protocol for storing per-user data on the web in an unhosted fasion. Anything implementing the remoteStorage protocol can be your data-repository, which basically works as a simple key-value store. As a result you can implement your own remoteStorage or e.g. take the â€œofficialâ€ PHP library to host one on your own server. There are also a few providers (like [5apps](http://5apps.com)) out there, yet, which you can use, but donâ€™t have to, if you donâ€™t trust them. An unhosted-app that is remoteStorage-capable can now connect to your remoteStorage, e.g. _https://rs.yourserver.com/user1/appXyz_, and sync its data there. RemoteStorage works together with [WebFinger](https://webfinger.net). What is WebFinger now? WebFinger is kind of a registry on the web, where unique keys (usually in email-address style, like user1@yourserver.com), are mapped to URLâ€™s for a certain type of relation. In this case you would tell your unhosted app such an email-address-like identifier, which maps to your remoteStorage-endpoint for the relation-type â€œremotestorageâ€. The app queries WebFinger for that key and follows the returned registered URL to the datastore. In [this example](https://client.webfinger.net/lookup?resource=tony%405apps.com) the identifier *tony@5apps.com* maps to a *remotestorage* located at _https://storage.5apps.com/tony_. This makes the entire thing as decentralized as possible. Note that you could change your remoteStorage anytime by simply registering a new URL at WebFinger (you usually wouldnâ€™t have to do this registration on your own, but the remoteStorage server implementation handles that for you). The authorization â€“ like which app may access which subkeys on the remoteStorage â€“ is handled by OAuth at your remoteStorage server implementation, where you can grant or revoke access for certain apps to certain store keys.\n\nTwo apps you can try are [litewrite.net](https://litewrite.net/) and [Grouptabs](http://grouptabs.5apps.com). If you just want to play around with remoteStorage it might be the easiest way to use [5apps](http://5apps.com)â€˜ remoteStorage for this.","source":"_posts/unhostedorg-applications-with-remotestorageio-and-webfingernet.md","raw":"---\ntitle: Unhosted.org applications with remoteStorage.io and WebFinger.net\ndate: 2016-04-12 22:57:43\ntags:\n---\n\nLately you as an interested web developer might have heard or read about a thing called **unhosted applications**, mostly with a reference to [unhosted.org](http://unhosted.org/). This basically means web-apps running in your browser which do not rely on any kind of backend. Most apps youâ€™re using on the web store data to a backend service at the providerâ€™s host server, regardless of them being Google Docs, Evernote, Wunderlist or also [Anchr.io](https://anchr.io). Obviously this makes you dependent on the provider in terms of availability and security. Also these apps are usually online-only apps, meaning that you can only use them with an internet connection. Another type of apps are those without a specific backend but still with a central, cloud-based data store, e.g. Firebase. In this case your data is still anywhere out there in the cloud at a provider you potentially could not trust (even though not on any kind of dubious private-hosted server but on a certified platform of one of the big players â€“ deciding whether that is better or worse itâ€™s up to you, actually). These apps are usually offline-capable, so you can use them without internet connection and if the connection comes back again, the data is synced to the data platform. And then thereâ€™s this third kind of apps, which they call unhosted ones. These are intended to be completely static, without needing any kind of backend. Theoretically you could download a zip of their HTML, JavaScript and CSS files to your computer and perfectly run the app without a webserver and a database. Well, ok, probably youâ€™ll need a webserver, but it only needs to server static files (like an Apache2, nginx or [http-server](https://www.npmjs.com/package/http-server)), nothing else â€“ no PHP, node Node.jsâ€¦ Those apps (e.g. a simple todo-list) store all their data to your browserâ€™s localStorage or IndexedDB. As a result it obviously is only available on your local computer and only until you clear you browser data. After all you might still want to sync your data to other devices now â€“ but without giving your data away to a untrusted provider.\n\n![](/images/unhosted.jpg)\n\nThis is where quite a new thing called [RemoteStorage](https://remotestorage.io) comes in. Itâ€™s a protocol for storing per-user data on the web in an unhosted fasion. Anything implementing the remoteStorage protocol can be your data-repository, which basically works as a simple key-value store. As a result you can implement your own remoteStorage or e.g. take the â€œofficialâ€ PHP library to host one on your own server. There are also a few providers (like [5apps](http://5apps.com)) out there, yet, which you can use, but donâ€™t have to, if you donâ€™t trust them. An unhosted-app that is remoteStorage-capable can now connect to your remoteStorage, e.g. _https://rs.yourserver.com/user1/appXyz_, and sync its data there. RemoteStorage works together with [WebFinger](https://webfinger.net). What is WebFinger now? WebFinger is kind of a registry on the web, where unique keys (usually in email-address style, like user1@yourserver.com), are mapped to URLâ€™s for a certain type of relation. In this case you would tell your unhosted app such an email-address-like identifier, which maps to your remoteStorage-endpoint for the relation-type â€œremotestorageâ€. The app queries WebFinger for that key and follows the returned registered URL to the datastore. In [this example](https://client.webfinger.net/lookup?resource=tony%405apps.com) the identifier *tony@5apps.com* maps to a *remotestorage* located at _https://storage.5apps.com/tony_. This makes the entire thing as decentralized as possible. Note that you could change your remoteStorage anytime by simply registering a new URL at WebFinger (you usually wouldnâ€™t have to do this registration on your own, but the remoteStorage server implementation handles that for you). The authorization â€“ like which app may access which subkeys on the remoteStorage â€“ is handled by OAuth at your remoteStorage server implementation, where you can grant or revoke access for certain apps to certain store keys.\n\nTwo apps you can try are [litewrite.net](https://litewrite.net/) and [Grouptabs](http://grouptabs.5apps.com). If you just want to play around with remoteStorage it might be the easiest way to use [5apps](http://5apps.com)â€˜ remoteStorage for this.","slug":"unhostedorg-applications-with-remotestorageio-and-webfingernet","published":1,"updated":"2018-03-19T09:30:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2giomi000qcxrgjjjns49t","content":"<p>Lately you as an interested web developer might have heard or read about a thing called <strong>unhosted applications</strong>, mostly with a reference to <a href=\"http://unhosted.org/\" target=\"_blank\" rel=\"noopener\">unhosted.org</a>. This basically means web-apps running in your browser which do not rely on any kind of backend. Most apps youâ€™re using on the web store data to a backend service at the providerâ€™s host server, regardless of them being Google Docs, Evernote, Wunderlist or also <a href=\"https://anchr.io\" target=\"_blank\" rel=\"noopener\">Anchr.io</a>. Obviously this makes you dependent on the provider in terms of availability and security. Also these apps are usually online-only apps, meaning that you can only use them with an internet connection. Another type of apps are those without a specific backend but still with a central, cloud-based data store, e.g. Firebase. In this case your data is still anywhere out there in the cloud at a provider you potentially could not trust (even though not on any kind of dubious private-hosted server but on a certified platform of one of the big players â€“ deciding whether that is better or worse itâ€™s up to you, actually). These apps are usually offline-capable, so you can use them without internet connection and if the connection comes back again, the data is synced to the data platform. And then thereâ€™s this third kind of apps, which they call unhosted ones. These are intended to be completely static, without needing any kind of backend. Theoretically you could download a zip of their HTML, JavaScript and CSS files to your computer and perfectly run the app without a webserver and a database. Well, ok, probably youâ€™ll need a webserver, but it only needs to server static files (like an Apache2, nginx or <a href=\"https://www.npmjs.com/package/http-server\" target=\"_blank\" rel=\"noopener\">http-server</a>), nothing else â€“ no PHP, node Node.jsâ€¦ Those apps (e.g. a simple todo-list) store all their data to your browserâ€™s localStorage or IndexedDB. As a result it obviously is only available on your local computer and only until you clear you browser data. After all you might still want to sync your data to other devices now â€“ but without giving your data away to a untrusted provider.</p>\n<p><img src=\"/images/unhosted.jpg\" alt=\"\"></p>\n<p>This is where quite a new thing called <a href=\"https://remotestorage.io\" target=\"_blank\" rel=\"noopener\">RemoteStorage</a> comes in. Itâ€™s a protocol for storing per-user data on the web in an unhosted fasion. Anything implementing the remoteStorage protocol can be your data-repository, which basically works as a simple key-value store. As a result you can implement your own remoteStorage or e.g. take the â€œofficialâ€ PHP library to host one on your own server. There are also a few providers (like <a href=\"http://5apps.com\" target=\"_blank\" rel=\"noopener\">5apps</a>) out there, yet, which you can use, but donâ€™t have to, if you donâ€™t trust them. An unhosted-app that is remoteStorage-capable can now connect to your remoteStorage, e.g. <em><a href=\"https://rs.yourserver.com/user1/appXyz\" target=\"_blank\" rel=\"noopener\">https://rs.yourserver.com/user1/appXyz</a></em>, and sync its data there. RemoteStorage works together with <a href=\"https://webfinger.net\" target=\"_blank\" rel=\"noopener\">WebFinger</a>. What is WebFinger now? WebFinger is kind of a registry on the web, where unique keys (usually in email-address style, like <a href=\"mailto:user1@yourserver.com\" target=\"_blank\" rel=\"noopener\">user1@yourserver.com</a>), are mapped to URLâ€™s for a certain type of relation. In this case you would tell your unhosted app such an email-address-like identifier, which maps to your remoteStorage-endpoint for the relation-type â€œremotestorageâ€. The app queries WebFinger for that key and follows the returned registered URL to the datastore. In <a href=\"https://client.webfinger.net/lookup?resource=tony%405apps.com\" target=\"_blank\" rel=\"noopener\">this example</a> the identifier <a href=\"mailto:*tony@5apps.com\" target=\"_blank\" rel=\"noopener\">*tony@5apps.com</a><em> maps to a </em>remotestorage* located at <em><a href=\"https://storage.5apps.com/tony\" target=\"_blank\" rel=\"noopener\">https://storage.5apps.com/tony</a></em>. This makes the entire thing as decentralized as possible. Note that you could change your remoteStorage anytime by simply registering a new URL at WebFinger (you usually wouldnâ€™t have to do this registration on your own, but the remoteStorage server implementation handles that for you). The authorization â€“ like which app may access which subkeys on the remoteStorage â€“ is handled by OAuth at your remoteStorage server implementation, where you can grant or revoke access for certain apps to certain store keys.</p>\n<p>Two apps you can try are <a href=\"https://litewrite.net/\" target=\"_blank\" rel=\"noopener\">litewrite.net</a> and <a href=\"http://grouptabs.5apps.com\" target=\"_blank\" rel=\"noopener\">Grouptabs</a>. If you just want to play around with remoteStorage it might be the easiest way to use <a href=\"http://5apps.com\" target=\"_blank\" rel=\"noopener\">5apps</a>â€˜ remoteStorage for this.</p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<p>Lately you as an interested web developer might have heard or read about a thing called <strong>unhosted applications</strong>, mostly with a reference to <a href=\"http://unhosted.org/\" target=\"_blank\" rel=\"noopener\">unhosted.org</a>. This basically means web-apps running in your browser which do not rely on any kind of backend. Most apps youâ€™re using on the web store data to a backend service at the providerâ€™s host server, regardless of them being Google Docs, Evernote, Wunderlist or also <a href=\"https://anchr.io\" target=\"_blank\" rel=\"noopener\">Anchr.io</a>. Obviously this makes you dependent on the provider in terms of availability and security. Also these apps are usually online-only apps, meaning that you can only use them with an internet connection. Another type of apps are those without a specific backend but still with a central, cloud-based data store, e.g. Firebase. In this case your data is still anywhere out there in the cloud at a provider you potentially could not trust (even though not on any kind of dubious private-hosted server but on a certified platform of one of the big players â€“ deciding whether that is better or worse itâ€™s up to you, actually). These apps are usually offline-capable, so you can use them without internet connection and if the connection comes back again, the data is synced to the data platform. And then thereâ€™s this third kind of apps, which they call unhosted ones. These are intended to be completely static, without needing any kind of backend. Theoretically you could download a zip of their HTML, JavaScript and CSS files to your computer and perfectly run the app without a webserver and a database. Well, ok, probably youâ€™ll need a webserver, but it only needs to server static files (like an Apache2, nginx or <a href=\"https://www.npmjs.com/package/http-server\" target=\"_blank\" rel=\"noopener\">http-server</a>), nothing else â€“ no PHP, node Node.jsâ€¦ Those apps (e.g. a simple todo-list) store all their data to your browserâ€™s localStorage or IndexedDB. As a result it obviously is only available on your local computer and only until you clear you browser data. After all you might still want to sync your data to other devices now â€“ but without giving your data away to a untrusted provider.</p>\n<p><img src=\"/images/unhosted.jpg\" alt=\"\"></p>\n<p>This is where quite a new thing called <a href=\"https://remotestorage.io\" target=\"_blank\" rel=\"noopener\">RemoteStorage</a> comes in. Itâ€™s a protocol for storing per-user data on the web in an unhosted fasion. Anything implementing the remoteStorage protocol can be your data-repository, which basically works as a simple key-value store. As a result you can implement your own remoteStorage or e.g. take the â€œofficialâ€ PHP library to host one on your own server. There are also a few providers (like <a href=\"http://5apps.com\" target=\"_blank\" rel=\"noopener\">5apps</a>) out there, yet, which you can use, but donâ€™t have to, if you donâ€™t trust them. An unhosted-app that is remoteStorage-capable can now connect to your remoteStorage, e.g. <em><a href=\"https://rs.yourserver.com/user1/appXyz\" target=\"_blank\" rel=\"noopener\">https://rs.yourserver.com/user1/appXyz</a></em>, and sync its data there. RemoteStorage works together with <a href=\"https://webfinger.net\" target=\"_blank\" rel=\"noopener\">WebFinger</a>. What is WebFinger now? WebFinger is kind of a registry on the web, where unique keys (usually in email-address style, like <a href=\"mailto:user1@yourserver.com\" target=\"_blank\" rel=\"noopener\">user1@yourserver.com</a>), are mapped to URLâ€™s for a certain type of relation. In this case you would tell your unhosted app such an email-address-like identifier, which maps to your remoteStorage-endpoint for the relation-type â€œremotestorageâ€. The app queries WebFinger for that key and follows the returned registered URL to the datastore. In <a href=\"https://client.webfinger.net/lookup?resource=tony%405apps.com\" target=\"_blank\" rel=\"noopener\">this example</a> the identifier <a href=\"mailto:*tony@5apps.com\" target=\"_blank\" rel=\"noopener\">*tony@5apps.com</a><em> maps to a </em>remotestorage* located at <em><a href=\"https://storage.5apps.com/tony\" target=\"_blank\" rel=\"noopener\">https://storage.5apps.com/tony</a></em>. This makes the entire thing as decentralized as possible. Note that you could change your remoteStorage anytime by simply registering a new URL at WebFinger (you usually wouldnâ€™t have to do this registration on your own, but the remoteStorage server implementation handles that for you). The authorization â€“ like which app may access which subkeys on the remoteStorage â€“ is handled by OAuth at your remoteStorage server implementation, where you can grant or revoke access for certain apps to certain store keys.</p>\n<p>Two apps you can try are <a href=\"https://litewrite.net/\" target=\"_blank\" rel=\"noopener\">litewrite.net</a> and <a href=\"http://grouptabs.5apps.com\" target=\"_blank\" rel=\"noopener\">Grouptabs</a>. If you just want to play around with remoteStorage it might be the easiest way to use <a href=\"http://5apps.com\" target=\"_blank\" rel=\"noopener\">5apps</a>â€˜ remoteStorage for this.</p>\n"},{"title":"Web Development Technology Stack","date":"2016-03-15T21:54:04.000Z","_content":"\nI tried to give a comprehensive overview of all important and fashionable technologies concerning web- and cross-platform development, so I created kind of a mind map outlining relevant technologies in terms of languages, frameworks, libraries, webservices and tools. I consider them kind of must-haves for JavaScript fullstack web-developers. You might have already heard of most of them and probably you have even worked with the majority.\n\nFeel free to give your opinion on this collection and maybe add something youâ€™re missing (in the comments after having logged in, via mail or via [telegram.me/n1try](http://telegram.me/n1try)).\n\n[![Web Tech Stack](/imgages/webdev_techstack.png)](/imgages/webdev_techstack_large.png)","source":"_posts/web-development-technology-stack.md","raw":"---\ntitle: Web Development Technology Stack\ndate: 2016-03-15 22:54:04\ntags:\n---\n\nI tried to give a comprehensive overview of all important and fashionable technologies concerning web- and cross-platform development, so I created kind of a mind map outlining relevant technologies in terms of languages, frameworks, libraries, webservices and tools. I consider them kind of must-haves for JavaScript fullstack web-developers. You might have already heard of most of them and probably you have even worked with the majority.\n\nFeel free to give your opinion on this collection and maybe add something youâ€™re missing (in the comments after having logged in, via mail or via [telegram.me/n1try](http://telegram.me/n1try)).\n\n[![Web Tech Stack](/imgages/webdev_techstack.png)](/imgages/webdev_techstack_large.png)","slug":"web-development-technology-stack","published":1,"updated":"2018-03-19T09:30:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2giomj000rcxrgtgpx51uu","content":"<p>I tried to give a comprehensive overview of all important and fashionable technologies concerning web- and cross-platform development, so I created kind of a mind map outlining relevant technologies in terms of languages, frameworks, libraries, webservices and tools. I consider them kind of must-haves for JavaScript fullstack web-developers. You might have already heard of most of them and probably you have even worked with the majority.</p>\n<p>Feel free to give your opinion on this collection and maybe add something youâ€™re missing (in the comments after having logged in, via mail or via <a href=\"http://telegram.me/n1try\" target=\"_blank\" rel=\"noopener\">telegram.me/n1try</a>).</p>\n<p><a href=\"/imgages/webdev_techstack_large.png\"><img src=\"/imgages/webdev_techstack.png\" alt=\"Web Tech Stack\"></a></p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<p>I tried to give a comprehensive overview of all important and fashionable technologies concerning web- and cross-platform development, so I created kind of a mind map outlining relevant technologies in terms of languages, frameworks, libraries, webservices and tools. I consider them kind of must-haves for JavaScript fullstack web-developers. You might have already heard of most of them and probably you have even worked with the majority.</p>\n<p>Feel free to give your opinion on this collection and maybe add something youâ€™re missing (in the comments after having logged in, via mail or via <a href=\"http://telegram.me/n1try\" target=\"_blank\" rel=\"noopener\">telegram.me/n1try</a>).</p>\n<p><a href=\"/imgages/webdev_techstack_large.png\"><img src=\"/imgages/webdev_techstack.png\" alt=\"Web Tech Stack\"></a></p>\n"},{"title":"Webdevlist.net - The Developer's Resource Collection","date":"2016-09-21T21:02:25.000Z","_content":"\n![](/images/webdevlist.jpg)\n\nI just put up a new project of mine, which is called Webdevlist.\n\n### So what is Webdevlist?\n\nIâ€™m pretty sure most developers know it all too well: you browse Twitter, Reddit or Stackoverflow on a late Sunday evening and come across some cool programming framework or webservice. You think like _â€œWow thatâ€™s cool! Could be helpful some time. I need to remember it.â€_ Then you put the link anywhere in a messy text file or the like and never visit it again. Webdevlistâ€™s aim is to become a comprehensive, community-maintained collection of useful resources concerning software development. Such could include frameworks and libraries for any language, devtools, software applications, apps, webservices like PaaS, SaaS or IaaS and also learning resources like guides and tutorials. Everytime you find a cool tool on the web, just post it to the list. Everytime youâ€™re looking for a tool to help you with your development problems come visit the list. Easy enough.\n\n### Tech facts\n\nWebdevlistâ€™s frontend is built with [Angular2](https://angular.io/ \"Angular2\"), which just has had its first final release. The backend makes use of [LoopbackJS](http://loopback.io/ \"LoopbackJS\"), which is a mighty framework to build REST APIs with a minimum of boilerplate code. Additionally the site is powered by HTTP/2.0 to get some more speed.\n\n### Is it finished, yet?\n\nNo, it isnâ€™t. Actually, it probably never will be. Iâ€™m continuously going to add new technology to Webdevlistâ€™s stack and change and refactor things. Currently Iâ€™m considering to switch to [GraphQL](http://graphql.org/learn/ \"GraphQL\"). Right now, Webdevlist is in some kind of beta state, meaning that it still might have bugs.\n\nIâ€™d really appreciate to get feedback on this project!\n\n[>> Webdevlist.net](https://webdevlist.net)  \n[>> Webdevlist on GitHub](https://github.com/n1try/webdevlist.net) ","source":"_posts/webdevlistnet-the-developers-resource-collection.md","raw":"---\ntitle: Webdevlist.net - The Developer's Resource Collection\ndate: 2016-09-21 23:02:25\ntags:\n---\n\n![](/images/webdevlist.jpg)\n\nI just put up a new project of mine, which is called Webdevlist.\n\n### So what is Webdevlist?\n\nIâ€™m pretty sure most developers know it all too well: you browse Twitter, Reddit or Stackoverflow on a late Sunday evening and come across some cool programming framework or webservice. You think like _â€œWow thatâ€™s cool! Could be helpful some time. I need to remember it.â€_ Then you put the link anywhere in a messy text file or the like and never visit it again. Webdevlistâ€™s aim is to become a comprehensive, community-maintained collection of useful resources concerning software development. Such could include frameworks and libraries for any language, devtools, software applications, apps, webservices like PaaS, SaaS or IaaS and also learning resources like guides and tutorials. Everytime you find a cool tool on the web, just post it to the list. Everytime youâ€™re looking for a tool to help you with your development problems come visit the list. Easy enough.\n\n### Tech facts\n\nWebdevlistâ€™s frontend is built with [Angular2](https://angular.io/ \"Angular2\"), which just has had its first final release. The backend makes use of [LoopbackJS](http://loopback.io/ \"LoopbackJS\"), which is a mighty framework to build REST APIs with a minimum of boilerplate code. Additionally the site is powered by HTTP/2.0 to get some more speed.\n\n### Is it finished, yet?\n\nNo, it isnâ€™t. Actually, it probably never will be. Iâ€™m continuously going to add new technology to Webdevlistâ€™s stack and change and refactor things. Currently Iâ€™m considering to switch to [GraphQL](http://graphql.org/learn/ \"GraphQL\"). Right now, Webdevlist is in some kind of beta state, meaning that it still might have bugs.\n\nIâ€™d really appreciate to get feedback on this project!\n\n[>> Webdevlist.net](https://webdevlist.net)  \n[>> Webdevlist on GitHub](https://github.com/n1try/webdevlist.net) ","slug":"webdevlistnet-the-developers-resource-collection","published":1,"updated":"2018-03-19T09:30:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2giomk000scxrgsn4xqb0k","content":"<p><img src=\"/images/webdevlist.jpg\" alt=\"\"></p>\n<p>I just put up a new project of mine, which is called Webdevlist.</p>\n<h3 id=\"So-what-is-Webdevlist\"><a href=\"#So-what-is-Webdevlist\" class=\"headerlink\" title=\"So what is Webdevlist?\"></a>So what is Webdevlist?</h3><p>Iâ€™m pretty sure most developers know it all too well: you browse Twitter, Reddit or Stackoverflow on a late Sunday evening and come across some cool programming framework or webservice. You think like <em>â€œWow thatâ€™s cool! Could be helpful some time. I need to remember it.â€</em> Then you put the link anywhere in a messy text file or the like and never visit it again. Webdevlistâ€™s aim is to become a comprehensive, community-maintained collection of useful resources concerning software development. Such could include frameworks and libraries for any language, devtools, software applications, apps, webservices like PaaS, SaaS or IaaS and also learning resources like guides and tutorials. Everytime you find a cool tool on the web, just post it to the list. Everytime youâ€™re looking for a tool to help you with your development problems come visit the list. Easy enough.</p>\n<h3 id=\"Tech-facts\"><a href=\"#Tech-facts\" class=\"headerlink\" title=\"Tech facts\"></a>Tech facts</h3><p>Webdevlistâ€™s frontend is built with <a href=\"https://angular.io/\" title=\"Angular2\" target=\"_blank\" rel=\"noopener\">Angular2</a>, which just has had its first final release. The backend makes use of <a href=\"http://loopback.io/\" title=\"LoopbackJS\" target=\"_blank\" rel=\"noopener\">LoopbackJS</a>, which is a mighty framework to build REST APIs with a minimum of boilerplate code. Additionally the site is powered by HTTP/2.0 to get some more speed.</p>\n<h3 id=\"Is-it-finished-yet\"><a href=\"#Is-it-finished-yet\" class=\"headerlink\" title=\"Is it finished, yet?\"></a>Is it finished, yet?</h3><p>No, it isnâ€™t. Actually, it probably never will be. Iâ€™m continuously going to add new technology to Webdevlistâ€™s stack and change and refactor things. Currently Iâ€™m considering to switch to <a href=\"http://graphql.org/learn/\" title=\"GraphQL\" target=\"_blank\" rel=\"noopener\">GraphQL</a>. Right now, Webdevlist is in some kind of beta state, meaning that it still might have bugs.</p>\n<p>Iâ€™d really appreciate to get feedback on this project!</p>\n<p><a href=\"https://webdevlist.net\" target=\"_blank\" rel=\"noopener\">&gt;&gt; Webdevlist.net</a><br><a href=\"https://github.com/n1try/webdevlist.net\" target=\"_blank\" rel=\"noopener\">&gt;&gt; Webdevlist on GitHub</a> </p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<p><img src=\"/images/webdevlist.jpg\" alt=\"\"></p>\n<p>I just put up a new project of mine, which is called Webdevlist.</p>\n<h3 id=\"So-what-is-Webdevlist\"><a href=\"#So-what-is-Webdevlist\" class=\"headerlink\" title=\"So what is Webdevlist?\"></a>So what is Webdevlist?</h3><p>Iâ€™m pretty sure most developers know it all too well: you browse Twitter, Reddit or Stackoverflow on a late Sunday evening and come across some cool programming framework or webservice. You think like <em>â€œWow thatâ€™s cool! Could be helpful some time. I need to remember it.â€</em> Then you put the link anywhere in a messy text file or the like and never visit it again. Webdevlistâ€™s aim is to become a comprehensive, community-maintained collection of useful resources concerning software development. Such could include frameworks and libraries for any language, devtools, software applications, apps, webservices like PaaS, SaaS or IaaS and also learning resources like guides and tutorials. Everytime you find a cool tool on the web, just post it to the list. Everytime youâ€™re looking for a tool to help you with your development problems come visit the list. Easy enough.</p>\n<h3 id=\"Tech-facts\"><a href=\"#Tech-facts\" class=\"headerlink\" title=\"Tech facts\"></a>Tech facts</h3><p>Webdevlistâ€™s frontend is built with <a href=\"https://angular.io/\" title=\"Angular2\" target=\"_blank\" rel=\"noopener\">Angular2</a>, which just has had its first final release. The backend makes use of <a href=\"http://loopback.io/\" title=\"LoopbackJS\" target=\"_blank\" rel=\"noopener\">LoopbackJS</a>, which is a mighty framework to build REST APIs with a minimum of boilerplate code. Additionally the site is powered by HTTP/2.0 to get some more speed.</p>\n<h3 id=\"Is-it-finished-yet\"><a href=\"#Is-it-finished-yet\" class=\"headerlink\" title=\"Is it finished, yet?\"></a>Is it finished, yet?</h3><p>No, it isnâ€™t. Actually, it probably never will be. Iâ€™m continuously going to add new technology to Webdevlistâ€™s stack and change and refactor things. Currently Iâ€™m considering to switch to <a href=\"http://graphql.org/learn/\" title=\"GraphQL\" target=\"_blank\" rel=\"noopener\">GraphQL</a>. Right now, Webdevlist is in some kind of beta state, meaning that it still might have bugs.</p>\n<p>Iâ€™d really appreciate to get feedback on this project!</p>\n<p><a href=\"https://webdevlist.net\" target=\"_blank\" rel=\"noopener\">&gt;&gt; Webdevlist.net</a><br><a href=\"https://github.com/n1try/webdevlist.net\" target=\"_blank\" rel=\"noopener\">&gt;&gt; Webdevlist on GitHub</a> </p>\n"},{"title":"Why RAID 10 is better than RAID 01","date":"2015-11-19T21:43:31.000Z","_content":"\nSince it took me a while to completely understand why a RAID 1+0 configuration should be better than a RAID 0+1 one in terms of failure tolerance I want to put my insights down.  \nFirst you should have a basic understanding of what the first two RAID levels are and what it means to nest them. Very basically at level 0 data gets striped, meaning a datum gets split up into two or more blocks that get stored on a different hard drive each. Goal is to improve read and write performance linearly to the number of disks used, because the fragments donâ€™t have to be read sequentially anymore but in parallel. Level 1 is about mirroring a datum on two disks with the goal to improve security. Of course, both levels can be combined â€“ you could either mirror striped data or stripe mirrored data which finally gives both: security and performance. In each case at least four disks are needed, while the half of the disks usually is a mirror. So if you took six disks you would do 3-striping. With eight disks you would do 4-striping and so on. Technically you could have more than one mirror (like doing 2-striping and having a 3-mirror or even more) but itâ€™s very unusual.  \nThe following diagrams shall illustrate these two ways and are useful for further explanations. In both cases we have a RAID with six disks.\n\n![raid01](/images/raid01.png)  \n\n*Disks 4, 5 and 6 are the mirrors of 1, 2 and 3.*\n\n![raid10](/images/raid10.png)  \n\n*Disk 2 mirrors 1, 4 mirrors 3 and 6 mirrors 5.*\n\nWe assert that RAID 10 is better in terms of fault tolerance because a total failure (= loss of data) is less likely. In other words if some drives crash in a RAID 01 configuration the chance that those are the right drives for suffering a data loss is higher.  \nFirst of all, both configurations can easily survive the crash of one drive. No matter which drive (see figures above) crashes, we have a second one with the exact same data on it in any case. Potentially both configurations can handle the simultaneous crash of two or even more drives (up to N/2), if theyâ€™re the right ones, but in the worst case, the second crash could end up in a total failure. What you need to make clear before understanding how RAID 01 is worse than RAID 10 is that a RAID 0 (sub)system immediately gets unusable if one of its disks goes down. This is apparent: In the upper figure (figure 1 from now on) data is divided up into three strips in both RAID 0 subsystem. So if one of their disks fails (assume a crash of Disc1), the subsystem is broken since the first two parts of a date wonâ€™t make sense without the third. You would still be in posession of all data, nothing is lost yet, but nevertheless the left RAID 0 subsystem is down. If a second drive fails this should only be 2 or 3 (since the left system in inacessible anyway) to keep the entire system up. Disc 4, 5 or 6 failing would cause a total crash. So the chance of the second failing disk resulting in a total crash is 3/5\\. Now take a look at figure 2\\. The crash of one disk in a RAID 1 (sub)system wonâ€™t make this subsystem go down because the RAID controller will seamlessly switch to the mirror drive which has exactly identical data. In figure 2 all RAID 0 disks (which actually are stanalone RAID 1 systems again) need to keep running for the entire system to stay up. So theoretically there wouldnâ€™t be a problem with disks 1, 3 and 5 (or 2, 4 and 6) could crashing simultaneously. After one disk having failed (assume a crash of Disc1 again) the second one failing could be 3, 4, 5 or 6 â€“ all but NOT 2\\. The probability of a total crash is 1/5 (namely Disc2 of the remaining five) now and therefore lower than 3/5 with RAID 01\\. Hope you got itâ€¦","source":"_posts/why-raid-10-is-better-than-raid-01.md","raw":"---\ntitle: Why RAID 10 is better than RAID 01\ndate: 2015-11-19 22:43:31\ntags:\n---\n\nSince it took me a while to completely understand why a RAID 1+0 configuration should be better than a RAID 0+1 one in terms of failure tolerance I want to put my insights down.  \nFirst you should have a basic understanding of what the first two RAID levels are and what it means to nest them. Very basically at level 0 data gets striped, meaning a datum gets split up into two or more blocks that get stored on a different hard drive each. Goal is to improve read and write performance linearly to the number of disks used, because the fragments donâ€™t have to be read sequentially anymore but in parallel. Level 1 is about mirroring a datum on two disks with the goal to improve security. Of course, both levels can be combined â€“ you could either mirror striped data or stripe mirrored data which finally gives both: security and performance. In each case at least four disks are needed, while the half of the disks usually is a mirror. So if you took six disks you would do 3-striping. With eight disks you would do 4-striping and so on. Technically you could have more than one mirror (like doing 2-striping and having a 3-mirror or even more) but itâ€™s very unusual.  \nThe following diagrams shall illustrate these two ways and are useful for further explanations. In both cases we have a RAID with six disks.\n\n![raid01](/images/raid01.png)  \n\n*Disks 4, 5 and 6 are the mirrors of 1, 2 and 3.*\n\n![raid10](/images/raid10.png)  \n\n*Disk 2 mirrors 1, 4 mirrors 3 and 6 mirrors 5.*\n\nWe assert that RAID 10 is better in terms of fault tolerance because a total failure (= loss of data) is less likely. In other words if some drives crash in a RAID 01 configuration the chance that those are the right drives for suffering a data loss is higher.  \nFirst of all, both configurations can easily survive the crash of one drive. No matter which drive (see figures above) crashes, we have a second one with the exact same data on it in any case. Potentially both configurations can handle the simultaneous crash of two or even more drives (up to N/2), if theyâ€™re the right ones, but in the worst case, the second crash could end up in a total failure. What you need to make clear before understanding how RAID 01 is worse than RAID 10 is that a RAID 0 (sub)system immediately gets unusable if one of its disks goes down. This is apparent: In the upper figure (figure 1 from now on) data is divided up into three strips in both RAID 0 subsystem. So if one of their disks fails (assume a crash of Disc1), the subsystem is broken since the first two parts of a date wonâ€™t make sense without the third. You would still be in posession of all data, nothing is lost yet, but nevertheless the left RAID 0 subsystem is down. If a second drive fails this should only be 2 or 3 (since the left system in inacessible anyway) to keep the entire system up. Disc 4, 5 or 6 failing would cause a total crash. So the chance of the second failing disk resulting in a total crash is 3/5\\. Now take a look at figure 2\\. The crash of one disk in a RAID 1 (sub)system wonâ€™t make this subsystem go down because the RAID controller will seamlessly switch to the mirror drive which has exactly identical data. In figure 2 all RAID 0 disks (which actually are stanalone RAID 1 systems again) need to keep running for the entire system to stay up. So theoretically there wouldnâ€™t be a problem with disks 1, 3 and 5 (or 2, 4 and 6) could crashing simultaneously. After one disk having failed (assume a crash of Disc1 again) the second one failing could be 3, 4, 5 or 6 â€“ all but NOT 2\\. The probability of a total crash is 1/5 (namely Disc2 of the remaining five) now and therefore lower than 3/5 with RAID 01\\. Hope you got itâ€¦","slug":"why-raid-10-is-better-than-raid-01","published":1,"updated":"2018-03-19T09:30:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjh2gioml000tcxrg1lmshc5o","content":"<p>Since it took me a while to completely understand why a RAID 1+0 configuration should be better than a RAID 0+1 one in terms of failure tolerance I want to put my insights down.<br>First you should have a basic understanding of what the first two RAID levels are and what it means to nest them. Very basically at level 0 data gets striped, meaning a datum gets split up into two or more blocks that get stored on a different hard drive each. Goal is to improve read and write performance linearly to the number of disks used, because the fragments donâ€™t have to be read sequentially anymore but in parallel. Level 1 is about mirroring a datum on two disks with the goal to improve security. Of course, both levels can be combined â€“ you could either mirror striped data or stripe mirrored data which finally gives both: security and performance. In each case at least four disks are needed, while the half of the disks usually is a mirror. So if you took six disks you would do 3-striping. With eight disks you would do 4-striping and so on. Technically you could have more than one mirror (like doing 2-striping and having a 3-mirror or even more) but itâ€™s very unusual.<br>The following diagrams shall illustrate these two ways and are useful for further explanations. In both cases we have a RAID with six disks.</p>\n<p><img src=\"/images/raid01.png\" alt=\"raid01\">  </p>\n<p><em>Disks 4, 5 and 6 are the mirrors of 1, 2 and 3.</em></p>\n<p><img src=\"/images/raid10.png\" alt=\"raid10\">  </p>\n<p><em>Disk 2 mirrors 1, 4 mirrors 3 and 6 mirrors 5.</em></p>\n<p>We assert that RAID 10 is better in terms of fault tolerance because a total failure (= loss of data) is less likely. In other words if some drives crash in a RAID 01 configuration the chance that those are the right drives for suffering a data loss is higher.<br>First of all, both configurations can easily survive the crash of one drive. No matter which drive (see figures above) crashes, we have a second one with the exact same data on it in any case. Potentially both configurations can handle the simultaneous crash of two or even more drives (up to N/2), if theyâ€™re the right ones, but in the worst case, the second crash could end up in a total failure. What you need to make clear before understanding how RAID 01 is worse than RAID 10 is that a RAID 0 (sub)system immediately gets unusable if one of its disks goes down. This is apparent: In the upper figure (figure 1 from now on) data is divided up into three strips in both RAID 0 subsystem. So if one of their disks fails (assume a crash of Disc1), the subsystem is broken since the first two parts of a date wonâ€™t make sense without the third. You would still be in posession of all data, nothing is lost yet, but nevertheless the left RAID 0 subsystem is down. If a second drive fails this should only be 2 or 3 (since the left system in inacessible anyway) to keep the entire system up. Disc 4, 5 or 6 failing would cause a total crash. So the chance of the second failing disk resulting in a total crash is 3/5. Now take a look at figure 2. The crash of one disk in a RAID 1 (sub)system wonâ€™t make this subsystem go down because the RAID controller will seamlessly switch to the mirror drive which has exactly identical data. In figure 2 all RAID 0 disks (which actually are stanalone RAID 1 systems again) need to keep running for the entire system to stay up. So theoretically there wouldnâ€™t be a problem with disks 1, 3 and 5 (or 2, 4 and 6) could crashing simultaneously. After one disk having failed (assume a crash of Disc1 again) the second one failing could be 3, 4, 5 or 6 â€“ all but NOT 2. The probability of a total crash is 1/5 (namely Disc2 of the remaining five) now and therefore lower than 3/5 with RAID 01. Hope you got itâ€¦</p>\n","site":{"data":{"projects":[{"name":"MiniNote","url":"https://github.com/n1try/mininote","desc":"A simple, persistent, self-hosted Markdown note-taking app built with VueJS."},{"name":"telegram-middleman-bot","url":"https://github.com/n1try/telegram-middleman-bot","desc":"A Telegram bot which translates push messages sent as simple HTTP calls into Telegram messages you can subscribe to. Written in Go."},{"name":"Webdevlist","url":"https://github.com/n1try/webdevlist.net","desc":"A resource collection for developers containing programming libraries and frameworks, software applications, webservices and *aaS providers as well as learning resources, guides and tutorials all in one place."},{"name":"Anchr.io","url":"https://github.com/n1try/anchr","desc":"A toolbox service for maintaining bookmark collections, shortening links and uploading and sharing images encryptedly."},{"name":"express-request-limit","url":"https://github.com/n1try/express-request-limit","desc":"Express middleware to limit the request rate to specific routes, based on client IP address."},{"name":"http2-serverpush-proxy","url":"https://github.com/n1try/http2-serverpush-proxy","desc":"A simple standalone reverse proxy that automatically enables server-push for assets related to a HTTP response."},{"name":"Telegram ExpenseBot","url":"https://ferdinand-muetsch.de/telegram-expensebot-doodlerbot.html","desc":"A Telegram bot to manage your daily expenses and keep track of your financial situation."}]}},"excerpt":"","more":"<p>Since it took me a while to completely understand why a RAID 1+0 configuration should be better than a RAID 0+1 one in terms of failure tolerance I want to put my insights down.<br>First you should have a basic understanding of what the first two RAID levels are and what it means to nest them. Very basically at level 0 data gets striped, meaning a datum gets split up into two or more blocks that get stored on a different hard drive each. Goal is to improve read and write performance linearly to the number of disks used, because the fragments donâ€™t have to be read sequentially anymore but in parallel. Level 1 is about mirroring a datum on two disks with the goal to improve security. Of course, both levels can be combined â€“ you could either mirror striped data or stripe mirrored data which finally gives both: security and performance. In each case at least four disks are needed, while the half of the disks usually is a mirror. So if you took six disks you would do 3-striping. With eight disks you would do 4-striping and so on. Technically you could have more than one mirror (like doing 2-striping and having a 3-mirror or even more) but itâ€™s very unusual.<br>The following diagrams shall illustrate these two ways and are useful for further explanations. In both cases we have a RAID with six disks.</p>\n<p><img src=\"/images/raid01.png\" alt=\"raid01\">  </p>\n<p><em>Disks 4, 5 and 6 are the mirrors of 1, 2 and 3.</em></p>\n<p><img src=\"/images/raid10.png\" alt=\"raid10\">  </p>\n<p><em>Disk 2 mirrors 1, 4 mirrors 3 and 6 mirrors 5.</em></p>\n<p>We assert that RAID 10 is better in terms of fault tolerance because a total failure (= loss of data) is less likely. In other words if some drives crash in a RAID 01 configuration the chance that those are the right drives for suffering a data loss is higher.<br>First of all, both configurations can easily survive the crash of one drive. No matter which drive (see figures above) crashes, we have a second one with the exact same data on it in any case. Potentially both configurations can handle the simultaneous crash of two or even more drives (up to N/2), if theyâ€™re the right ones, but in the worst case, the second crash could end up in a total failure. What you need to make clear before understanding how RAID 01 is worse than RAID 10 is that a RAID 0 (sub)system immediately gets unusable if one of its disks goes down. This is apparent: In the upper figure (figure 1 from now on) data is divided up into three strips in both RAID 0 subsystem. So if one of their disks fails (assume a crash of Disc1), the subsystem is broken since the first two parts of a date wonâ€™t make sense without the third. You would still be in posession of all data, nothing is lost yet, but nevertheless the left RAID 0 subsystem is down. If a second drive fails this should only be 2 or 3 (since the left system in inacessible anyway) to keep the entire system up. Disc 4, 5 or 6 failing would cause a total crash. So the chance of the second failing disk resulting in a total crash is 3/5. Now take a look at figure 2. The crash of one disk in a RAID 1 (sub)system wonâ€™t make this subsystem go down because the RAID controller will seamlessly switch to the mirror drive which has exactly identical data. In figure 2 all RAID 0 disks (which actually are stanalone RAID 1 systems again) need to keep running for the entire system to stay up. So theoretically there wouldnâ€™t be a problem with disks 1, 3 and 5 (or 2, 4 and 6) could crashing simultaneously. After one disk having failed (assume a crash of Disc1 again) the second one failing could be 3, 4, 5 or 6 â€“ all but NOT 2. The probability of a total crash is 1/5 (namely Disc2 of the remaining five) now and therefore lower than 3/5 with RAID 01. Hope you got itâ€¦</p>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[],"Tag":[]}}